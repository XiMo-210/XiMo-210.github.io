[{"title":"Windows Server 部署 ASP 网站","path":"/posts/windows-server-deploy-asp-website/","content":"起始背景刚接手某个坑位组织的技术总监位置，在短学期工训的时候被指导老师拉进了某个群聊，告知学校的旧心理测评平台需要重新启用，至于为什么和我有关，是因为这个旧服务借挂在组织的内网服务器上，作为当代的技术总监，自然就被捎带上了，不过具体情况我还不清楚，好在看了眼群里还有前两代技术总监在压阵。这里简单提一下服务器的情况，组织在内网有 2 台 PVE 的服务器，一台近一年有使用过（代称 1 号机），另一台目前没怎么用过（代称 2 号机），旧心理测评的服务就在 2 号机上。 这里提一下 PVE，简单讲可以类比为 VMware，下面介绍摘自维基百科。 Proxmox Virtual Environment（简称：Proxmox VE、PVE），是一个开源的服务器虚拟化环境 Linux 发行版。Proxmox VE 基于 Debian，使用基于 Ubuntu 的定制内核，包含安装程序、网页控制台和命令行工具，并且向第三方工具提供了 REST API，在 Affero 通用公共许可证第三版下发行。Proxmox VE 支持两类虚拟化技术：基于容器的 LXC 和硬件抽象层全虚拟化的 KVM。 工训闲暇时翻了下服务器的祖传文档，发现心理测评这个服务开的是 Windows Server 2008R2 Enterprise 的清朝遗物虚拟机，还贴了个已废弃的 tag，估计是没想到还有要重启的一天，除此之外就没有用的信息了。和上代技术总监沟通了下，只要上 PVE 把心理测评的虚拟机启动就行。 失联的 2 号机PVE 通常是通过 Web 管理界面去操作虚拟机，有图形化谁用命令行，但是前提是 8006 的端口（Web 管理界面的访问端口）开放。由于学校内网默认只开放 80 端口，其他端口开放需要和信息办申请，因此先找相关老师去走了波流程。联系完的第二天，在得到端口已经开放的答复后，2 号机的管理界面却依旧访问不了，原以为是开放出了岔子，但是发现 1 号机的管理界面能正常访问。于是排查了一下得出结论，端口开放了，2 号机出问题了。2 号机有问题其实早有预兆 ，实际上在我刚接手服务器的时候就没连上过 2 号机，根本 ping 不通，我以为是文档有问题或者是哪里加了限制，但是 1 号机的访问正常，且 2 号机并未在使用也就没有多深究。如今看来，是在接手前 2 号机就失联了。不确定 2 号机是被关了还是没跑起来，于是又联系了上代总监。 由于服务器在另一个校区，只能先联系信息办的老师去排查了。 上不去的 1 号机然而祸不单行，当我想上 1 号机的管理界面去看看时，根据文档里记录的账密却怎么也登不上去，你这文档保熟吗。于是又又联系了上代总监。 得出的结果为 1 号机和 2 号机做了集群，于是 2 号机挂了顺带踢了一脚 1 号机，又导致 1 号机登不上了，于是现在都堵在 2 号机了，只能先等待信息办的回复了。 失联的 1 号机信息办去完现场后给了一个返图。 坏了两个硬盘，然后他们说把 2 号机强行启动了。但是不出意外的话，又要出意外了，2 号机还是失联，而且这次 1 号机也一起失联了，两台一起寄了，具体故障原因未知。更寄的是组织的一部分服务还挂在 1 号机的虚拟机上，不出意外的，服务也歇菜了。原本不急的，因为旧心理测评的服务和我们组织实质的关系不大，现在不得不急了。不过庆幸的是还值暑假，服务并没有多少流量，临时将服务切回公网的服务器也算没造成太大影响。那么接下来就是得想办法去抢救一下这两哥哥弟弟了。 抢救服务器由于只玩过云服务器，对于线下的物理服务器一窍不通，只好联系前前前···总监出手了，约了时间一起去现场看服务器，中途顶着大太阳去找垃圾佬整了几块硬盘，然后开始抢救服务器。初期判断 2 号机组的是 raid10，损坏的两个都是备份盘，理论上的数据没有丢失，可以尝试更换硬盘进行重建，于是乎半场准备开香槟了，一块换了后正常重建了，但是另一块换了好几块硬盘依旧是 Failed，继续排查了两三个小时，最后赶在机房工作人员下班前得出了结论，那块的硬盘盒读写有问题，导致了无法重建。由于到了点且手头没有多的硬盘盒于是只能先行撤退，但并非无功而返，重启了几次后的 2 号机能够连上了，且 1 号机也恢复了正常，同时管理界面也都能正常访问且登录了，但可惜的是心理测评服务所在的虚拟器由于硬盘问题无法启动。走前给群里发了个反馈，这事就暂时停滞了，等着后面再来抢修。 转机其实在准备去抢救服务器的前两天，相关老师发过一个 21 年的网站备份数据。 我姑且进去扫了一眼目录。但是没有什么印象，也不知道是什么网站数据的备份，问了上代总监也没什么头绪，于是也没有在意，等着后面先去抢救服务器。但是服务器没有完全抢救成功，心理测评的服务还是没有恢复，于是心血来潮我又打算研究一下这个备份文件，然后被我在 wwwroot 下翻到了一个安装说明.txt。这下事件开始迎来了转机，补首诗在此。 游山西村陆游莫笑农家腊酒浑，丰年留客足鸡豚。山重水复疑无路，柳暗花明又一村。箫鼓追随春社近，衣冠简朴古风存。从今若许闲乘月，拄杖无时夜叩门。诗词节选 根据说明基本得知是 Windows Server 上部署的一个 ASP 项目，事后回来看，前面的目录就是 ISS 网站的目录，果然还是阅历尚浅了，平常 linux 服务器用的多，栽在 windows 服务器上了。所以接下来的数据恢复实质上就是重新将服务在 Windows Server 上跑起来，但是能否恢复还是未知数，得看数据库的数据是否有备份，下面简单记录下折腾了半天的部署过程。 ASP 网站部署由于打算先在本地尝试恢复，因此使用 VMware 演示，Windows Server 的版本没有选择 2008 的老古董，直接上了最新版的 2022，测试下来的流程基本相同。 1.安装 IIS 服务首先打开服务器管理器，一般启动时会自动打开。打开后的服务器管理器页面如下所示，点击添加角色和功能，之后一直点击下一步。选择服务器角色时添加**Web 服务器(IIS)**，添加完后继续下一步。 选择角色服务时添加应用程序开发下的ASP，会同时添加ISAPI 扩展，添加完后继续下一步 确认选择无误后安装等待进度条跑完后点击关闭即可，到此 ISS 服务就安装完成了。打开浏览器输入 127.0.0.1，出现下图就说明安装成功了。另外此时打开资源管理器，可以看到熟悉的 inethub 目录。这里的目录是安装完 ISS 服务默认创建的，对应/inethub/wwwroot存放的就是项目文件夹，后文的Default Web Site的内容就在此处，可以选择在该目录直接部署，备份文件中的部署方式应该就是直接覆盖了默认网站的内容，不过后续演示采用添加新网站的方式。 2.添加网站回到服务器管理器页面，依次点击工具-&gt;Internet Information Services (IIS)管理器。展开左侧目录后可以看到网站下有一个Default Web Site，绑定监听的是*:80，即刚才访问127.0.0.1所看到的页面，然后右键网站-&gt;添加网站。填写网站名称，物理路径和IP 地址后点击确定。 网站名称自取 物理路径即 ASP 项目的路径，即备份文件中/inethup/wwwroot文件夹的内容，这里我重命名为了 xlcp IP 地址点击下拉框选择即可，默认是本机的 ip 地址 注：全部未分配即*已经分配给了Default Web Site 3.设置网站目录权限如果不编辑权限直接访问 192.168.108.136（上文的 IP 地址），会显示如下页面并提示权限不足，因此需要先设置权限。回到IIS 管理器，右键xlcp-&gt;编辑权限依次点击安全-&gt;编辑-&gt;添加-&gt;高级点击立即查找，在搜索结果中找到并选择Everyone后确定。给Everyone添加完全控制权限后一路确定回去。 4.配置 ASP 应用程序属性点击xlcp-&gt;ASP，将启动父路径修改为True后应用。 5.设置默认文档点击xlcp-&gt;默认文档，将index.asp移动至最上方。 6.配置应用程序池依次点击应用程序池-&gt;xlcp（添加网站时自动创建）-&gt;高级设置，将启用 32 位应用程序修改为True后确定。 7.配置数据库如果没有其他环境依赖的项目在上一步就可以正常运行了，但是心理测评还有一个数据库需要处理，不处理直接访问会出现下面的错误。原先我较为担心的是使用 MySQL 或者 SQL Server 数据库，没有带着数据库内容一起备份，导致即使服务重新跑起来也没用，因为实际上要的是旧心理测评平台里的老数据。但是翻了下 db 目录后放心了，是 Access 数据库，数据都存在 mdb 文件里了，看时间基本是备份时的数据都在了。在项目文件夹里找到了 global.asa 的配置文件，看了眼只需要将 Data Source 的路径修改为当前 mdb 文件所在的路径即可。重新访问页面，可以看到已经正常运行了。 后续在本地 VMware 上成功部署恢复后，后续就是在 PVE 2 号机上重新部署一遍了，于是又申请开放了几天的端口进行操作。在本地部署踩了一遍坑后，PVE 上又踩了一波新的坑，因为坑太多所以懒得再一一记录了。中途还因为换服务器的问题导致在线注册时的系统检测没过（提示系统运行环境与上次注册时不同，不能注册！），拉了心海软件的客服进群处理，所以你原来能联系到客服的吗。最后补一张心理测评平台进去的图，好像网上搜心理测评都是这个平台。最后总算是结束了这个坑。 然后补一个梳理时间线罢。 day1被拉入群聊，告知需要重启旧心理测评平台day2联系信息办开放 PVE Web 管理界面的访问端口day3端口开放，发现 2 号机失联，1 号机管理界面无法登录，联系信息办先排查线下物理机day4信息办反馈 2 号机坏了 2 个硬盘，强制重启了 2 号机，结果带着 1 号机一起失联day5相关老师发送了原心理测评网站的备份文件day6和前辈去线下抢救服务器，1 号机和 2 号机恢复连接day12根据备份文件在本地 VMware 尝试恢复成功，联系信息办再次开放端口day13端口开放，开始在 1 号机上尝试恢复day141 号机上恢复成功，联系心海客服处理注册问题day15和心海客服联系处理完毕，可以正常使用，下班","tags":["Windows Server","ASP"],"categories":["日常记录"]},{"title":"Docker 安装 Redis","path":"/posts/docker-install-redis/","content":"本文环境 系统：Ubuntu 22.04 终端：腾讯云 OrcaTerm（可使用 Xshell+Xftp 代替） 前言 首先需要安装好 Docker，可以参考Ubuntu 安装 Docker 使用 Docker 需要 root 权限，推荐将用户加入 Docker 用户组（上文中有），这样使用就不需要加上sudo了（但是我是 root，所以文中都没加） Docker Hub 中的 Redis 官方镜像文档 redis - Official Image | Docker Hub 1.寻找镜像在 Docker 仓库中查找 Redis 镜像 1docker search redis 可以看到第一个就是我们需要的镜像 2.拉取镜像在查找到 Redis 的镜像后，就可以进行拉取 1docker pull redis 因为没有指定 Redis 的版本，所以默认拉取最新的版本（即 latest）如果想要拉取指定的版本，可以在拉取时添加版本号（redis:tag），以 Redis 7.2.3 版本为例 1docker pull redis:7.2.3 3.查看镜像拉取完毕后，检查镜像是否安装完成 12## 查看所有镜像docker images 可以看到已经有 Redis 的镜像了 4.创建容器并启动通过 Docker 安装 Redis 和直接安装 Redis 的一处不同在于通过 Docker 创建的 Redis 容器中是没有redis.conf配置文件的Redis 可以在没有配置文件的情况下使用内置的默认配置启动，但是这种方法只建议在测试和开发的时候使用，当然 Redis 官方也给我们提供了使用配置文件启动 Redis 容器的方法，因此下面介绍两种方法 一、无配置文件简易版1234567# 容器名称、端口、密码均可自行指定docker run \\ --name redis \\ -p 6379:6379 \\ -- requirepass 123456 \\ -d \\ redis 参数说明： --name redis：指定容器的名称为 redis（可以自己指定） -p 6379:6379：将容器的 6379（右边的）端口映射到宿主机的 6379（左边的）端口（前提是不被占用） -- requirepass 123456：设置密码为 123456 如果不想设置密码可以不使用该参数，但是需要注意为了便于容器外能够访问到该容器内的 Redis，其protected mode（保护模式）默认关闭，这意味着如果你将端口暴露在主机外部，它将在没有密码的情况下对所有人开放 -d：以后台的方式运行 redis:tag：指定创建容器的镜像（:tag指定版本，不加默认最新版） 建议创建容器时使用:tag指定版本，可以使用docker images查看镜像的版本，以免过段时间版本更新后导致现在拉取的镜像已经不是最新版本，又重新拉取一个最新版本的镜像进行容器创建 执行后返回的一长串是容器 id 说明该方式创建的容器适合在测试环境使用，简单方便，但是没法通过配置文件去自定义一些配置，而且数据容易丢失，一旦关机或者容器挂了数据就没了，因为是存在缓存里的 二、 配置文件挂载版准备配置文件先准备一个目录用于存放配置文件（用于后面创建容器时挂载配置），目录可以自己选择，通常选择放在用户的主目录下的一个子目录中，好处是每个用户都有自己的挂载目录，可以隔离不同用户的数据但是因为我的云服务器只有我一个人在玩，平常都是直接用的 root 用户，所以直接在根目录下创建了一个/data目录用来存放 Docker 容器的挂载配置和数据，因此我这边准备的目录在/data/redis/ 12# 创建用于 Redis 容器配置文件挂载的目录mkdir /data/redis/conf 然后提前在该目录下新建一个redis.conf文件 12# 新建 redis.conf 文件touch /data/redis/conf/redis.conf 创建完配置文件后，直接去 Redis 的官网找对应版本的配置文件 Redis configuration | Redis往下滑可以找到各个不同版本的配置文件因为我拉取的是最新版本的镜像，所以这边选择第一个 7.2 版本（最新版本），根据拉取 Redis 的实际版本选择即可点进去后就可以看到配置文件的内容，本文就不具体介绍了，可以自行了解直接ctrl+a + ctrl+c复制，然后用 vim 打开我们之前准备好的redis.conf文件 1vim /data/redis/conf/redis.conf 输入i进入编辑模式，ctrl+v粘贴，然后别急着保存退出，还需要修改一些配置 编辑配置文件修改配置主要是为了能在宿主机访问容器中的 Redis，因为配置文件中的protected-mode（保护模式）设置是开启的 保护模式：如果符合下面两个条件（不是之一）则无法被外部访问 没有明确使用 bind 绑定某个 ip 地址 没有设置密码 取消本地绑定&#x2F;绑定某个 ip 地址定位到bind 127.0.0.1 -::1，将其注释bind 127.0.0.1 -::1的意思是限制只能本地访问（即只有该容器内部才可以访问，容器外的宿主机也访问不了），注释掉表示允许所有 ip 访问当然也可以选择绑定指定 ip 允许其访问 设置密码定位到## requirepass foobared，取消其注释，并将foobared修改为你想设置的密码比如我这边就将密码设置为了123456如果不想设置密码还想被外部宿主机访问，那就需要另外定位到protected-mode yes，将参数修改为no（解除保护模式的限制） 其他配置12345## 默认 no，表示不以守护进程启动，Docker 部署不需要改为 yes，因为 docker run -d 本身就是后台启动daemonize no## 开启持久化，根据需求选择是否开启，会将数据持久化到容器中的 /data 目录appendonly yes 更多其他配置根据自己需求修改，本文不多介绍 以配置文件方式创建容器并启动12345678910# 容器名称、端口、挂载目录均可自行指定docker run \\ --name redis \\ -p 6379:6379 \\ -v /data/redis/conf:/usr/local/etc/redis \\ # 如果配置了 appendonly yes（持久化）可以选择挂载该目录 -v /data/redis/data:/data \\ -d \\ redis \\ redis-server /usr/local/etc/redis/redis.conf 简易版的参数就不再介绍了，说明一下新参数： -v：数据卷挂载 /data/redis/conf:/usr/local/etc/redis：将容器中/usr/local/etc/redis目录挂载到宿主机的/data/redis/conf目录 /data/redis/conf目录即之前准备的存放redis.conf文件的目录，这里可以理解为 Docker 容器和宿主机共享该配置文件 /data/redis/data:/data：将容器中/data数据目录挂载到宿主机的/data/redis/data目录 如果开启了持久化，进行挂载可以避免持久化的数据丢失，如果不挂载的话在删除容器后会丢失该容器中持久化的数据，即挂载后即使容器删除，只要宿主机目录中的数据还存在，使用该目录新创建的容器中依旧有原先容器中挂载的数据 如果没有开启持久化也就不需要挂载\\data数据目录了，因为 Redis 的数据都存在缓存里，不开启持久化也不会在该目录下存储数据 宿主机用于挂载的目录（比如我这边的/data/redis/data）可以自行选择，一般就放在配置目录旁边 redis-server /usr/local/etc/redis/redis.conf：以配置文件启动容器，加载容器内的redis.conf文件，实际找到的是挂载在宿主机中配置目录下的reids.conf 返回的一长串是创建的容器 id 6.查看容器检查容器是否创建成功 12# 查看运行中的容器docker ps 可以看到创建的 Redis 容器已经在运行中了我们可以通过 Docker 命令进入 Redis 容器内部 12345# 这里的 redis 是创建容器时自行指定的容器名称docker exec -it redis /bin/bash# 也可以使用容器 id（即上图中的 CONTANINER ID）docker exec -it 7cd1552e2cf5 /bin/bash 进入后就可以和在 linux 中一样使用 Redis 了输入redis-cli -a 123456即可进入 Redis 命令行，-a后面的参数是你设置的密码后续使用和正常 Redis 一样，想要退出 Redis 和容器使用exit命令即可 7.删除容器不能直接删除运行中的容器，因此需要先停止容器再删除 12345# 这里的 redis 是创建容器时自行指定的容器名称# 停止容器docker stop redis# 删除容器docker rm redis 但是可以加上-f参数来强制删除运行中的容器 12# 这里的 redis 是创建容器时自行指定的容器名称docker rm -f redis","tags":["Redis","Docker"],"categories":["日常记录"]},{"title":"Docker 安装 MySQL","path":"/posts/docker-install-mysql/","content":"本文环境 系统：Ubuntu 22.04 终端：腾讯云 OrcaTerm（可使用 Xshell+Xftp 代替） 前言 首先需要安装好 Docker，可以参考Ubuntu 安装 Docker 使用 Docker 需要 root 权限，推荐将用户加入 Docker 用户组（上文中有），这样使用就不需要加上sudo了（但是我是 root，所以文中都没加） Docker Hub 中的 MySQL 官方镜像文档 mysql - Official Image | Docker Hub 1.寻找镜像在 Docker 仓库中查找 MySQL 镜像 1docker search mysql 可以看到第一个就是我们需要的镜像 2.拉取镜像在查找到 MySQL 的镜像后，就可以进行拉取 1docker pull mysql 因为没有指定 MySQL 的版本，所以默认拉取最新的版本（即 latest）如果想要拉取指定的版本，可以在拉取时添加版本号（mysql:tag），以 MySQL 5.7 版本为例 1docker pull mysql:5.7 3.查看镜像拉取完毕后，检查镜像是否安装完成 12# 查看所有镜像docker images 可以看到已经有 MySQL 的镜像了（hello-world 是我在安装完 Docker 测试时拉取的镜像） 4.创建容器并启动12345678910# 容器名称、端口、挂载目录、root 密码均可自行指定docker run \\ --name mysql \\ -p 3306:3306 \\ -v /data/mysql/conf:/etc/mysql/conf.d \\ -v /data/mysql/data:/var/lib/mysql \\ -v /data/mysql/log:/var/log/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -d \\ mysql 参数说明： --name mysql：指定容器的名称为 mysql（可以自己指定） -p 3306:3306：将容器的 3306（右边的）端口挂载到宿主机的 3306（左边的）端口（前提是不被占用） -v：将相关目录挂载到宿主机防止数据丢失，如果不挂载的话在删除容器后会丢失存储的数据，即挂载后即使容器删除，只要宿主机目录中的数据还存在，使用该目录新创建的容器中依旧有原先容器中挂载的数据 注： 实际宿主机中用于挂载的目录根据自己需求设置，如果只是开发测试环境可以选择不挂载（用完就删不留痕迹，正合我意），但是配置目录还是推荐挂载，方便修改配置 挂载目录通常选择放在用户的主目录下的一个子目录中，好处是每个用户都有自己的挂载目录，可以隔离不同用户的数据，但是因为我的云服务器只有我一个人在玩，平常都是直接用的 root 用户，所以直接在根目录下创建了一个/data目录用来存放 Docker 容器的挂载配置和数据，MySQL 容器的就都挂载在/data/mysql目录下了 /data/mysql/conf:/etc/mysql/conf.d：将容器中/etc/mysql/conf.d配置目录挂载到宿主机的/data/mysql/conf目录 想要修改 MySQL 配置可以直接在宿主机的配置目录下添加一份自定义的my.cnf配置文件，该文件中的配置优先级高于 MySQL 的默认配置（容器中 MySQL 的配置文件路径位于/etc/my.cnf） 也可以提前编辑好my.cnf文件，创建的容器会按你挂载目录中的自定义配置启动 /data/mysql/data:/var/lib/mysql：将容器中/var/lib/mysql数据目录挂载到宿主机的/data/mysql/data目录 /data/mysql/log:/var/log/mysql：将容器中/var/log/mysql日志目录挂载到宿主机的/data/mysql/log目录 -e MYSQL_ROOT_PASSWORD=123456：初始化 MySQL root 用户的密码为 123456 -d：以后台的方式运行 mysql:tag：指定创建容器的镜像（:tag指定版本，不加默认最新版） 建议创建容器时使用:tag指定版本，可以使用docker images查看镜像的版本，以免过段时间版本更新后导致现在拉取的镜像已经不是最新版本，又重新拉取一个最新版本的镜像进行容器创建 返回的一长串是创建的容器 id 5.查看容器检查容器是否创建成功 12# 查看运行中的容器docker ps 可以看到创建的 MySQL 容器已经在运行中了我们可以通过 Docker 命令进入 MySQL 容器内部 12345# 这里的 mysql 是创建容器时自行指定的容器名称docker exec -it mysql /bin/bash# 也可以使用容器 id（即上图中的 CONTANINER ID）docker exec -it 01c4a501d5c4 /bin/bash 进入后就可以和在 linux 中一样使用 MySQL 了查看 MySQL 版本号 1mysql --version 注：写本文时的最新版本为 8.2.0输入mysql -u root -p后再输入密码即可进入 MySQL 命令行后续使用和正常 MySQL 一样，想要退出 MySQL 和容器使用exit命令即可 6.删除容器不能直接删除运行中的容器，因此需要先停止容器再删除 12345# 这里的 mysql 是创建容器时自行指定的容器名称# 停止容器docker stop mysql# 删除容器docker rm mysql 但是可以加上-f参数来强制删除运行中的容器 12# 这里的 mysql 是创建容器时自行指定的容器名称docker rm -f mysql 其他时区问题问题描述进入 MySQL 命令行后使用下面命令查看当前时间 1select now(); 会发现 MySQL 中时间比系统时间少了 8 个小时，因为 MySQL 的时区并不是我们所在的东八区（即北京时间） 解决方法一：命令行中修改MySQL 中的系统时区，分为全局时区和当前会话的时区，如果当前会话不指定时区，默认使用全局时区，可以使用下面的命令将全局时区修改为东八区（即北京时间） 1234set global time_zone = &#x27;+8.00&#x27;;# 修改当前会话的时区（相当于临时修改）# set time_zone = &#x27;+8.00&#x27;; 如果想要立即生效需要执行 1flush privileges; 再次select now();查看时间会发现已经是东八区的时间了 二：修改 my.cnf 配置文件容器中修改可以编辑容器中 MySQL 的my.cnf（位于/etc/my.cnf）配置文件然后在 [mysqld] 区域加上default-time_zone = &#39;+8:00&#39; 123456[mysqld]......default-time_zone = &#x27;+8:00&#x27;......[client]...... 然后重启 MySQL注：MySQL 容器中没有 vim，如果想要编辑需要先安装 vim（所以我没有演示） 通过挂载的配置文件修改如果在创建容器时将容器中的配置目录挂载到了宿主机，那就可以直接编辑宿主机中的配置文件进行修改了首先在配置目录挂载的宿主机目录下新建一个my.cnf文件，然后使用 vim 编辑 123456# 进入你自己挂载的宿主机配置目录cd /data/mysql/conf# 新建一个 my.cnf 文件touch my.cnf# 使用 vim 编辑vim my.cnf 添加下面配置内容（不会还有人不会 vim 吧） 12[mysqld]default-time-zone = &#x27;+08:00&#x27; 保存退出后重启容器即可 123# 这里的 mysql 是创建容器时自行指定的容器名称# 重启 MySQLdocker restart mysql 之后再次进入容器中的 MySQL，通过select now();查看时间会发现已经是东八区的时间了 注：想要修改其他配置也可以按照相同的方法在宿主机编辑配置文件，并且只要创建容器时挂载宿主机的配置目录不变，即使删除当前容器重开一个，修改的配置也依旧在","tags":["MySQL","Docker"],"categories":["日常记录"]},{"title":"Ubuntu 安装 Docker","path":"/posts/ubuntu-install-docker/","content":"本文环境 云服务器：阿里云（不同厂商云服务器上的操作基本相同） 系统：Ubuntu 22.04 终端：腾讯云 OrcaTerm（可使用 Xshell+Xftp 代替） 本文全部 shell 终端指令均执行在 root 用户下（命令前的sudo可不加），如果是非 root 用户也许本文中某些没加sudo命令也要加上sudo 本文不具体介绍 Docker下面步骤均根据写本文时最新的官方文档 安装 docker使用 APT 安装首次在新的主机上安装 Docker Engine 之前，需要先设置 Docker 的软件源，之后就可以通过软件源安装和更新 Docker 1.设置 Docker 的软件源依次执行以下命令 123456# 更新软件包列表sudo apt-get update# 安装相关依赖sudo apt-get install ca-certificates curl gnupg# 创建目录用于存放软件源的 GPG 密钥文件sudo install -m 0755 -d /etc/apt/keyrings 鉴于国内网络问题，建议使用国内源，官方源请在注释中查看 1234567891011121314151617181920212223# 添加软件源的 GPG 密钥（阿里镜像源）curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg# 官方源# curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg# 修改 docker.gpg 的文件权限sudo chmod a+r /etc/apt/keyrings/docker.gpg# 将 docker 软件源添加到 apt 源（阿里镜像源）echo \\ &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.aliyun.com/docker-ce/linux/ubuntu \\ $(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;) stable&quot; | \\ sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null# 官方源# echo \\# &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\# $(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;) stable&quot; | \\# sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null# 重新更新软件包列表sudo apt-get update 2.安装 Docker执行以下命令 1sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 使用脚本安装Docker 在 https://get.docker.com/ 提供了一个方便的脚本，可以在开发环境中非交互式地安装 Docker，不推荐在生产环境使用，但对于创建适合自己需求的配置脚本非常有用，该脚本的源代码开源在 GitHub 上的 docker-install 仓库 12curl -fsSL https://get.docker.com -o get-docker.shsudo sh get-docker.sh 这个示例会从 https://get.docker.com/ 下载脚本并运行，在 Linux 上安装最新稳定版本的 Docker 可以使用--dry-run选项运行脚本，以了解脚本在调用时会运行哪些步骤 curl -fsSL https://get.docker.com -o get-docker.shsudo sh .&#x2F;get-docker.sh –dry-run 如果想安装最新的预发布版本，可以通过测试通道 12curl -fsSL https://test.docker.com -o test-docker.shsudo sh test-docker.sh 查看 Docker 状态安装完成后，Docker 服务将会自动启动，可以输入下面命令查看 Docker 服务状态 1sudo systemctl status docker 输出显示 Docker 正常运行 测试 Docker 是否安装正确1sudo docker run hello-world 若能正常输出以下信息，则说明安装成功 1234567891011121314151617181920212223242526Unable to find image &#x27;hello-world:latest&#x27; locallylatest: Pulling from library/hello-world719385e32844: Pull completeDigest: sha256:c79d06dfdfd3d3eb04cafd0dc2bacab0992ebc243e083cabe208bac4dd7759e0Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 停止 Docker 服务希望通过执行以下命令停止 Docker 服务时 1sudo systemctl stop docker 会提示 12Warning: Stopping docker.service, but it can still be activated by: docker.socket 此时再次查看 Docker 状态会发现有一个TriggeredBy: docker.socket依旧在运行实际上是 Docker 在关闭状态下被访问的自动唤醒机制，即在执行任意 Docker 命令时会自动启动如果不希望 Docker 被自动唤醒，在停止 Docker 服务时应该依次执行下面两条命令 12sudo systemctl stop docker.socketsudo systemctl stop docker 附上启动的命令 1sudo systemctl start docker 注：docker.socket也会一起跟着重启 卸载 Docker 卸载 Docker Engine, CLI, containerd 和 Docker Compose 软件包 1sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin docker-ce-rootless-extras 主机上的镜像、容器、卷或自定义配置文件不会自动删除，因此要手动删除所有的镜像、容器和卷 12sudo rm -rf /var/lib/dockersudo rm -rf /var/lib/containerd 以及相关编辑过的配置文件 非 root 用户管理 DockerDocker 守护进程绑定Unix socket而不是 TCP 端口，默认情况下，Unix socket的所有者是 root 用户，其他用户想要访问只能使用 sudo，Docker 守护进程始终以 root 用户身份运行出于安全考虑，一般 Linux 系统上不会直接使用 root 用户，如果希望非 root 用户能够不通过 sudo 访问，可以创建一个名为docker的 Unix 组，并将需要使用 Docker 的用户添加进用户组 创建docker组注：Ubuntu 在使用 apt 安装 Docker 时会自动创建该组 1sudo groupadd docker 将用户添加到docker组12# 将 $USER 修改为你要添加的用户名sudo usermod -aG docker $USER 刷新组成员权限重新登陆或运行以下命令 1newgrp docker 测试不使用 sudo 运行以下命令（使用添加到docker用户组的用户） 1docker run hello-world 正常输出以下信息，则说明添加成功 1234567891011121314151617181920Hello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 注：如果没有在测试 Docker 是否安装正确时运行过该命令，则会多出拉取镜像的信息 可能出现的问题12WARNING: Error loading config file: /home/user/.docker/config.json -stat /home/user/.docker/config.json: permission denied 原因：当前用户没有加入docker用户组解决方法：按上述流程将该用户加入用户组，并依次执行以下命令 123# 将 $USER 修改为当前用户的用户名sudo chown &quot;$USER&quot;:&quot;$USER&quot; /home/&quot;$USER&quot;/.docker -Rsudo chmod g+rwx &quot;$HOME/.docker&quot; -R","tags":["Docker","Ubuntu"],"categories":["日常记录"]},{"title":"Ubuntu 部署 Gin+Vue 前后端分离项目","path":"/posts/ubuntu-deploy-gin-and-vue-project/","content":"本文环境 系统：Ubuntu 22.04 LTS 终端：腾讯云 OrcaTerm（可使用 Xshell+Xftp 代替） 本文全部 shell 终端指令均执行在 root 用户下（命令前的sudo可不加），如果是非 root 用户也许本文中某些没加sudo命令也要加上sudo 后端前提如果后端服务需要服务器上的数据库，需要提前准备好附上 MySQL 和 Redis 的安装配置Ubuntu 安装 MySQL 并配置远程连接Ubuntu 安装 Redis 并配置远程连接 部署Go 项目打包Go 支持跨平台编译，因此我们可以很轻松的将当前平台的 Go 项目打包成能够在 Linux 运行的文件进入到 main.go 的文件目录下，执行以下命令（打包前记得将环境或者配置修改为服务器的） Windows 系统下1234SET CGO_ENABLE=0SET GOOS=linuxSET GOARCH=amd64go build main.go 注：在 cmd 中执行，PowerShell 中不知道为什么不起作用（编译出来还是 Windows 下的 .exe 文件） Mac 系统下1CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.go Linux 系统下1go build main.go 参数说明123CGO_ENABLE 是否开启 CGO，默认为 1 开启 CGO（不支持交叉编译），0 表示关闭GOARCH 表示目标平台的体系架构GOOS 表示目标平台的操作系统 Linux、Windows、Darwin（Mac） 等待编译完成后就可以得到一个不带后缀的二进制文件，默认名为main如果想要指定输出的文件名，可以在 go build 时加上 -o 参数，如 1go build -o cms main.go cms就是我指定输出的文件名，也是我本次部署使用的打包文件 将打包文件上传到服务器可以使用 xftp 上传打包文件至服务器，也可以使用对应云服务器厂商自带的 WebShell（我使用的是腾讯云的 OrcaTerm）这边将打包好的 cms 文件上传到/opt/go/cms文件夹下（文件路径可以自己选择）注：如果有配置文件也需要一起上传 修改文件权限橙色方框中可以看到当前的权限是 640也可以cd /opt/go/cms通过ls -l命令查看想要运行该文件，我们至少需要拥有执行该文件的权利，执行下面的命令 1chmod 740 cms 将执行权限赋予 root 用户（实际根据自己需求赋予不同用户组权限）这时候我们其实已经可以运行了，输入./cms去运行我们编译好的文件没有报错说明已经启动成功了没有别的信息显示是因为部署在正式环境中，设置了gin.SetMode(gin.ReleaseMode)（Gin 的生产环境模式） 云服务器放行端口想要访问后端服务，需要将服务对应运行的端口（比如我这边就是默认跑在8080端口）放开，不然在外部是访问不到服务器上的后端服务的在云服务器厂商找到对应云服务器的防火墙，并放行 8080 端口（对应你自己后端服务的运行端口）这里以腾讯云为例，不同厂商基本都大同小异有这样一条记录就说明 8080 端口已经放行了 测试访问可以通过 Apifox 测试能否正常访问可以看到能够正常访问并响应也可以看到 Gin 自己 Logger 中间件的日志 使用 Systemd 守护进程现在我们希望我们的后端服务能在后台运行，并且不会随着我们终端的关闭而退出，这里就需要用到守护进程，守护进程是一个在后台运行并且不受任何终端控制的进程，这里我们选择使用 systemd 守护进程注：本文不详细讲解 systemd，建议自行查阅相关知识 创建 service 文件先CTRL+C结束启动的服务回到 linux 命令行在/etc/systemd/system路径下新建一个cms.service文件，文件名可以自己取，文件后缀.service 1touch /etc/systemd/system/cms.service 编辑 service 文件使用 vim 打开编辑该文件 1vim /etc/systemd/system/cms.service 输入i进入编辑模式（在英文输入法下） 123456789101112[Unit]Description=cms（contact manager system）backend server daemon[Service]Type=simpleExecStart=/opt/go/cms/cmsWorkingDirectory=/opt/go/cmsRestart=alwaysRestartSec=10s[Install]WantedBy=multi-user.target 参数解释（想要了解更多参数和配置可以参考这篇 利用 Systemd 守护进程 | 派大星的石头屋） Unit Description：简短描述 Service Type：启动类型，simple表示ExecStart字段启动的进程为主进程 ExecStart：启动当前服务的命令，即打包文件的具体路径 WorkingDirectory：指定服务运行目录，即打包文件所在的文件夹 Restart：定义何种情况 Systemd 会自动重启当前服务，always表示总是重启 RestartSec：自动重启当前服务间隔的秒数 Install WantedBy：它的值是一个或多个 Target，当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面以 Target 名 + .wants后缀构成的子目录中 将Description、ExecStart和WorkingDirectory修改为自己的即可然后将修改完的代码粘贴到我们正在编辑的文件中按Esc退出编辑模式，输入:wq（包括:，在英文输入法下）后回车即保存退出 启动 service输入下面命令即可启动后端服务 1sudo systemctl start cms # cms 对应修改为你之前创建的 service 文件名 然后可以通过下面命令查看服务状态 1sudo systemctl status cms # cms 对应修改为你之前创建的 service 文件名 active (running)说明服务已经成功启动，即我们的后端服务已经在后台运行了附上其他相关命令 12345678# 停止sudo systemctl stop cms # cms 对应修改为你之前创建的 service 文件名# 重启sudo systemctl restart cms # cms 对应修改为你之前创建的 service 文件名# 设置开机自启动sudo systemctl enable cms # cms 对应修改为你之前创建的 service 文件名# 取消开机自启动sudo systemctl disable cms # cms 对应修改为你之前创建的 service 文件名 Nginx 反向代理，将域名映射到 ip:port（可选）完成部署后后端服务已经可以通过服务器的 ip 地址和端口进行访问如果想实现将某个域名映射到 ip:port，即通过访问域名实现对后端服务的访问，我们需要用 Nginx 进行一个反代（因为域名只能绑定 ip）注：本文不详细讲解 Nginx，建议自行查阅相关知识 前提需要有一个解析到该服务器的域名，可以创建一个子域名 安装 NginxUbuntu 下输入下面命令即可安装 Nginx 1sudo apt install nginx 中间会询问是否继续安装，输入y回车即可等待安装完成，可以输入下面命令查看 Nginx 服务状态 1sudo systemctl status nginx 安装完成后，Nginx 服务会自己启动，可以看到 Nginx 服务已经正常运行 配置文件部分说明Nginx 配置文件路径默认在/etc/nginx可以输入下面命令查看 Nginx 配置文件位置 1nginx -t 红框中即 Nginx 主要配置文件所在的位置cd /etc/nginx到 Nginx 目录下，ls查看结构 nginx.conf 即 Nginx 的主要配置文件，可以直接在该文件中进行修改（大多数教程也是这么做的），但是如果以后部署的服务多起来，都放在一个配置文件中会显得混乱和臃肿 新版本的 Nginx 允许我们在 nginx.conf 中导入其他文件夹中的 .conf 文件，因此我们可以针对不同的服务，建立不同的 conf 配置文件，方便管理 而 Nginx 已经为我们建好了一个文件夹，并且导入到了配置文件中，即 conf.d 文件夹，我们可以直接在该文件夹下新建和添加配置文件 注：nginx.conf 中有关于 Nginx 整体的相关配置，但这里不多介绍，我们也不去修改 新建配置文件在/etc/nginx/conf.d路径下新建一个cms.conf文件，文件名可以自己取，文件后缀.conf 1touch /etc/nginx/conf.d/cms.conf 编辑配置文件使用 vim 打开编辑该文件 1vim /etc/nginx/conf.d/cms.conf 输入i进入编辑模式（在英文输入法下） 12345678910server &#123; listen 80; # 服务端绑定的域名 server_name cms-back.ximo210.top; location / &#123; # 需要映射到的端口 proxy_pass http://localhost:8080; &#125;&#125; 在server_name填入你要绑定的域名，比如我这边就是cms-back.ximo210.top 在proxy_pass填入你需要映射到的端口，比如我需要的是 8080 端口 listen 80表示的是监听的端口，因为 http 请求默认访问的是 80 端口，举例来说当我们在访问www.baidu.com的时候其实访问的是www.baidu.com:80，不过 80 可以省略 将上面的代码理解一下就是当我直接访问cms-back.ximo210.top时，Nginx 会监听到 80 端口有请求，然后做一个反向代理将这个请求发送到 8080 端口，实现将对域名的请求映射到 ip:port将修改完的代码粘贴进配置文件按Esc退出编辑模式，输入:wq（包括:，在英文输入法下）后回车即保存退出 重启 Nginx输入下面命令重启 Nginx 以应用修改后的配置文件 1sudo nginx -s reload 测试访问注：需要确保云服务器 80 端口放开依旧是利用 Apifox 进行测试可以看到能够直接用域名进行访问了 配置 SSL 证书（可选）前面只能用 http 进行访问，现在我想要用 https 进行访问，并且在使用 http 访问时强制跳转 https 前提 有对应域名的 SSL 证书，可以去申请免费的 SSL 证书 转换 SSL 证书，主要需要.crt和.key文件，具体可以自行搜索 上传证书文件在/etc/nginx目录下新建一个 cert 文件夹存放证书 12# 在 /etc/nginx 路径下执行mkdir cert 将转换得到的.crt和.key文件上传到服务器的/etc/nginx/cert文件夹下 编辑配置文件依旧是编辑/etc/nginx/conf.d/cms.conf文件 1vim /etc/nginx/conf.d/cms.conf 输入i进入编辑模式（在英文输入法下） 1234567891011121314151617181920212223242526272829server &#123; listen 80; # 服务端绑定的域名 server_name cms-back.ximo210.top; # 强制跳转https rewrite ^/(.*) https://$server_name$request_uri? permanent;&#125;server &#123; # SSL 默认访问端口号为 443 listen 443 ssl; # 请填写绑定证书的域名 server_name cms-back.ximo210.top; # 请填写证书文件的相对路径或绝对路径 ssl_certificate /etc/nginx/cert/cms-back.crt; # 请填写私钥文件的相对路径或绝对路径 ssl_certificate_key /etc/nginx/cert/cms-back.key; ssl_session_timeout 5m; # 请按照以下协议配置 ssl_protocols TLSv1.2 TLSv1.3; # 请按照以下套件配置，配置加密套件，写法遵循 openssl 标准。 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / &#123; # 请填写后端运行的端口 proxy_pass http://localhost:8080; &#125;&#125; 用上述代码覆盖原先的配置并将红框部分修改为你自己的配置然后按Esc退出编辑模式，输入:wq（包括:，在英文输入法下）后回车即保存退出 重启 Nginx先检查配置有无问题 1nginx -t 没有问题则sudo nginx -s reload重启 Nginx 以应用修改 测试访问注：需要确保云服务器 80 和 443 端口放开实际在访问 http 时也会强制跳转到 https，这里就不做演示了 前端前提已经部署完后端并且能够正常访问 Vue 项目打包在 Vue 项目的根目录执行下面的命令，打包成 dist 目录（打包前记得将环境或者配置修改为服务器的） 1npm run build 将 dist 目录重命名为 cms（名字自取） 将打包文件上传到服务器可以使用 xftp 上传打包文件至服务器，也可以使用对应云服务器厂商自带的 WebShell（我使用的是腾讯云的 OrcaTerm）这边将打包好的 cms 文件上传到/var/www文件夹下（文件路径可以自己选择） 修改文件权限将 cms 目录的权限修改为 755，确保 Nginx 对该文件有访问权限 12cd /var/wwwchmod -R 755 cms 安装 Nginx注：如果是从后端 Nginx 部分看过来的，可以直接跳到编辑配置文件，将内容添加到原有配置的后面即可Ubuntu 下输入下面命令即可安装 Nginx 1sudo apt install nginx 中间会询问是否继续安装，输入y回车即可等待安装完成，可以输入下面命令查看 Nginx 服务状态 1sudo systemctl status nginx 安装完成后，Nginx 服务会自己启动，可以看到 Nginx 服务已经正常运行 配置文件部分说明Nginx 配置文件路径默认在/etc/nginx可以输入下面命令查看 Nginx 配置文件位置 1nginx -t 红框中即 Nginx 主要配置文件所在的位置cd /etc/nginx到 Nginx 目录下，ls查看结构 nginx.conf 即 Nginx 的主要配置文件，可以直接在该文件中进行修改（大多数教程也是这么做的），但是如果以后部署的服务多起来，都放在一个配置文件中则会显得混乱和臃肿 新版本的 Nginx 允许我们在 nginx.conf 中导入其他文件夹中的 .conf 文件，因此我们可以针对不同的服务，建立不同的 conf 配置文件，方便管理 而 Nginx 已经为我们建好了一个文件夹，并且导入到了配置文件中，即 conf.d 文件夹，我们可以直接在该文件夹下新建和添加配置文件 注：nginx.conf 中有关于 Nginx 整体的相关配置，但这里不多介绍，我们也不去修改 新建配置文件在/etc/nginx/conf.d路径下新建一个cms.conf文件，文件名可以自己取，文件后缀.conf 1touch /etc/nginx/conf.d/cms.conf 编辑配置文件使用 vim 打开编辑该文件 1vim /etc/nginx/conf.d/cms.conf 输入i进入编辑模式（在英文输入法下） 12345678910111213141516171819202122232425server &#123; # 监听的端口号（即想要访问的前端服务的端口） listen 5173; server_name localhost; location / &#123; # 打包文件的路径 root /var/www/cms; index index.html; # 此处的 @router 实际上是引用下面的转发，否则在 Vue 路由刷新时可能会抛出 404 try_files $uri $uri/ @router; &#125; # 由于路由的资源不一定是真实的路径，无法找到具体文件 # 所以需要将请求重写到 index.html 中，然后交给真正的 Vue 路由处理请求资源 location @router &#123; rewrite ^.*$ /index.html last; &#125; # 将所有 ip:port/api 的请求转发到对应的后端地址（根据自己实际情况修改） location /api &#123; # 填写后端服务的端口（如果不是同一台服务器则填写对应服务器的地址） proxy_pass http://localhost:8080; &#125;&#125; 将红框部分的代码修改为你自己的配置后写进配置文件按Esc退出编辑模式，输入:wq（包括:，在英文输入法下）后回车即保存退出 重启 Nginx输入下面命令重启 Nginx 以应用修改后的配置文件 1sudo nginx -s reload 云服务器放行端口想要访问前端页面，需要将服务对应运行的端口（比如我这边就是在5173端口）放开，不然直接访问是访问不到的在云服务器厂商找到对应云服务器的防火墙，并放行 5173 端口（对应你自己前端的运行端口）这里以腾讯云为例，不同厂商基本都大同小异有这样一条记录就说明 5173 端口已经放行了 测试访问在浏览器输入ip:5173（对应你自己的ip:port）可以看到能正常访问 绑定域名（可选）前面是直接使用 ip:port 去访问前端，现在我想要通过域名去访问 前提需要有一个解析到该服务器的域名（可以创建一个子域名） 编辑配置文件依旧是编辑/etc/nginx/conf.d/cms.conf文件 1vim /etc/nginx/conf.d/cms.conf 输入i进入编辑模式（在英文输入法下） 12345678910111213141516171819202122232425server &#123; listen 80; # 前端绑定的域名 server_name cms.ximo210.top; location / &#123; # 打包文件的路径 root /var/www/cms; index index.html; # 此处的 @router 实际上是引用下面的转发，否则在 Vue 路由刷新时可能会抛出 404 try_files $uri $uri/ @router; &#125; # 由于路由的资源不一定是真实的路径，无法找到具体文件 # 所以需要将请求重写到 index.html 中，然后交给真正的 Vue 路由处理请求资源 location @router &#123; rewrite ^.*$ /index.html last; &#125; # 将所有 ip:port/api 的请求转发到对应的后端地址（根据自己实际情况修改） location /api &#123; # 填写后端服务的端口（如果不是同一台服务器则填写对应服务器的地址） proxy_pass http://localhost:8080; &#125;&#125; 在原先的基础上修改 listen修改为 80，表示的是监听的端口，因为 http 请求默认访问的是 80 端口，举例来说当我们在访问www.baidu.com的时候其实访问的是www.baidu.com:80，不过 80 可以省略 在server_name填入你要绑定的域名，比如我这边就是cms.ximo210.top 修改完后按Esc退出编辑模式，输入:wq（包括:，在英文输入法下）后回车即保存退出 测试访问sudo nginx -s reload重启 Nginx 以应用修改注：需要确保云服务器 80 端口放开在浏览器输入http://cms.ximo210.top（对应你自己的域名）可以看到能正常访问 配置 SSL 证书（可选）前面只能用 http 进行访问，现在我想要用 https 进行访问，并且在使用 http 访问时强制跳转 https 前提 有对应域名的 SSL 证书，可以去申请免费的 SSL 证书 转换 SSL 证书，主要需要.crt和.key文件，具体可以自行搜索 注：如果配置了后端域名的 SSL 证书，需要另外再申请一个给当前前端的域名 上传证书文件在/etc/nginx目录下新建一个 cert 文件夹存放证书 12# 在 /etc/nginx 路径下执行mkdir cert 将转换得到的.crt和.key文件上传到服务器的/etc/nginx/cert文件下 编辑配置文件依旧是编辑/etc/nginx/conf.d/cms.conf文件 1vim /etc/nginx/conf.d/cms.conf 输入i进入编辑模式（在英文输入法下） 1234567891011121314151617181920212223242526272829303132333435363738394041424344server &#123; listen 80; # 前端绑定的域名 server_name cms.ximo210.top; # 强制跳转https rewrite ^/(.*) https://$server_name$request_uri? permanent;&#125;server &#123; # SSL 默认访问端口号为 443 listen 443 ssl; # 请填写绑定证书的域名 server_name cms.ximo210.top; # 请填写证书文件的相对路径或绝对路径 ssl_certificate /etc/nginx/cert/cms.crt; # 请填写私钥文件的相对路径或绝对路径 ssl_certificate_key /etc/nginx/cert/cms.key; ssl_session_timeout 5m; # 请按照以下协议配置 ssl_protocols TLSv1.2 TLSv1.3; # 请按照以下套件配置，配置加密套件，写法遵循 openssl 标准。 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / &#123; # 打包文件的路径 root /var/www/cms; index index.html; # 此处的 @router 实际上是引用下面的转发，否则在 Vue 路由刷新时可能会抛出 404 try_files $uri $uri/ @router; &#125; # 由于路由的资源不一定是真实的路径，无法找到具体文件 # 所以需要将请求重写到 index.html 中，然后交给真正的 Vue 路由处理请求资源 location @router &#123; rewrite ^.*$ /index.html last; &#125; # 将所有 ip:port/api 的请求转发到对应的后端地址（根据自己实际情况修改） location /api &#123; # 填写后端服务的端口（如果不是同一台服务器则填写对应服务器的地址） proxy_pass http://localhost:8080; &#125;&#125; 用上述代码覆盖原先的配置并将红框部分修改为你自己的配置然后按Esc退出编辑模式，输入:wq（包括:，在英文输入法下）后回车即保存退出 测试访问sudo nginx -s reload重启 Nginx 以应用修改注：需要确保云服务器 80 和 443 端口放开在浏览器输入https://cms.ximo210.top（对应你自己的域名）可以看到能正常访问实际在访问 http 时也会强制跳转到 https，这里就不做演示了","tags":["Ubuntu","Gin","Vue"],"categories":["日常记录"]},{"title":"Ubuntu 安装 Redis 并配置远程连接","path":"/posts/ubuntu-install-redis/","content":"本文环境 系统：Ubuntu 22.04 LTS 终端：腾讯云 OrcaTerm（可使用 Xshell+Xftp 代替） 本文全部 shell 终端指令均执行在 root 用户下（命令前的sudo可不加），如果是非 root 用户也许本文中某些没加sudo命令也要加上sudo 一、安装 Redis1.更新软件包列表1sudo apt update 2.查看是否安装 Redis1dpkg -l | grep redis 如果输入上述命令后没有任何的输出（如上图），则说明没有安装 Redis 3.安装 Redis1sudo apt install redis-server 这里列出了软件包的相关信息并询问你是否继续安装输入y后回车确定继续安装等待安装完后再输入第 2 步的命令查看 Redis 是否已经安装输出如上图，说明 Redis 已经安装成功 安装的 Redis 版本默认为当前 apt 源中最新的稳定版本，可以输入下面的命令查看 Redis 版本 1redis-server -v 注：写本文时的版本为 6.0.16 4.查看 Redis 状态一旦安装完成，Redis 服务将会自动启动，想要查看 Redis 服务运行状态可以输入下面命令查看 1sudo systemctl status redis 输出显示 Redis 服务已经被启动，并且正在运行 5.启动、重启、停止 Redis 服务的命令上一步的命令可以用来查看 Redis 服务的运行状态，下面是启动、重启、停止命令 123456# 启动sudo systemctl start redis# 停止sudo systemctl stop redis# 重启sudo systemctl restart redis 停止和启动命令的演示 6.测试 Redis输入下面命令连接到 Redis 服务器 1redis-cli 使用乒乓来测试连通性，输入ping返回pong说明成功！退出 1exit 二、配置 Redis 远程连接配置 Redis 主要是对配置文件 redis.conf 进行修改，默认位置在 &#x2F;etc&#x2F;redis&#x2F;redis.conf 1.查找 Redis 配置文件使用之前的sudo systemctl status redis命令查看 Redis 服务的状态可以找到这样一个文件然后使用下面的命令查看该文件 1cat /lib/systemd/system/redis-server.service 就可以找到我们 redis.conf 文件所在的位置 2.编辑配置文件使用 vim 编辑 redis.conf 文件 1vim /etc/redis/redis.conf 说明Redis 默认开启保护模式，并且绑定了本地，也就是只有云服务器本地才能连接并操作 Redis 保护模式：如果符合下面两个条件（不是之一）则无法被远程连接 没有明确使用 bind 绑定某个 ip 地址 没有设置密码 想要实现远程连接主要有三种方案 取消本地绑定（可以被任何 ip 访问），设置密码 明确绑定某个 ip 地址，设置密码（可选） 取消本地绑定（可以被任何 ip 访问），关闭保护模式 取消本地绑定&#x2F;绑定某个 ip 地址移动光标定位到bind 127.0.0.1 ::1输入i进入编辑模式（在英文输入法下）bind 127.0.0.1 ::1的意思是只接受本机的访问请求 如果想取消本地绑定（可以被任何 ip 访问） 将该行注释掉（在前面加#，即## bind 127.0.0.1 ::1），表示接受任何 ip 地址的访问 如果想明确绑定某个 ip 地址 将127.0.0.1替换为指定的 ip 地址即可 设置密码移动光标定位到## requirepass foobared取消该行注释（删除#），并将foobared修改为你想要设置的密码如 123456 就是我设置的密码配置修改生效后再进入 Redis 命令行时需要输入密码登录即使用redis-cli -a your_password命令登录，your_password是你自己设置的密码示例：如果不输入密码进入则会报错未授权 关闭保护模式移动光标定位到protected-mode yes将yes修改为no即表示关闭保护模式 总结 一般在上线部署时（只在云服务器本地运行），不需要修改配置文件 线下调试时，希望开发环境也可以连接到 Redis（方案一） ## bind 127.0.0.1 ::1，取消本地绑定（可以被任何 ip 访问） protected-mode yes，保护模式默认开启即可 requirepass your_password，设置密码 以上仅作为参考，具体可以自行选择 3.重启 Redis 服务按Esc退出编辑模式，然后输入:wq后回车保存文件并退出（在英文输入法下）输入下面命令重启 Redis 服务以应用修改后的配置文件 1sudo systemctl restart redis 输入以下命令查看 Redis 服务所监听的 ip 和端口（以方案一设置为例） 1netstat -tlpn | grep redis 可以看到 Redis 绑定的 ip 已经变成了 0.0.0.0，即接受任何 ip 地址的访问 4.云服务器放行 6379 端口在云服务器厂商找到对应云服务器的防火墙，并放行 6379 端口（Redis 的默认端口）这里以腾讯云为例，不同厂商基本都大同小异有这样一条记录就说明 6379 端口已经放行了 5.测试连接本文使用 Another Redis Desktop Manager 测试连接云服务器上的 Redis地址填你云服务器的 ip 地址连接成功！","tags":["Redis","Ubuntu"],"categories":["日常记录"]},{"title":"Ubuntu 安装 MySQL 并配置远程连接","path":"/posts/ubuntu-install-mysql/","content":"本文环境 云服务器：腾讯云（不同厂商云服务器上的操作基本相同） 系统：Ubuntu 22.04 LTS 终端：腾讯云 OrcaTerm（可使用 Xshell+Xftp 代替） 本文全部 shell 终端指令均执行在 root 用户下（命令前的sudo可不加），如果是非 root 用户也许本文中某些没加sudo命令也要加上sudo 一、安装 MySQL1.更新软件包列表1sudo apt update 2.查看是否安装 MySQL1dpkg -l | grep mysql 如果输入上述命令后没有任何的输出（如上图），则说明没有安装 MySQL 3.安装 MySQL1sudo apt install mysql-server 这里列出了软件包的相关信息并询问你是否继续安装输入y后回车确定继续安装等待安装完后再输入第 2 步的命令查看 MySQL 是否已经安装输出如上图，说明 MySQL 已经安装成功安装的 MySQL 版本默认为当前 apt 源中最新的稳定版本，可以输入下面的命令查看 MySQL 版本 1mysql --version 注：写本文时的版本为 8.0.34 4.查看 MySQL 状态一旦安装完成，MySQL 服务将会自动启动，想要查看 MySQL 服务运行状态可以输入下面命令查看 1sudo systemctl status mysql 输出显示 MySQL 服务已经被启动，并且正在运行 5.启动、重启、停止 MySQL 服务的命令上一步的命令可以用来查看 MySQL 服务的运行状态，下面是启动、重启、停止命令 123456# 启动sudo systemctl start mysql# 停止sudo systemctl stop mysql# 重启sudo systemctl restart mysql 停止和启动命令的演示 6.开机自启动设置（可选）注：使用systemd管理服务，前提是使用 apt 安装的 MySQL当前新版本的 MySQL 服务默认是开机自启动，可以通过前面的sudo systemctl status mysql命令查看该处的参数为enabled，说明当前 MySQL 服务是开机自启动可以用下面命令关闭开机自启动 1sudo systemctl disable mysql 查看状态可以发现原本的enabled参数变成了disabled，说明 MySQL 服务不再是开机自启动附上开启开机自启动的命令 1sudo systemctl enabled mysql 再次查看状态就可以发现又变回了enabled 二、MySQL 安全配置向导MySQL 安装文件时会附带一个名为mysql_secure_installation的脚本，我们可以通过运行该脚本提高 MySQL 的安全性 1sudo mysql_secure_installation 这里有一个插件VALIDATE PASSWORD PLUGIN，它可以测试 MySQL 用户密码的强度，并且提高安全性，如果你想设置验证密码插件，按y回车后移动到下一个步骤注：如果不想设置复杂密码（比如想设置密码是 123456）的建议选择输入n不设置验证密码的插件，因为即使是下面的 LOW 策略也要求密码长度至少为 8 位（安全性哪有方便重要）这里给出了低级，中级，高级三个级别的密码验证策略 低级 长度 &gt;&#x3D; 8 中级 在低级的基础上，需要同时包含数字，大小写字母和特殊字符 高级 在中级的基础上，要求密码不能存在字典文件中 可以输入对应级别前的数字进行选择，这边选择了 STRONG（即 2） 注：这里是输入 2 后回车，显示的上半部分内容，我在写本文时从网上找到的教程在这里都会有要你设置密码的一步，但是在新版本的 MySQL 是没有的，被上面这段话代替了，翻译过来的意思是： 默认情况下，使用 auth_socket 进行身份验证，因此跳过为 root 用户设置密码。如果你想改用密码身份验证，可以使用”ALTER_USER”命令进行设置。请参考 https://dev.mysql.com/doc/refman/8.0/en/alter-user.html#alter-user-password-management 获取更多信息。 这边仅做一个补充，为 root 用户设置密码的操作在第三部分会提到 询问是否删除匿名用户，建议输入y删除 在 MySQL 中，默认情况下会存在一个匿名用户（没有用户名和密码就可以登录），该用户具有一些基本的权限 如果每个用户都有明确的身份和权限，可以更容易地追踪和监视数据库的活动，识别潜在的安全问题 为了确保数据库仅允许经过授权的用户进行访问和操作，减少潜在的安全风险，建议删除匿名用户 询问是否禁止 root 远程登录，根据自己需求选择，如果你想要使用 root 用户远程连接 MySQL 数据库，可以输入任意键跳过该设置出于安全考虑，建议输入y禁止 root 是 MySQL 数据库的超级管理员，拥有最高权限，一旦泄露后果非常严重，禁止 root 用户远程登录可以降低潜在的风险 更推荐的做法是创建一个普通用户，并为其授予适当的权限，以便远程访问数据库，这样做可以限制对数据库的访问权限，并提供额外的安全层 禁止 root 用户远程登录还可以防止意外的操作或误操作 询问是否删除 test 数据库，输入y删除询问是否重新加载权限表，输入y重新加载Success.All done! 三、修改 root 用户验证方式（可选）在 MySQL 5.7（及更高版本）的 Ubuntu 系统中，root 用户默认使用 auth_socket 插件授权，而不是通过密码进行身份验证（即使输入了密码也不会验证），但这并不意味着安全性降低，因为他有两个限制： 只能用 UNIX 的 socket 方式登陆，这就保证了只能本地登陆，用户在使用这种登陆方式时已经通过了操作系统的安全验证 操作系统的用户和 MySQL 数据库的用户名必须一致，如果你要登陆 MySQL 的 root 用户，必须使用操作系统的 root 用户 在多数情况下，这可以获得更高的安全性和可用性，但也会阻碍你使用外部程序（如 phpMyAdmin）访问数据库，或者是想使用 root 用户远程连接数据库等对此有两种解决方案： 将身份验证方式从 auth_socket 修改为 caching_sha2_password（即使用密码验证 root 用户） 我在写本文时从网上找到的教程都是修改为 mysql_native_password，主要原因是因为 caching_sha2_password 在 MySQL 8.0.3 才开始引入，并且由老版本升级为新版本时会出现一些问题 但相比于 mysql_native_password，caching_sha2_password 的安全性更高，从 MySQL 8.0.4 开始，此插件成为 MySQL 服务器的新默认身份验证插件 因为我们安装的是新版的 MySQL，所以我更建议使用 caching_sha2_password 创建一个新的管理用户，拥有所有数据库的访问权限 1.使用 root 身份登录 MySQL1sudo mysql 登入成功后输出如上图 2.查看不同用户使用的身份验证方法输入下面的命令查看数据库对不同用户使用的身份验证方法 1SELECT user,authentication_string,plugin,host FROM mysql.user; 可以看到 root 用户确实是使用的 auth_socket 插件进行身份验证，并且密码为空 方案一：修改身份验证方式修改输入下面命令将 root 用户的身份验证方式 auth_socket 修改成 caching_sha2_password，并设置登录的密码（包含在单引号之间）注：需要满足在安全配置向导中选择的密码强度 1ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED WITH caching_sha2_password BY &#x27;your_password&#x27;; 如果设置的密码不满足之前选择的强度则会报下图的错误最后输入下面命令，重新加载授权表并将更改更新到 MySQL 数据库 1FLUSH PRIVILEGES; 完成后，再次运行以下命令确认 root 用户不再使用 auth_socket 进行身份验证 1SELECT user,authentication_string,plugin,host FROM mysql.user; 从上图中，我们可以看到 root 身份验证方式已经修改为 caching_sha2_password，即 root 用户可以使用密码作为验证方式登陆了 修改后登录输入exit退出 MySQL由于我们更改了 root 的身份验证方法，因此我们不能再使用之前的命令（即sudo mysql）登录 MySQL我们在登陆时需要加上用户名和密码参数 1mysql -u root -p -u 表示 user，-p 表示 password，当你按下回车后，服务器会要求你输入密码考虑到安全性，输入的密码不会在屏幕上显示出来，输入正确的密码后回车即可登录成功 方案二：创建新的管理用户（推荐）创建创建一个新的管理用户，并赋予所有数据库的访问权限注：需要满足在安全配置向导中选择的密码强度 1234# 创建用户并设置密码CREATE USER &#x27;new_root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;your_password&#x27;;# 赋予用户所有权限GRANT ALL PRIVILEGES ON *.* TO &#x27;new_root&#x27;@&#x27;localhost&#x27; WITH GRANT OPTION; 输入下面命令，重新加载授权表并将更改更新到 MySQL 数据库 1FLUSH PRIVILEGES; 查看创建用户的权限 1show grants for new_root@localhost; 输出格式怪怪的，可能是终端的问题，但是问题不大可以看到所有权限都被赋予了我们新创建的 new_root 用户，之后我们就能将该用户当作 root 用户使用 登录创建用户我们依旧可以使用sudo mysql命令登录 root 用户，但是现在我们想要登录新创建的 new_root 用户输入exit退出 MySQL我们在登陆时需要加上用户名和密码参数 1mysql -u new_root -p -u 表示 user，-p 表示 password，当你按下回车后，服务器会要求你输入密码考虑到安全性，输入的密码不会在屏幕上显示出来，输入正确的密码后回车即可登录成功 四、配置远程连接先使用 root 身份登录 MySQL 1234# 没修改过 root 用户身份验证方式sudo mysql# 修改过 root 用户身份验证方式mysql -u root -p 说明 推荐的做法是创建一个普通用户，并为其授予适当的权限，用来远程访问数据库 该部分可以参考本文 修改 root 用户验证方式（可选） 中的 方案二：创建新的管理用户 部分 不同的地方在于可以根据自己的实际情况赋予创建的用户权限，相关命令可以自行百度，懒得写了 如果暂时不清楚需要给什么权限，可以先赋予所有权限（跟着方案二即可），后续再修改 如果想要使用 root 用户进行远程连接，请先确保已经跟着方案一修改好了 root 用户的验证方式 root 用户或者是自己新创建的用户，后续配置远程连接的操作都是一样的，这里用 root 用户进行演示，如果选择创建一个新的用户进行远程连接，将带有 root 用户名的部分都替换成新创建用户的用户名即可 1.修改 host查看 root 用户的 host 1SELECT user,host FROM mysql.user; 如果 root 用户的 host 为localhost，表示只能在本地（该服务器内）登录 root 用户修改 root 用户的 host 为%注：host 为%表示所有 ip 都有连接权限 123456# 使用名为 mysql 的数据库use mysql# 修改 hostupdate user set host = &#x27;%&#x27; where user = &#x27;root&#x27;;# 刷新权限flush privileges; 再次查看 root 用户的 host，确认已经修改为% 2.注释掉 bind-address输入exit退出 MySQL，回到 Ubuntu 终端使用 vim 查看编辑 MySQL 配置文件，输入下面命令后回车 1vim /etc/mysql/mysql.conf.d/mysqld.cnf 移动光标找到下图中标记的位置按下i进入 vim 的编辑模式（在英文输入法下）将该行（意思是只允许本地访问）注释掉（在前面加#然后按下Esc键退出编辑模式再输入:wq（包括:号，在英文输入法下）后回车即保存退出 3.重启 mysql 服务1sudo systemctl restart mysql 4.云服务器放行 3306 端口在云服务器厂商找到对应云服务器的防火墙，并放行 3306 端口（MySQL 的默认端口）这里以腾讯云为例，不同厂商基本都大同小异有这样一条记录就说明 3306 端口已经放行了 5.测试连接本文使用 Navicat 测试连接云服务器上的 MySQL主机填你云服务器的 ip 地址用户名填你用来进行远程连接的 MySQL 用户名结束！","tags":["MySQL","Ubuntu"],"categories":["日常记录"]},{"title":"Gorm 简易教程","path":"/posts/gorm-simple-tutorial/","content":"精弘网络 2023 暑期后端 Go Web 开发基础课程 —— Gorm（MySQL）B 站授课链接点击此处 初识ORM什么是 ORM ORM 是 Object Relational Mapping 的缩写，译为 ”对象关系映射“，他解决了对象和关系型数据库之间的数据交互问题 将程序中的对象&#x2F;实例与关系型数据库映射起来 三个映射关系 数据表对应结构体 数据行对应结构体实例 字段对应结构体字段 以 Go 为例： 为什么使用 ORM 提高开发效率 12345678910111213141516type UserInfo struct &#123; ID int Name string Age int Sex string&#125;func main() &#123; user := UserInfo&#123;1, &quot;XiMo&quot;, 3, &quot;male&quot;&#125; // 将 user 存入数据库 // SQL 语句 // insert into userinfo values(1,&quot;XiMo&quot;,3,&quot;male&quot;);\t// orm 语句\t// orm.Create(&amp;user)&#125; 缺点 自动生成 SQL 语句，会牺牲一定的性能 对于复杂的数据库操作，ORM 通常难以处理，即使能够处理，也不如直接手写原生 SQL 语句灵活 弱化 SQL 能力 Gorm GORM 是 Go 语言目前比较热门的数据库 ORM 操作库，对开发者也比较友好，使用非常简单 连接安装在使用 gorm 之前我们需要下载 gorm 以及对应数据库 mysql 的驱动 12$ go get -u gorm.io/gorm$ go get -u gorm.io/driver/mysql 简单连接1234567891011121314151617181920212223242526272829// 定义一个全局变量var DB *gorm.DBfunc Init() &#123; user := &quot;root&quot; pass := &quot;123456&quot; host := &quot;127.0.0.1&quot; port := &quot;3306&quot; DBname := &quot;gorm_learn&quot; // dsn data-source-name 告知数据库所在的位置以及数据库相关的属性 // user:pass@tcp(host:port)/dbname?charset=utf8mb4&amp;parseTime=True&amp;loc=Local dsn := fmt.Sprintf(&quot;%s:%s@tcp(%s:%s)/%s?charset=utf8mb4&amp;parseTime=True&amp;loc=Local&quot;, user, pass, host, port, DBname) // 连接数据库，获得 DB 类型实例，用于后面对数据库进行的操作 db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config&#123;&#125;) if err != nil &#123; panic(&quot;failed to connect database, error = &quot; + err.Error()) &#125; // 赋值给全局变量 DB = db&#125;func main() &#123;\t// 做一层简单的封装，后续操作可以直接利用全局变量 DB 进行 Init()&#125; 模型定义模型定义在使用 ORM 工具时，通常我们需要在代码中定义模型（Model）与数据库中的数据表进行映射，在 GORM 中模型（Model）通常是正常定义的结构体、由 Go 的基本数据类型、实现了 Scanner 和 Valuer 接口的自定义类型及其指针或别名组成例如： 1234567891011type User struct &#123; ID uint Name string Email *string Age uint8 Birthday *time.Time MemberNumber sql.NullString ActivatedAt sql.NullTime CreatedAt time.Time UpdatedAt time.Time&#125; 自动迁移建表AutoMigrate 会根据结构体帮我们自动创建一个表 1DB.AutoMigrate(&amp;User) AutoMigrate 的逻辑是只新增，不删除，不修改（可以修改大小）例如 User 结构体中将 Name 改成 Username，对应的表中会多出一个 username 的字段，但是原本的 name 字段不会删除 Gorm 约定GORM 倾向于约定优于配置 默认情况下 Gorm 使用名为 ID 的字段作为主键 如果没有 TableName 函数，使用结构体的蛇形复数作为表名 字段名的蛇形作为列名 使用 CreatedAt、UpdatedAt 字段追踪创建更新时间 123456789// 结构体的蛇形复数作为表名（UserInfo --&gt; user_infos）// 默认列名是字段名的蛇形小写（CreatedAt --&gt; created_at）type UserInfo struct &#123; ID uint // 默认为主键 Name string Age int CreatedAt time.Time // 创建记录时，如果该字段值为零值，则将该字段的值设为当前时间 UpdatedAt time.Time // 更新记录时，将该字段的值设为当前时间，创建记录时，如果该字段值为零值，则将该字段的值设为当前时间&#125; 如果遵循 GORM 的约定，就可以少写一些配置、代码。 当然，如果约定不符合你的实际要求，GORM 允许你配置它们 主键（Primary Key）GORM 默认会使用名为 ID 的字段作为表的主键，你可以通过标签 primaryKey 将其它字段设为主键 1234567// 使用 UUID 作为主键type User struct &#123; ID uint UUID int64 `gorm:&quot;primaryKey&quot;` Name string Age int64&#125; 复数表名（Table Name）表名默认就是结构体的蛇形复数，例如： 123456789type User struct &#123;&#125; // 默认表名是 `users`type UserInfo struct &#123;&#125; // 默认表名是 `user_infos`// 将 UserInfo 的表名设置为 `user`func (UserInfo) TableName() string &#123; return &quot;user&quot;&#125;// 除了这种方式外还有别的方法，比如临时修改表名、修改 Gorm 的命名策略等，这边不多做涉及，可以自行查阅文档 列名数据表的列名使用的是 struct 字段名的蛇形命名可以使用 column 标签来覆盖列名 12345type User struct &#123; ID uint `gorm:&quot;column:user_id&quot;` // 将列名设为 `user_id` UserName string `gorm:&quot;column:name&quot;` // 将列名设为 `name` Age int64 `gorm:&quot;column:user_age&quot;` // 将列名设为 `user_age`&#125; 时间戳追踪CreatedAt对于有 CreatedAt 字段的模型，创建记录时，如果该字段值为零值，则将该字段的值设为当前时间可以通过将 autoCreateTime 标签置为 false 来禁用时间戳追踪 123type User struct &#123; CreatedAt time.Time `gorm:&quot;autoCreateTime:false&quot;`&#125; UpdatedAt对于有 UpdatedAt 字段的模型，更新记录时，将该字段的值设为当前时间。创建记录时，如果该字段值为零值，则将该字段的值设为当前时间可以通过将 autoUpdateTime 标签置为 false 来禁用时间戳追踪 123type User struct &#123; UpdatedAt time.Time `gorm:&quot;autoUpdateTime:false&quot;`&#125; 结构体标记（tag）声明 model 时，tag 是可选的，GORM 支持以下 tag：tag 名大小写不敏感，但建议使用 camelCase 风格，多个 tag 之间用 ; 分格 标签名 说明 column 指定 db 列名 type 列数据类型，推荐使用兼容性好的通用类型，例如：所有数据库都支持 bool、int、uint、float、string、time、bytes 并且可以和其他标签一起使用，例如：not null、size, autoIncrement… 像 varbinary(8) 这样指定数据库数据类型也是支持的。在使用指定数据库数据类型时，它需要是完整的数据库数据类型，如：MEDIUMINT UNSIGNED not NULL AUTO_INCREMENT serializer 指定将数据序列化或反序列化到数据库中的序列化器, 例如: serializer:json/gob/unixtime size 定义列数据类型的大小或长度，例如 size: 256 primaryKey 将列定义为主键 unique 将列定义为唯一键 default 定义列的默认值 precision 指定列的精度 scale 指定列大小 not null 指定列为 NOT NULL autoIncrement 指定列为自动增长 autoIncrementIncrement 自动步长，控制连续记录之间的间隔 embedded 嵌套字段 embeddedPrefix 嵌入字段的列名前缀 autoCreateTime 创建时追踪当前时间，对于 int 字段，它会追踪时间戳秒数，您可以使用 nano&#x2F;milli 来追踪纳秒、毫秒时间戳，例如：autoCreateTime:nano autoUpdateTime 创建&#x2F;更新时追踪当前时间，对于 int 字段，它会追踪时间戳秒数，您可以使用 nano&#x2F;milli 来追踪纳秒、毫秒时间戳，例如：autoUpdateTime:milli index 根据参数创建索引，多个字段使用相同的名称则创建复合索引，查看 索引 获取详情 uniqueIndex 与 index 相同，但创建的是唯一索引 check 创建检查约束，例如 check:age &gt; 13，查看 约束 获取详情 &lt;- 设置字段写入的权限， &lt;-:create 只创建、&lt;-:update 只更新、&lt;-:false 无写入权限、&lt;- 创建和更新权限 -&gt; 设置字段读的权限，-&gt;:false 无读权限 - 忽略该字段，- 表示无读写，-:migration 表示无迁移权限，-:all 表示无读写迁移权限 comment 迁移时为字段添加注释 tag 使用如下： 1234567type User struct &#123; ID uint `gorm:&quot;autoIncrement&quot;` // 自增主键 Name string `gorm:&quot;size:10&quot;` // 大小为 10 个字符 Age int `gorm:&quot;size:3; check:age &gt; 0&quot;` // 大小为 3 位数，并且值要 &gt; 0 Email string `gorm:&quot;type:varchar(25); unique;&quot;` // 类型为 varchar(25)，唯一 Password string `gorm:&quot;type:varchar(20); default:123456&quot;` // 类型为 varchar(20)，默认值为 123456&#125; gorm.Model对于一张数据表的每一条数据来说，都有自增主键，创建、更新与删除时间等比较通用的字段，因此 GORM 将其抽出来并定义了 gorm.Model，包含 ID, CreatedAt, UpdatedAt, DeletedAt 四个字段 1234567// gorm.Model 的定义type Model struct &#123; ID uint `gorm:&quot;primaryKey&quot;` CreatedAt time.Time UpdatedAt time.Time DeletedAt gorm.DeletedAt `gorm:&quot;index&quot;`&#125; 你可以将它嵌入到你自己的模型中 123456789101112131415type User struct &#123; gorm.Model Name string Age int&#125;// 等效于type User struct &#123; ID uint `gorm:&quot;primaryKey&quot;` CreatedAt time.Time UpdatedAt time.Time DeletedAt gorm.DeletedAt `gorm:&quot;index&quot;` Name string Age int&#125; 创建记录模型123456type User struct &#123; ID uint Name string Age int Sex string&#125; 创建记录1234567user := User&#123;Name: &quot;XiMo&quot;, Age: 3, Sex: &quot;male&quot;&#125;result := db.Create(&amp;user) // 通过数据的指针来创建user.ID // 返回插入数据的主键result.Error // 返回 errorresult.RowsAffected // 返回插入记录的条数 注：Create 传入的参数是指针而不是值 由于传递的是一个指针，执行完 Create 函数后 user 中就有了该记录相关的信息，比如创建的 ID 我们还可以使用 Create() 创建多项记录： 123456789users := []User&#123; &#123;Name: &quot;惜寞&quot;, Age: 3, Sex: &quot;male&quot;&#125;, &#123;Name: &quot;青鸟&quot;, Age: 18, Sex: &quot;male&quot;&#125;, &#125;result := db.Create(&amp;users) // 传入切片的指针result.Error // 返回 errorresult.RowsAffected // 返回插入记录的条数 用指定的字段创建记录创建记录并为指定的字段分配值： 1db.Select(&quot;Name&quot;, &quot;Age&quot;).Create(&amp;user) 创建记录并忽略要省略的传递字段的值： 1db.Omit(&quot;Name&quot;, &quot;Age&quot;).Create(&amp;user) 根据 Map 创建（不常用）123456789db.Model(&amp;User&#123;&#125;).Create(map[string]interface&#123;&#125;&#123; &quot;Name&quot;: &quot;竹林&quot;, &quot;Age&quot;: 19,&#125;)// 通过 []map[string]interface&#123;&#125;&#123;&#125; 批量插入db.Model(&amp;User&#123;&#125;).Create([]map[string]interface&#123;&#125;&#123; &#123;&quot;Name&quot;: &quot;知更鸟&quot;, &quot;Age&quot;: 19&#125;, &#123;&quot;Name&quot;: &quot;桑葚&quot;, &quot;Age&quot;: 19&#125;,&#125;) 更多查询记录一般查询 GORM 提供了 First、Take、Last 方法，以便从数据库中检索单个对象 提供了 Find 方法，以便从数据库中检索全部对象 1234567891011121314151617181920212223242526var user Uservar users []User// 根据主键查询第一条记录db.First(&amp;user)//// SELECT * FROM users ORDER BY id LIMIT 1;// 获取一条记录，没有指定排序字段db.Take(&amp;user)//// SELECT * FROM users LIMIT 1;// 根据主键查询最后一条记录db.Last(&amp;user)//// SELECT * FROM users ORDER BY id DESC LIMIT 1;// 查询指定的某条记录(仅当主键为整型时可用)db.First(&amp;user, 10)//// SELECT * FROM users WHERE id = 10;// 查询所有的记录db.Find(&amp;users)//// SELECT * FROM users;result := db.First(&amp;user)result.RowsAffected // 返回找到的记录数result.Error // 返回错误 注意： 当目标对象有一个主键值时，将使用主键构建查询条件 使用 First 等方法查询单个记录时，如果查询不到数据会返回 ErrRecordNotFound 错误 使用 Find 查询时，查询不到数据不会返回错误 条件string 条件123456789101112131415161718192021222324252627// 获取第一条匹配的记录db.Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).First(&amp;user)// SELECT * FROM users WHERE name = &#x27;jinzhu&#x27; ORDER BY id LIMIT 1;// 获取所有匹配的记录db.Where(&quot;name &lt;&gt; ?&quot;, &quot;jinzhu&quot;).Find(&amp;users)// SELECT * FROM users WHERE name &lt;&gt; &#x27;jinzhu&#x27;;// INdb.Where(&quot;name IN ?&quot;, []string&#123;&quot;jinzhu&quot;, &quot;jinzhu 2&quot;&#125;).Find(&amp;users)// SELECT * FROM users WHERE name IN (&#x27;jinzhu&#x27;,&#x27;jinzhu 2&#x27;);// LIKEdb.Where(&quot;name LIKE ?&quot;, &quot;%jin%&quot;).Find(&amp;users)// SELECT * FROM users WHERE name LIKE &#x27;%jin%&#x27;;// ANDdb.Where(&quot;name = ? AND age &gt;= ?&quot;, &quot;jinzhu&quot;, &quot;22&quot;).Find(&amp;users)// SELECT * FROM users WHERE name = &#x27;jinzhu&#x27; AND age &gt;= 22;// Timedb.Where(&quot;updated_at &gt; ?&quot;, lastWeek).Find(&amp;users)// SELECT * FROM users WHERE updated_at &gt; &#x27;2000-01-01 00:00:00&#x27;;// BETWEENdb.Where(&quot;created_at BETWEEN ? AND ?&quot;, lastWeek, today).Find(&amp;users)// SELECT * FROM users WHERE created_at BETWEEN &#x27;2000-01-01 00:00:00&#x27; AND &#x27;2000-01-08 00:00:00&#x27;; struct &amp; Map 条件1234567891011// Structdb.Where(&amp;User&#123;Name: &quot;jinzhu&quot;, Age: 20&#125;).First(&amp;user)// SELECT * FROM users WHERE name = &quot;jinzhu&quot; AND age = 20 ORDER BY id LIMIT 1;// Mapdb.Where(map[string]interface&#123;&#125;&#123;&quot;name&quot;: &quot;jinzhu&quot;, &quot;age&quot;: 20&#125;).Find(&amp;users)// SELECT * FROM users WHERE name = &quot;jinzhu&quot; AND age = 20;// Slice of primary keysdb.Where([]int64&#123;20, 21, 22&#125;).Find(&amp;users)// SELECT * FROM users WHERE id IN (20, 21, 22); 注意：使用 struct 查询时，GORM 将仅使用非零字段进行查询，这意味着如果你的字段的值为 0 &#39;&#39; false 或其他零值时，将不会用于构建查询条件，例如： 12db.Where(&amp;User&#123;Name: &quot;jinzhu&quot;, Age: 0&#125;).Find(&amp;users)//// SELECT * FROM users WHERE name = &quot;jinzhu&quot;; 要在查询条件中包含零值，可以使用 map，它会将所有键值作为查询条件包含在内，例如： 12db.Where(map[string]interface&#123;&#125;&#123;&quot;Name&quot;: &quot;jinzhu&quot;, &quot;Age&quot;: 0&#125;).Find(&amp;users)// SELECT * FROM users WHERE name = &quot;jinzhu&quot; AND age = 0; 指定结构体查询字段在使用 struct 进行搜索时，指定在查询条件中要使用结构体中的哪些特定值，例如： 12345db.Where(&amp;User&#123;Name: &quot;jinzhu&quot;&#125;, &quot;name&quot;, &quot;Age&quot;).Find(&amp;users)// SELECT * FROM users WHERE name = &quot;jinzhu&quot; AND age = 0;db.Where(&amp;User&#123;Name: &quot;jinzhu&quot;&#125;, &quot;Age&quot;).Find(&amp;users)// SELECT * FROM users WHERE age = 0; 内联条件123456789101112131415161718// Get by primary key if it were a non-integer typedb.First(&amp;user, &quot;id = ?&quot;, &quot;string_primary_key&quot;)// SELECT * FROM users WHERE id = &#x27;string_primary_key&#x27;;// Plain SQLdb.Find(&amp;user, &quot;name = ?&quot;, &quot;jinzhu&quot;)// SELECT * FROM users WHERE name = &quot;jinzhu&quot;;db.Find(&amp;users, &quot;name &lt;&gt; ? AND age &gt; ?&quot;, &quot;jinzhu&quot;, 20)// SELECT * FROM users WHERE name &lt;&gt; &quot;jinzhu&quot; AND age &gt; 20;// Structdb.Find(&amp;users, User&#123;Age: 20&#125;)// SELECT * FROM users WHERE age = 20;// Mapdb.Find(&amp;users, map[string]interface&#123;&#125;&#123;&quot;age&quot;: 20&#125;)// SELECT * FROM users WHERE age = 20; Not 条件1234567891011121314db.Not(&quot;name = ?&quot;, &quot;jinzhu&quot;).First(&amp;user)// SELECT * FROM users WHERE NOT name = &quot;jinzhu&quot; ORDER BY id LIMIT 1;// Not Indb.Not(map[string]interface&#123;&#125;&#123;&quot;name&quot;: []string&#123;&quot;jinzhu&quot;, &quot;jinzhu 2&quot;&#125;&#125;).Find(&amp;users)// SELECT * FROM users WHERE name NOT IN (&quot;jinzhu&quot;, &quot;jinzhu 2&quot;);// Structdb.Not(User&#123;Name: &quot;jinzhu&quot;, Age: 18&#125;).First(&amp;user)// SELECT * FROM users WHERE name &lt;&gt; &quot;jinzhu&quot; AND age &lt;&gt; 18 ORDER BY id LIMIT 1;// Not In slice of primary keysdb.Not([]int64&#123;1,2,3&#125;).First(&amp;user)// SELECT * FROM users WHERE id NOT IN (1,2,3) ORDER BY id LIMIT 1; Or 条件12345678910db.Where(&quot;role = ?&quot;, &quot;admin&quot;).Or(&quot;role = ?&quot;, &quot;super_admin&quot;).Find(&amp;users)// SELECT * FROM users WHERE role = &#x27;admin&#x27; OR role = &#x27;super_admin&#x27;;// Structdb.Where(&quot;name = &#x27;jinzhu&#x27;&quot;).Or(User&#123;Name: &quot;jinzhu 2&quot;, Age: 18&#125;).Find(&amp;users)// SELECT * FROM users WHERE name = &#x27;jinzhu&#x27; OR (name = &#x27;jinzhu 2&#x27; AND age = 18);// Mapdb.Where(&quot;name = &#x27;jinzhu&#x27;&quot;).Or(map[string]interface&#123;&#125;&#123;&quot;name&quot;: &quot;jinzhu 2&quot;, &quot;age&quot;: 18&#125;).Find(&amp;users)// SELECT * FROM users WHERE name = &#x27;jinzhu&#x27; OR (name = &#x27;jinzhu 2&#x27; AND age = 18); 选择特定字段Select 允许指定要从数据库中检索的字段，没有 Select GORM 将默认选择所有字段 12345db.Select(&quot;name&quot;, &quot;age&quot;).Find(&amp;users)// SELECT name, age FROM users;db.Select([]string&#123;&quot;name&quot;, &quot;age&quot;&#125;).Find(&amp;users)// SELECT name, age FROM users; 排序123456db.Order(&quot;age desc, name&quot;).Find(&amp;users)// SELECT * FROM users ORDER BY age desc, name;// Multiple ordersdb.Order(&quot;age desc&quot;).Order(&quot;name&quot;).Find(&amp;users)// SELECT * FROM users ORDER BY age desc, name; Limit &amp; OffsetLimit 指定要检索的最大记录数，Offset 指定在开始返回记录之前要跳过的记录数 12345678910db.Limit(3).Find(&amp;users)// SELECT * FROM users LIMIT 3;// -1 表示检索所有记录db.Limit(10).Find(&amp;users1).Limit(-1).Find(&amp;users2)// SELECT * FROM users LIMIT 10; (users1)// SELECT * FROM users; (users2)db.Limit(10).Offset(5).Find(&amp;users)// SELECT * FROM users OFFSET 5 LIMIT 10; 注意：Offset 不能单独使用，要和 Limit 要一起使用 更多更新记录 以查询到记录为基础 更新的记录不存在不会报 error 保存所有字段Save 会保存所有的字段，即使字段是零值 123456db.First(&amp;user)user.Name = &quot;jinzhu 2&quot;user.Age = 100db.Save(&amp;user)// UPDATE users SET name=&#x27;jinzhu 2&#x27;, age=100, updated_at = &#x27;2013-11-17 21:34:10&#x27; WHERE id=111; 如果保存值不包含主键（或者主键值在数据库中不存在），它将执行 Create 创建 主键存在则会执行更新保存所有字段 12345db.Save(&amp;User&#123;Name: &quot;jinzhu&quot;, Age: 100&#125;)// INSERT INTO `users` (`name`,`age`,`update_at`) VALUES (&quot;jinzhu&quot;,100,&quot;0000-00-00 00:00:00&quot;)db.Save(&amp;User&#123;ID: 1, Name: &quot;jinzhu&quot;, Age: 100&#125;)// UPDATE `users` SET `name`=&quot;jinzhu&quot;,`age`=100,`update_at`=&quot;0000-00-00 00:00:00&quot; WHERE `id` = 1 更新单个列 需要通过 Model 函数来传入要更新的模型，主要是用来确定表名 当使用该方法并且其值具有主值时，主键将用于构建条件 123456789101112// 根据条件更新db.Model(&amp;User&#123;&#125;).Where(&quot;active = ?&quot;, true).Update(&quot;name&quot;, &quot;hello&quot;)// UPDATE users SET name=&#x27;hello&#x27;, updated_at=&#x27;2013-11-17 21:34:10&#x27; WHERE active=true;// 根据主键更新// User&#x27;s ID is `111`:db.Model(&amp;user).Update(&quot;name&quot;, &quot;hello&quot;)// UPDATE users SET name=&#x27;hello&#x27;, updated_at=&#x27;2013-11-17 21:34:10&#x27; WHERE id=111;// 根据条件和主键更新db.Model(&amp;user).Where(&quot;active = ?&quot;, true).Update(&quot;name&quot;, &quot;hello&quot;)// UPDATE users SET name=&#x27;hello&#x27;, updated_at=&#x27;2013-11-17 21:34:10&#x27; WHERE id=111 AND active=true; 更新多列 如果要更新多个字段的话，可以使用 Updates 函数，该函数需要传入一个结构体或 map 在使用结构体时，不会更新零值，如果要更新的话，需要使用 map 或者更新选定字段 1234567// 用结构体更新db.Model(&amp;user).Updates(User&#123;Name: &quot;hello&quot;, Age: 18, Active: false&#125;)// UPDATE users SET name=&#x27;hello&#x27;, age=18, updated_at = &#x27;2013-11-17 21:34:10&#x27; WHERE id = 111;// 用 map 更新db.Model(&amp;user).Updates(map[string]interface&#123;&#125;&#123;&quot;name&quot;: &quot;hello&quot;, &quot;age&quot;: 18, &quot;active&quot;: false&#125;)// UPDATE users SET name=&#x27;hello&#x27;, age=18, active=false, updated_at=&#x27;2013-11-17 21:34:10&#x27; WHERE id=111; 更新选定字段如果要在更新时更新所选字段或忽略某些字段，可以使用 select 和 omit 1234567891011121314151617// Select with Map// User&#x27;s ID is `111`:db.Model(&amp;user).Select(&quot;name&quot;).Updates(map[string]interface&#123;&#125;&#123;&quot;name&quot;: &quot;hello&quot;, &quot;age&quot;: 18, &quot;active&quot;: false&#125;)// UPDATE users SET name=&#x27;hello&#x27; WHERE id=111;db.Model(&amp;user).Omit(&quot;name&quot;).Updates(map[string]interface&#123;&#125;&#123;&quot;name&quot;: &quot;hello&quot;, &quot;age&quot;: 18, &quot;active&quot;: false&#125;)// UPDATE users SET age=18, active=false, updated_at=&#x27;2013-11-17 21:34:10&#x27; WHERE id=111;// Select with Struct (select zero value fields)db.Model(&amp;user).Select(&quot;Name&quot;, &quot;Age&quot;).Updates(User&#123;Name: &quot;new_name&quot;, Age: 0&#125;)// UPDATE users SET name=&#x27;new_name&#x27;, age=0 WHERE id=111;// Select all fields (select all fields include zero value fields)db.Model(&amp;user).Select(&quot;*&quot;).Updates(User&#123;Name: &quot;jinzhu&quot;, Role: &quot;admin&quot;, Age: 0&#125;)// Select all fields but omit Role (select all fields include zero value fields)db.Model(&amp;user).Select(&quot;*&quot;).Omit(&quot;Role&quot;).Updates(User&#123;Name: &quot;jinzhu&quot;, Role: &quot;admin&quot;, Age: 0&#125;) 批量更新如果我们没有指定主键值，GORM 将执行批量更新 Model，更新所有符合条件的记录 1234567// Update with structdb.Model(User&#123;&#125;).Where(&quot;role = ?&quot;, &quot;admin&quot;).Updates(User&#123;Name: &quot;hello&quot;, Age: 18&#125;)// UPDATE users SET name=&#x27;hello&#x27;, age=18 WHERE role = &#x27;admin&#x27;;// Update with mapdb.Model(User&#123;&#125;).Where(&quot;id IN ?&quot;, []int&#123;10, 11&#125;).Updates(map[string]interface&#123;&#125;&#123;&quot;name&quot;: &quot;hello&quot;, &quot;age&quot;: 18&#125;)// UPDATE users SET name=&#x27;hello&#x27;, age=18 WHERE id IN (10, 11); 更多删除记录 以查询到记录为基础 删除的记录不存在不会报 error 删除一条记录删除一条记录时，删除对象需要指定主键，否则会触发批量删除注：删除的记录不存在不会报 error 1234567// User 的 ID 是 `10`db.Delete(&amp;user)// DELETE from users where id = 10;// 带额外条件的删除db.Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).Delete(&amp;user)// DELETE from users where id = 10 AND name = &quot;jinzhu&quot;; 根据主键删除GORM 允许通过主键和内联条件来删除对象 123456789db.Delete(&amp;User&#123;&#125;, 10)// DELETE FROM users WHERE id = 10;db.Delete(&amp;users, []int&#123;1,2,3&#125;)// DELETE FROM users WHERE id IN (1,2,3);// 内联条件db.Delete(&amp;user&#123;&#125;, &quot;name = ?&quot;, &quot;jinzhu&quot;)// DELETE FROM users WHERE name = &quot;jinzhu&quot;; 批量删除如果指定的值不包括主属性，那么 GORM 会执行批量删除，它将删除所有匹配的记录 12345db.Where(&quot;name LIKE ?&quot;, &quot;%jinzhu%&quot;).Delete(&amp;User&#123;&#125;)// DELETE from users where name LIKE &quot;%jinzhu%&quot;;db.Delete(&amp;User&#123;&#125;, &quot;name LIKE ?&quot;, &quot;%jinzhu%&quot;)// DELETE from users where name LIKE &quot;%jinzhu%&quot;; 阻止全局删除当你试图执行不带任何条件的批量删除时，GORM 将不会运行并返回ErrMissingWhereClause 错误如果一定要这么做，你必须添加一些条件，或者使用原生 SQL，或者开启AllowGlobalUpdate 模式，如下例： 12345678910111213141516db.Delete(&amp;User&#123;&#125;).Error// gorm.ErrMissingWhereClause// 需要主键值db.Delete(&amp;[]User&#123;&#123;Name: &quot;jinzhu1&quot;&#125;, &#123;Name: &quot;jinzhu2&quot;&#125;&#125;).Error// gorm.ErrMissingWhereClausedb.Where(&quot;1 = 1&quot;).Delete(&amp;User&#123;&#125;)// DELETE FROM `users` WHERE 1=1// 原生 SQLdb.Exec(&quot;DELETE FROM users&quot;)// DELETE FROM usersdb.Session(&amp;gorm.Session&#123;AllowGlobalUpdate: true&#125;).Delete(&amp;User&#123;&#125;)// DELETE FROM users 软删除如果你的模型包含了 gorm.DeletedAt 字段（该字段也被包含在 gorm.Model 中），那么该模型将会自动获得软删除的能力当调用 Delete 时，GORM 并不会从数据库中删除该记录，而是将该记录的 DeleteAt 设置为当前时间，而后的一般查询方法将无法查找到此条记录 1234567891011// user&#x27;s ID is `111`db.Delete(&amp;user)// UPDATE users SET deleted_at=&quot;2013-10-29 10:23&quot; WHERE id = 111;// 批量删除db.Where(&quot;age = ?&quot;, 20).Delete(&amp;User&#123;&#125;)// UPDATE users SET deleted_at=&quot;2013-10-29 10:23&quot; WHERE age = 20;// 软删除的记录在查询时会被忽略db.Where(&quot;age = 20&quot;).Find(&amp;user)// SELECT * FROM users WHERE age = 20 AND deleted_at IS NULL; 如果你并不想嵌套 gorm.Model，你也可以像下方例子那样开启软删除特性： 12345type User struct &#123; ID int Deleted gorm.DeletedAt Name string&#125; 查找被软删除的记录你可以使用 Unscoped 来查询到被软删除的记录 12db.Unscoped().Where(&quot;age = 20&quot;).Find(&amp;users)// SELECT * FROM users WHERE age = 20; 永久删除你可以使用 Unscoped 来永久删除匹配的记录 123// user&#x27;s ID is `10`db.Unscoped().Delete(&amp;user)// DELETE FROM users WHERE id=10; 更多","tags":["Go","Gorm"],"categories":["Go Web"]},{"title":"Gin 简易教程","path":"/posts/gin-simple-tutorial/","content":"精弘网络 2023 暑期后端 Go Web 开发基础课程 —— Gin 框架B 站授课链接点击此处 引入Go 内置的 net&#x2F;http 包 Go 语言内置的 net&#x2F;http 包十分优秀，提供了 HTTP 客户端和服务端的实现 这里使用 Go 语言中的 net&#x2F;http 包来编写一个简单的接收 HTTP 请求的服务端（后端）示例，具体的代码如下： 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( &quot;fmt&quot; &quot;net/http&quot;)// SayHello 函数是需要我们自己实现的一个函数，它有两个规定的参数// 第一个参数用于给前端的响应（Response）写入数据，响应想要返回什么，就往这个参数里面写什么// 第二个参数用于获取前端发送的请求（Request）// Web 开发的本质就是一个请求对应一个响应的过程func SayHello(w http.ResponseWriter, r *http.Request) &#123; // fmt 包中的 Fprintln 函数是一个简单的可以往 w 里写东西的函数 // 使用 Fprintln 函数将 &quot;Hello 精弘!&quot; 这句话以纯文本的形式写进 w 后返回给前端 fmt.Fprintln(w, &quot;Hello 精弘!&quot;)&#125;func main() &#123; // HandleFunc 函数接受两个参数，第一个是路径，即前端请求的 URL，另一个是回调函数，用于处理前端发送的请求 // HandleFunc 函数是一个设置路由的函数，它的作用是将前端对 /hello 路径的请求映射到 SayHello 函数 // 当前端访问 /hello 路径的时候，就去执行 SayHello 的函数，往响应写入 &quot;Hello 精弘!&quot; 后返回给前端 http.HandleFunc(&quot;/hello&quot;, SayHello) // ListenAndServe 函数用于启动服务（Serve）并监听（Listen），接收两个参数 // 第一个参数是 ip:port 格式的 string 参数，给 /hello 路径确定访问它的 ip 地址和端口号 // 第二个参数指的是处理 HTTP 请求的处理器，填入nil表示使用默认的处理器 // &quot;:8080&quot; 是简写，省略了 ip，默认为本机的所有 ip 如 127.0.0.1 就是其中一个，端口号指定为 8080 // 在浏览器（前端）访问 127.0.0.1:8080/hello 就可以看到 SayHello 函数做出的响应了 // 另外有一个 err 参数，如果端口被占用或者启动失败会返回错误，正常启动则返回 nil，即空（没有错误） err := http.ListenAndServe(&quot;:8080&quot;, nil) // 错误处理，如果错误不为 nil 则在终端打印错误 if err != nil &#123; fmt.Printf(&quot;http server failed, err:%v &quot;, err) return &#125;&#125; 将上面的代码编译运行后，在浏览器的地址栏中输入127.0.0.1:8080/hello后回车，就能够看到如下页面： Web 框架 什么是 Web 框架 用于进行 Web 开发的一套软件架构 为 Web 应用程序提供了基础的功能 优点 可以利用它更容易、方便、快速的做一些事情 缺点 作为一套体系，它会有一些自己的规定或约束，不可能百分百的满足你的需求 为什么要用 Web 框架 如果从零开始，利用 Go 的基础库去搭建，过程会很繁琐 主要作用 简化应用开发 在 Web 框架的基础上实现自己的业务逻辑 框架提供基础功能 只需要专注应用的业务逻辑 初识介绍Gin 是 Go 世界里最流行的一个 Web 框架，Github 上有 69K+ star，封装比较优雅，API 友好，源码注释比较明确， 是一个简单易用的轻量级框架，并且中文文档齐全。 安装1、先初始化当前文件夹（如果没有初始化） 1$ go mod init `name` 2、下载并安装 Gingo get 是 go 安装软件包的下载命令 1$ go get -u github.com/gin-gonic/gin 开始将上节课的代码用 Gin 框架来实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445package mainimport ( &quot;fmt&quot; // 将 gin 引入到代码中 &quot;github.com/gin-gonic/gin&quot;)// SayHello 函数是一个处理 HTTP 请求的回调函数// 接受一个 gin 封装过的规定参数，即上下文对象 Context，它是所有请求处理器（处理请求的函数或方法）的入口参数// Context 包含了 Request 和 ResponseWriter 两个参数，用于获取前端请求信息和返回响应// 本质上是对于 Request 和 Response 的封装，提供了丰富的方法用于获取当前请求的上下文信息以及返回响应func SayHello(c *gin.Context) &#123; // 200 表示 HTTP 响应状态码（&lt;=&gt; http.StatusOK） // 使用 Context 的 String 函数将 &quot;Hello 精弘!&quot; 这句话以纯文本（字符串）的形式返回给前端 // 实际上是对返回响应的封装 c.String(200, &quot;Hello 精弘!&quot;)&#125;func main() &#123; // gin.Default 函数会生成一个默认的 Engine（路由引擎）对象（集成了 Logger 和 Recovery 两个中间件，中间件后面的课会讲） // 变量名 r 是 router（路由）的一个简写 // Engine 是 Gin 框架最重要的数据结构，它是 Gin 框架的入口，本质上是一个 Http Handler // 它是一个用于处理 HTTP 请求的对象，维护了一张路由表，将不同的 HTTP 请求路径映射到不同的处理函数上 r := gin.Default() // r.GET 函数接受两个参数，一个是路径，即前端请求的 URL，另一个是回调函数，用于处理前端发送的请求 // r.GET 函数将 /hello 路径添加到了 r 的路由表中，将对 /hello 路径的 GET 请求映射到 SayHello 函数上 // 表示前端给后端的 /hello 路由发送一个 HTTP 的 GET 请求时 // 后端会执行后面的 SayHello 函数，对前端的请求做出一个响应，给前端返回一个 &quot;Hello 精弘!&quot; 的字符串 r.GET(&quot;/hello&quot;, SayHello) // 启动服务并监听,只接受一个 ip:port 格式的 string 参数，表示服务运行的 ip 地址和端口号 // &quot;:8080&quot; 是简写，省略了 ip，表示监听本地所有 ip （如 127.0.0.1）的 8080 端口，接收并处理 HTTP 请求 // 在浏览器（前端）访问 127.0.0.1:8080/hello 就可以看到 SayHello 函数做出的响应 // 等价于 r.Run()，将 port 端口也省略，默认为 8080 端口 err := r.Run(&quot;:8080&quot;) // 错误处理，如果错误不为 nil 则在终端打印错误 if err != nil &#123; fmt.Printf(&quot;http server failed, err:%v &quot;, err) return &#125;&#125; 将上面的代码编译运行后，在浏览器的地址栏中输入127.0.0.1:8080/hello后回车，就能够看到和上节一样的页面： HTTP 状态码 当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求，当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含 HTTP 状态码的信息头（server header）用以响应浏览器的请求 常见的 HTTP 状态码 200 - 请求成功 301 - 资源（网页等）被永久转移到其它 URL 404 - 请求的资源（网页等）不存在 500 - 内部服务器错误 响应返回 JSONString123r.GET(&quot;/hello&quot;, func(c *gin.Context) &#123; c.String(200, &quot;Hello 精弘!&quot;) &#125;) 上节课我们讲的是 c.String 给前端返回一个字符串，但在实际的前后端分离的开发过程中，直接使用 string 进行前后端数据传输并不便利，所以我们往往会选择使用 JSON 的数据格式进行前后端的数据传输 JSON JSON 数据类型 JSON(JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式，用它可以来表示各种各样复杂的数据，如对象，数组，集合，以及集合的集合等数据 JSON 实际上就是一串字符串，只不过元素会使用特定的符号标注。 {} 双括号表示对象，[] 中括号表示数组，”” 双引号内是属性或值，: 冒号表示后者是前者的值(这个值可以是字符串、数字、也可以是另一个数组或对象)。 一些常见的 JSON 格式 一个 JSON 对象——JSONObject &#123;&quot;name&quot;:&quot;XiMo&quot;, &quot;age&quot;:3&#125; &#123;&quot;name&quot;:&quot;XiMo&quot;, &quot;age&quot;:3，&quot;address&quot;:&#123;&quot;city&quot;:HangZhou&quot;, &quot;country&quot;:&quot;China&quot;&#125;&#125; 一个 JSON 数组——JSONArray [&quot;XiMo&quot;, &quot;惜寞&quot;] [&#123;&quot;name&quot;:&quot;XiMo&quot;, &quot;age&quot;:3&#125;, &#123;&quot;name&quot;:&quot;惜寞&quot;, &quot;age&quot;:4&#125;] [&#123;&quot;name&quot;:&quot;XiMo&quot;, &quot;age&quot;:3, &quot;address&quot;:&#123;&quot;city&quot;:&quot;HangZhou&quot;, &quot;country&quot;:&quot;China&quot;&#125;&#125;, &#123;&quot;name&quot;:&quot;惜寞&quot;, &quot;age&quot;: 4, &quot;address&quot;:&#123;&quot;city&quot;:&quot;JiaXing&quot;, &quot;country&quot;:&quot;China&quot;&#125;&#125;] 可以通过可视化将 JSON 数据类型格式化来查看，结构清晰，并且内容相同，字符串形式只是将空格回车给去掉了而已 当然，数组可以包含对象，在对象中也可以包含数组 为什么普遍选择 JSON 用于前后端数据的传输 采用完全独立于任何程序语言的文本格式，使 JSON 成为理想的数据交换语言 易于人阅读和编写，键值对类型的数据结构具有良好的可读性 数据格式比较简单, 格式都是压缩的，占用带宽小，能有效地提升网络传输效率 易于解析，前端可以很方便的进行 JSON 数据的读取 JSON 格式能够直接为后端代码使用，大大简化了前后端的代码开发量，但是完成的任务不变，且易于维护 和返回 string 一样，Gin 在 Context 里面也给我们封装了返回 JSON 的方法，下面是一个简单的 Gin 返回 JSON 的示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func Json(c *gin.Context) &#123; // 1.使用结构体，可以灵活利用 tag 对字段进行&quot;换名&quot; type UserInfo struct &#123; Name string `json:&quot;username&quot;` Age int `json:&quot;age&quot;` Password string `json:&quot;-&quot;` // 忽略该字段 &#125; user := UserInfo&#123; Name: &quot;XiMo&quot;, Age: 3, Password: &quot;123456&quot;, &#125; // c.JSON 实际上是将结构体和 map 类型的变量进行序列化（将对象转换为JSON格式的字符串的过程） // 注意 UserInfo.Name 在序列化中变成了 &quot;username&quot;，UserInfo.Age 变成了 &quot;age&quot; // &quot;-&quot; 表示忽略该字段，所以 UserInfo.Password 在序列化的时候会被忽略 // 响应将返回：&#123;&quot;username&quot;: &quot;XiMo&quot;, &quot;age&quot;: 3&#125; c.JSON(200, user) // // 2.使用 map // userMap := map[string]any&#123; // &quot;name&quot;: &quot;XiMo&quot;, // &quot;age&quot;: 3, // &#125; // c.JSON(200, userMap) // // 3.使用 gin.H // // gin.H 实际上是 map[string]any 的一种快捷方式 // c.JSON(200, gin.H&#123; // &quot;name&quot;: &quot;XiMo&quot;, // &quot;age&quot;: 3, // &#125;)&#125;func main() &#123; r := gin.Default() r.GET(&quot;/json&quot;, Json) r.Run()&#125; 其实除了 JSON 和 string 类型的返回，Gin 还给我们提供了响应 XML、YAML、HTML 等的方式，但由于使用较少，所以这里不多涉及，感兴趣的可以自行查阅 获取参数Query 查询参数 Query 参数是在 URL 中的一部分，用于向服务器发送额外的数据，由键值对组成，以 ? 为起始符号，键值对之间使用 &amp; 分隔，例如：/user/search?name=XiMo&amp;age=3 Query 参数常用于 HTTP GET 请求 常见的地方有搜索（浏览器等等） Gin 里面给我们封装的 Context 参数提供了丰富的方法帮我们获取 Query 参数 Query 方法 说明 Query 获取 key 对应的值，不存在返回空字符串 DefaultQuery key 不存在时返回一个默认值 GetQuery 获取 key 对应的值，并且返回 bool 标识，标识成功或者失败 QueryArray 获取 key 对应的值，值是一个字符串数组，不存在返回空字符串数组 GetQueryArray 获取 key 对应的值，并且返回 bool 标识，标识成功或者失败 QueryMap 获取 key 对应的值，值是一个字符串 map[string]string，不存在返回空 GetQueryMap 获取 key 对应的值，值是一个字符串 map[string]string，并且返回 bool 标识，标识成功或者失败 需要注意的是通过 Query 获取到的参数都是 string 类型 下面是一些代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func Query(c *gin.Context) &#123; // 访问 /query?name=ximo&amp;age=3&amp;sex= // Query 获取key对应的值，不存在返回空字符串 nameQuery := c.Query(&quot;name&quot;) ageQuery := c.Query(&quot;age&quot;) sexQuery := c.Query(&quot;sex&quot;) organizationQuery := c.Query(&quot;organization&quot;) c.JSON(200, gin.H&#123; &quot;nameQuery&quot;: nameQuery, &quot;ageQuery&quot;: ageQuery, &quot;sexQuery&quot;: sexQuery, &quot;organizationQuery&quot;: organizationQuery, &#125;) // // 访问 /query?name=ximo&amp;age=3&amp;sex= // // DefaultQuery key不存在时返回一个默认值 // organizationDefaultQuery := c.DefaultQuery(&quot;organization&quot;, &quot;精弘网络&quot;) // sexDefaultQuery := c.DefaultQuery(&quot;sex&quot;, &quot;male&quot;) // nameDefaultQuery := c.DefaultQuery(&quot;name&quot;, &quot;惜寞&quot;) // c.JSON(200, gin.H&#123; // &quot;organizationDefaultQuery&quot;: organizationDefaultQuery, // &quot;sexDefaultQuery&quot;: sexDefaultQuery, // &quot;nameDefaultQuery&quot;: nameDefaultQuery, // &#125;) // // 访问 /query?name=ximo&amp;age=3&amp;sex= // // GetQuery 获取key对应的值，并且返回bool标识，标识成功或者失败 // nameGetQuery, nameExist := c.GetQuery(&quot;name&quot;) // sexGetQuery, sexExist := c.GetQuery(&quot;sex&quot;) // organizationGetQuery, orgaorganizationExist := c.GetQuery(&quot;organization&quot;) // c.JSON(200, gin.H&#123; // &quot;nameGetQuery&quot;: nameGetQuery, // &quot;nameExist&quot;: nameExist, // &quot;sexGetQuery&quot;: sexGetQuery, // &quot;sexExist&quot;: sexExist, // &quot;organizationGetQuery&quot;: organizationGetQuery, // &quot;orgaorganizationExist&quot;: orgaorganizationExist, // &#125;) // // 访问 /query?name=ximo&amp;age=3&amp;sex=&amp;hobby=code&amp;hobby=sleep&amp;hobby= // // QueryArray // hobbyQuery := c.Query(&quot;hobby&quot;) // hobbyQueryArray := c.QueryArray(&quot;hobby&quot;) // nameQueryArray := c.QueryArray(&quot;name&quot;) // sexQueryArray := c.QueryArray(&quot;sex&quot;) // organizationQueryArray := c.QueryArray(&quot;organization&quot;) // c.JSON(200, gin.H&#123; // &quot;hobbyQuery&quot;: hobbyQuery, // &quot;hobbyQueryArray&quot;: hobbyQueryArray, // &quot;nameQueryArray&quot;: nameQueryArray, // &quot;sexQueryArray&quot;: sexQueryArray, // &quot;organizationQueryArray&quot;: organizationQueryArray, // &#125;) // // 访问 /query?name=ximo&amp;age=3&amp;sex=&amp;hobby=code&amp;hobby=sleep&amp;hobby= // // GetQueryArray // hobbyGetQueryArray, hobbyExist := c.GetQueryArray(&quot;hobby&quot;) // nameGetQueryArray, nameExist := c.GetQueryArray(&quot;name&quot;) // sexGetQueryArray, sexExist := c.GetQueryArray(&quot;sex&quot;) // organizationGetQueryArray, orgaorganizationExist := c.GetQueryArray(&quot;organization&quot;) // c.JSON(200, gin.H&#123; // &quot;hobbyGetQueryArray&quot;: hobbyGetQueryArray, // &quot;hobbyExist&quot;: hobbyExist, // &quot;nameGetQueryArray: &quot;: nameGetQueryArray, // &quot;nameExist&quot;: nameExist, // &quot;sexGetQueryArray&quot;: sexGetQueryArray, // &quot;sexExist&quot;: sexExist, // &quot;organizationGetQueryArray&quot;: organizationGetQueryArray, // &quot;orgaorganizationExist&quot;: orgaorganizationExist, // &#125;) // // 访问 /query?user[name]=ximo&amp;user[age]=3&amp;user[sex]=&amp;user[hobby]=code&amp;user[hobby]=sleep // // QueryMap // userQueryMap := c.QueryMap(&quot;user&quot;) // adminQueryMap := c.QueryMap(&quot;admin&quot;) // c.JSON(200, gin.H&#123; // &quot;userQueryMap&quot;: userQueryMap, // &quot;adminQueryMap&quot;: adminQueryMap, // &#125;) // // 访问 /query?user[name]=ximo&amp;user[age]=3&amp;user[sex]=&amp;user[hobby]=code&amp;user[hobby]=sleep // // GetQueryMap // userGetQueryMap, userExist := c.GetQueryMap(&quot;user&quot;) // adminGetQueryMap, adminExist := c.GetQueryMap(&quot;admin&quot;) // c.JSON(200, gin.H&#123; // &quot;userGetQueryMap&quot;: userGetQueryMap, // &quot;userExist&quot;: userExist, // &quot;adminGetQueryMap&quot;: adminGetQueryMap, // &quot;adminExist&quot;: adminExist, // &#125;)&#125;func main() &#123; r := gin.Default() r.GET(&quot;/query&quot;, Query) r.Run(&quot;:8080&quot;)&#125; Param 动态参数 Param 参数获取到的数据类型也是 string 类型 路由形式一般写成 /user/:name/:age，这里的 : 表示后面的参数是一个占位符 请求的参数可以通过 URL 路径传递，name 和 age 可以通过访问 /user/XiMo/3 这个路由去获取 XiMo 和 3 ，访问 /user/惜寞/4 可以获取 惜寞 和 4 Gin 给我们提供了 Param 方法去获取这些参数： 12345678910111213141516171819202122232425package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func main() &#123; r := gin.Default() // 注意会匹配 /param/XiMo 但不会匹配 /param/ 或者 /param r.GET(&quot;/param/:name&quot;, func(c *gin.Context) &#123; // 访问 /param/XiMo name := c.Param(&quot;name&quot;) // 不存在会返回空字符串 age := c.Param(&quot;age&quot;) c.JSON(200, gin.H&#123; &quot;name&quot;: name, &quot;age&quot;: age, &#125;) &#125;) r.Run(&quot;:8080&quot;)&#125; PostForm 表单参数 和 Query 很像，不同之处在于数据不通过 URL 来传递，而是处于请求的主体当中 表单参数常用于 POST 请求中 Gin 提供的 PostForm 函数与 Query 基本上一一对应的，具体情况见下表： Query 方法 PostForm 方法 说明 Query PostForm 获取 key 对应的值，不存在返回空字符串 DefaultQuery DefaultPostForm key 不存在时返回一个默认值 GetQuery GetPostForm 获取 key 对应的值，并且返回 bool 标识，标识成功或者失败 QueryArray PostFormArray 获取 key 对应的值，值是一个字符串数组，不存在返回空字符串数组 GetQueryArray GetPostFormArray 获取 key 对应的值，并且返回 bool 标识，标识成功或者失败 QueryMap PostFormMap 获取 key 对应的值，值是一个字符串 map[string]string，不存在返回空 GetQueryMap GetPostFomMap 获取 key 对应的值，值是一个字符串 map[string]string，并且返回 bool 标识，标识成功或者失败 下面是一些代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func PostForm(c *gin.Context) &#123; // PostForm 获取key对应的值，不存在返回空字符串 // name=ximo&amp;age=3&amp;sex= namePostForm := c.PostForm(&quot;name&quot;) agePostForm := c.PostForm(&quot;age&quot;) sexPostForm := c.PostForm(&quot;sex&quot;) organizationPostForm := c.PostForm(&quot;organization&quot;) c.JSON(200, gin.H&#123; &quot;namePostForm&quot;: namePostForm, &quot;agePostForm&quot;: agePostForm, &quot;sexPostForm&quot;: sexPostForm, &quot;organizationPostForm&quot;: organizationPostForm, &#125;) // // DefaultPostForm key不存在时返回一个默认值 // // name=ximo&amp;age=3&amp;sex= // organizationDefaultPostForm := c.DefaultPostForm(&quot;organization&quot;, &quot;精弘网络&quot;) // sexDefaultPostForm := c.DefaultPostForm(&quot;sex&quot;, &quot;male&quot;) // nameDefaultPostForm := c.DefaultPostForm(&quot;name&quot;, &quot;惜寞&quot;) // c.JSON(200, gin.H&#123; // &quot;organizationPostForm&quot;: organizationPostForm, // &quot;organizationDefaultPostForm&quot;: organizationDefaultPostForm, // &quot;sexPostForm&quot;: sexPostForm, // &quot;sexDefaultPostForm&quot;: sexDefaultPostForm, // &quot;namePostForm&quot;: namePostForm, // &quot;nameDefaultPostForm&quot;: nameDefaultPostForm, // &#125;) // // GetPostForm 获取key对应的值，并且返回bool标识，标识成功或者失败 // // name=ximo&amp;age=3&amp;sex= // nameGetPostForm, nameExist := c.GetPostForm(&quot;name&quot;) // sexGetPostForm, sexExist := c.GetPostForm(&quot;sex&quot;) // organizationGetPostForm, orgaorganizationExist := c.GetPostForm(&quot;organization&quot;) // c.JSON(200, gin.H&#123; // &quot;nameGetPostForm&quot;: nameGetPostForm, // &quot;nameExist&quot;: nameExist, // &quot;sexGetPostForm&quot;: sexGetPostForm, // &quot;sexExist&quot;: sexExist, // &quot;organizationGetPostForm&quot;: organizationGetPostForm, // &quot;orgaorganizationExist&quot;: orgaorganizationExist, // &#125;) // // PostFormArray 获取key对应的值，值是一个字符串数组，不存在返回空字符串数组 // // name=ximo&amp;age=3&amp;sex=&amp;hobby=code&amp;hobby=sleep&amp;hobby= // hobbyPostForm := c.PostForm(&quot;hobby&quot;) // hobbyPostFormArray := c.PostFormArray(&quot;hobby&quot;) // namePostFormArray := c.PostFormArray(&quot;name&quot;) // sexPostFormArray := c.PostFormArray(&quot;sex&quot;) // organizationPostFormArray := c.PostFormArray(&quot;organization&quot;) // c.JSON(200, gin.H&#123; // &quot;hobbyPostForm&quot;: hobbyPostForm, // &quot;hobbyPostFormArray&quot;: hobbyPostFormArray, // &quot;namePostFormArray&quot;: namePostFormArray, // &quot;sexPostFormArray&quot;: sexPostFormArray, // &quot;organizationPostFormArray&quot;: organizationPostFormArray, // &#125;) // // GetPostFormArray 获取key对应的值，并且返回bool标识，标识成功或者失败 // // name=ximo&amp;age=3&amp;sex=&amp;hobby=code&amp;hobby=sleep&amp;hobby= // hobbyGetPostFormArray, hobbyExist := c.GetPostFormArray(&quot;hobby&quot;) // nameGetPostFormArray, nameExist := c.GetPostFormArray(&quot;name&quot;) // sexGetPostFormArray, sexExist := c.GetPostFormArray(&quot;sex&quot;) // organizationGetPostFormArray, orgaorganizationExist := c.GetPostFormArray(&quot;organization&quot;) // c.JSON(200, gin.H&#123; // &quot;hobbyGetPostFormArray&quot;: hobbyGetPostFormArray, // &quot;hobbyExist&quot;: hobbyExist, // &quot;nameGetPostFormArray: &quot;: nameGetPostFormArray, // &quot;nameExist&quot;: nameExist, // &quot;sexGetPostFormArray&quot;: sexGetPostFormArray, // &quot;sexExist&quot;: sexExist, // &quot;organizationGetPostFormArray&quot;: organizationGetPostFormArray, // &quot;orgaorganizationExist&quot;: orgaorganizationExist, // &#125;) // // PostFormMap 获取key对应的值，值是一个字符串map[string]string，不存在返回空 // // user[name]=ximo&amp;user[age]=3&amp;user[sex]=&amp;user[hobby]=code&amp;user[hobby]=sleep // userPostFormMap := c.PostFormMap(&quot;user&quot;) // adminPostFormMap := c.PostFormMap(&quot;admin&quot;) // c.JSON(200, gin.H&#123; // &quot;userPostFormMap&quot;: userPostFormMap, // &quot;adminPostFormMap&quot;: adminPostFormMap, // &#125;) // // GetPostFormMap 获取key对应的值，值是一个字符串map[string]string，并且返回bool标识，标识成功或者失败 // // user[name]=ximo&amp;user[age]=3&amp;user[sex]=&amp;user[hobby]=code&amp;user[hobby]=sleep // userGetPostFormMap, userExist := c.GetPostFormMap(&quot;user&quot;) // adminGetPostFormMap, adminExist := c.GetPostFormMap(&quot;admin&quot;) // c.JSON(200, gin.H&#123; // &quot;userGetPostFormMap&quot;: userGetPostFormMap, // &quot;userExist&quot;: userExist, // &quot;adminGetPostFormMap&quot;: adminGetPostFormMap, // &quot;adminExist&quot;: adminExist, // &#125;)&#125;func main() &#123; r := gin.Default() r.POST(&quot;/post-form&quot;, PostForm) r.Run(&quot;:8080&quot;)&#125; GetRawData 原始参数我们如果想去获取前端传来的 JSON 数据类型就需要用到这个方法，但是实际上 Gin 帮我们封装了一种更简便的方式（参数绑定里的 ShouldBindJSON 方法），所以这个方法我们很少会用到，因此不专门去讲，有兴趣了解的可以看看 利用 GetRawData 方法可以获取请求体中 body 的内容，我们也是通过这种方式来获取前端给我们传来的 JSON 数据，但实际上通过这个方法我们不仅仅是可以获取 JSON ，还可以获取很多别的一些数据类型像是 xml、html 等等，这里我们仅仅是用获取 JSON 数据为例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;github.com/gin-gonic/gin&quot;)func Raw(c *gin.Context) &#123; // GetRawData 实际上是去获取 request.body 中的内容 // 它返回两个参数，一个是获取到的 []byte 类型的 body 数据，另一个是 error 类型 // 这里忽略了 error 的处理 data, _ := c.GetRawData() // 打印 data 可以看到传过来的原始数据 fmt.Println(data) // 将 []byte 转成 string 类型可以看它实际传过来的内容 fmt.Println(string(data)) // 注：下面是对 JSON 数据类型的处理 // 我们可以通过 json 包里的 Unmarshal 来对 JSON 数据类型进行反序列化 // 就是我前几节课所说的用 JSON 中的数据去给结构体和 map 类型变量赋值 // 1.结构体，tag 在反序列化的时候依旧可用，会根据 tag 将对应的值赋给对应的键 type UserInfo struct &#123; Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;` Sex string `json:&quot;sex&quot;` &#125; var userStruct UserInfo // JSON 反序列化，会返回一个 error，这里忽略了对其的处理 _ = json.Unmarshal(data, &amp;userStruct) c.JSON(200, userStruct) // // 2.map // var userMap map[string]interface&#123;&#125; // _ = json.Unmarshal(data, &amp;userMap) // //获取 JSON 中的 key，注意使用 [&quot;key&quot;] 获取 // // name := userMap[&quot;name&quot;] // // age := userMap[&quot;age&quot;] // // sex := userMap[&quot;sex&quot;] // c.JSON(200, userMap)&#125;func main() &#123; r := gin.Default() r.POST(&quot;/raw&quot;, Raw) r.Run()&#125; 我们将上面的代码运行起来，然后可以利用 apifox 新建一个快捷请求去查看效果： 发送请求后的结果如下： 说明我们成功的收到了前端传来的 JSON 参数并且解析到了我们的结构体和 map 上，并将其响应返回给了前端 Bind 参数绑定下面是 Gin 的官方文档给出的介绍：Gin 提供了两类绑定方法： Type - Must bind Methods - Bind, BindJSON, BindXML, BindQuery, BindYAML Behavior - 这些方法属于 MustBindWith 的具体调用。 如果发生绑定错误，则请求终止，并触发 c.AbortWithError(400, err).SetType(ErrorTypeBind)。响应状态码被设置为 400 并且 Content-Type 被设置为 text/plain; charset=utf-8。 如果您在此之后尝试设置响应状态码，Gin 会输出日志 [GIN-debug] [WARNING] Headers were already written. Wanted to override status code 400 with 422。 如果您希望更好地控制绑定，考虑使用 ShouldBind 等效方法。 Type - Should bind Methods - ShouldBind, ShouldBindJSON, ShouldBindXML, ShouldBindQuery, ShouldBindYAML Behavior - 这些方法属于 ShouldBindWith 的具体调用。 如果发生绑定错误，Gin 会返回错误并由开发者处理错误和请求。 使用 Bind 方法时，Gin 会尝试根据 Content-Type 推断如何绑定。 如果你明确知道要绑定什么，可以使用 MustBindWith 或 ShouldBindWith。 你也可以指定必须绑定的字段。 如果一个字段的 tag 加上了 binding:&quot;required&quot;，但绑定时是空值, Gin 会报错。 我们一般不会使用 Must Bind 相关的绑定方法，因为绑定一旦发生错误，就会修改你的响应状态码，不便于你对绑定状态的控制 通常使用 Should Bind 方法，发生绑定错误可以自由进行处理 简单来说：为了能够更方便的获取请求相关参数，提高开发效率，我们可以基于请求的 Content-Type 识别请求数据类型并利用反射机制自动提取请求中 Query、Param、Form、JSON 等参数到结构体中。 下面的示例代码演示了 ShouldBind() 强大的功能，它能够基于请求自动提取相应类型的数据，并把值绑定到指定的结构体对象中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package mainimport ( &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot;)type UserInfo struct &#123; Name string `form:&quot;name_form&quot; uri:&quot;name_uri&quot; json:&quot;name_form&quot; binding:&quot;required&quot;` // binding:&quot;required&quot; tag 表示该属性值不能为空 Age int `form:&quot;age_form&quot; uri:&quot;age_uri&quot; json:&quot;age_form&quot;` Sex string `form:&quot;sex_form&quot; uri:&quot;sex&quot; json:&quot;sex_form&quot;`&#125;func main() &#123; r := gin.Default() // 对应反射 tag form // 绑定 Query 示例 // 1. /query?name_form=ximo&amp;age_form=3&amp;sex_form=male 正常响应 // 2. /query?name_form=ximo&amp;age_form=3&amp;sex_form= 或 /query?name_form=ximo&amp;age_form=3 正常响应 // 3. /query?age_form=3&amp;sex_form=male 或 /query?name_form=&amp;age_form=3&amp;sex_form=male 返回 error，binding:&quot;required&quot; tag 表示 Name 属性值不能为空 r.GET(&quot;/query&quot;, func(c *gin.Context) &#123; var user UserInfo // 根据请求的 Content-type 自动识别请求数据类型并利用反射机制自动提取请求中的参数到结构体中 // 会返回一个 error 参数 err := c.ShouldBind(&amp;user) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;error&quot;: err.Error(), &#125;) return &#125; c.JSON(200, user) &#125;) // 对应反射 tag uri // 绑定 Param 的示例 /param/ximo/3/male r.POST(&quot;/param/:name_uri/:age_uri/:sex_uri&quot;, func(c *gin.Context) &#123; var user UserInfo // 获取 Param 比较特殊，不能直接通过 ShouldBind 绑定 err := c.ShouldBindUri(&amp;user) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;error&quot;: err.Error(), &#125;) return &#125; c.JSON(200, user) &#125;) // 对应反射 tag json // 绑定 JSON 的示例 // 1. &#123;&quot;user_json&quot;: &quot;ximo&quot;, &quot;age_json&quot;: 3, &quot;sex_json&quot;: male&#125; 正常响应 // 2. &#123;&quot;user_json&quot;: &quot;ximo&quot;, &quot;age_json&quot;: 3&#125; 或 &#123;&quot;user_json&quot;: &quot;ximo&quot;, &quot;age_json&quot;: 3, &quot;sex_json&quot;:&quot;&quot;&#125; 正常响应 // 3. &#123;&quot;age_json&quot;: 3, &quot;sex_json&quot;: male&#125; 或 &#123;&quot;user_json&quot;: &quot;&quot;, &quot;age_json&quot;: 3, &quot;sex_json&quot;: male&#125;返回 error，binding:&quot;required&quot; tag 表示 Name 属性值不能为空 r.POST(&quot;/json&quot;, func(c *gin.Context) &#123; var user UserInfo err := c.ShouldBind(&amp;user) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;error&quot;: err.Error(), &#125;) return &#125; c.JSON(200, user) &#125;) // 对应反射 tag form（和 Query 相同） // 绑定 form 表单示例 // 1. name_form=ximo&amp;age_form=3&amp;sex_form=male 正常响应 // 2. name_form=ximo&amp;age_form=3&amp;sex_form= 或 name_form=ximo&amp;age_form=3 正常响应 // 3. age_form=3&amp;sex_form=male 或 name_form=&amp;age_form=3&amp;sex_form=male 返回 error，binding:&quot;required&quot; tag 表示 Name 属性值不能为空 r.POST(&quot;/post-form&quot;, func(c *gin.Context) &#123; var user UserInfo err := c.ShouldBind(&amp;user) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;error&quot;: err.Error(), &#125;) return &#125; c.JSON(200, user) &#125;) r.Run()&#125; Should Bind 会按照下面的顺序解析请求中的数据完成绑定： 如果是 GET 请求，只使用 Form 绑定（query） 其他请求，根据 Content-Type 自动识别对应类型，匹配不上会默认使用 Form（form-data） 如果你明确知道要绑定什么数据类型，推荐直接使用 ShouldBindWith 比如你明确接收到的是一个 JSON 数据，就可以使用 ShouldBindWith(&amp;user, binding.JSON) 或者 ShouldBindJSON(&amp;user) （实际上是上面方法的缩写，通常写这个） 我们主要知道如何用 ShouldBindJSON 去获取前端发送过来的 JSON 数据就可以了 12345678910111213141516171819202122232425262728293031323334package mainimport ( &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot;)type UserInfo struct &#123; Name string `json:&quot;name&quot; binding:&quot;required&quot;` Age int `json:&quot;age&quot;` Sex string `json:&quot;sex&quot;`&#125;func main() &#123; r := gin.Default() r.POST(&quot;/json&quot;, func(c *gin.Context) &#123; var user UserInfo // 绑定 JSON，接收前端发送过来的 JSON 数据 err := c.ShouldBindJSON(&amp;user) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;error&quot;: err.Error(), &#125;) return &#125; c.JSON(200, user) &#125;) r.Run()&#125; 路由在 Gin 中，路由是指将 HTTP 请求映射到相应的处理函数的机制 普通路由1234r.GET(&quot;/path&quot;, func(c *gin.Context)&#123;...&#125;)r.POST(&quot;/path&quot;, func(c *gin.Context)&#123;...&#125;)r.PUT(&quot;/path&quot;, func(c *gin.Context)&#123;...&#125;)r.DELETE(&quot;/path&quot;, func(c *gin.Context)&#123;...&#125;) Any 方法 可以匹配所有 HTTP 请求 1r.Any(&quot;/path&quot;, func(c *gin.Context) &#123;...&#125;) NoRoute 方法 用于处理找不到路由的情况，即当没有匹配到任何定义的路由时执行的处理函数 1r.NoRoute(func(c *gin.Context) &#123;...&#125;) NoMethod 方法 用于处理请求的 HTTP 方法不被允许的情况，即当请求的 HTTP 方法与路由定义的方法不匹配时执行的处理函数 1r.NoMethod(func(c *gin.Context) &#123;...&#125;) 参数路由12r.GET(&quot;/path/:id&quot;, func(c *gin.Context) &#123;...&#125;) // 匹配带有 id 参数的GET请求r.GET(&quot;/path/*action&quot;, func(c *gin.Context) &#123;...&#125;) // 匹配任意路径的 GET 请求，只要是以 /path 开头 通过参数路由，可以根据不同的参数值生成不同的 URL，实现对不同资源的访问。 路由组我们可以将拥有共同 URL 前缀的路由划分为一个路由组，习惯性一对 &#123;&#125; 包裹同组的路由，这只是为了看着清晰，用不用 &#123;&#125; 包裹功能上没什么区别通常将路由分组用在划分业务逻辑或划分 API 版本时 12345678910111213user := r.Group(&quot;/user&quot;) &#123; user.POST(&quot;/register&quot;, func(c *gin.Context) &#123;...&#125;) user.POST(&quot;/login&quot;, func(c *gin.Context) &#123;...&#125;) user.POST(&quot;/exit&quot;, func(c *gin.Context) &#123;...&#125;) &#125;admin := r.Group(&quot;/admin&quot;) &#123; admin.POST(&quot;/register&quot;, func(c *gin.Context) &#123;...&#125;) admin.POST(&quot;/login&quot;, func(c *gin.Context) &#123;...&#125;) admin.POST(&quot;/exit&quot;, func(c *gin.Context) &#123;...&#125;) &#125; 路由组支持嵌套 1234567891011121314user := r.Group(&quot;/user&quot;) &#123; user.POST(&quot;/register&quot;, func(c *gin.Context) &#123;...&#125;) // 路由组嵌套 login := user.Group(&quot;/login&quot;) &#123; login.POST(&quot;/email&quot;, func(c *gin.Context) &#123;...&#125;) login.POST(&quot;/phone&quot;, func(c *gin.Context) &#123;...&#125;) login.POST(&quot;/password&quot;, func(c *gin.Context) &#123;...&#125;) &#125; user.POST(&quot;/exit&quot;, func(c *gin.Context) &#123;...&#125;) &#125; 其实可以类比成文件夹 RESTful APIREST 与技术无关，代表的是一种软件架构风格，REST 是 Representational State Transfer 的简称，中文翻译为“表征状态转移”或“表现层状态转化”。 简单来说，REST 的含义就是客户端（前端）与 Web 服务器（后端）之间进行交互的时候，使用 HTTP 协议中的 4 个请求方法代表不同的动作。 GET 用来获取资源 POST 用来新建资源 PUT 用来更新资源 DELETE 用来删除资源 只要 API 程序遵循了 REST 风格，那就可以称其为 RESTful API。目前在前后端分离的架构中，前后端基本都是通过 RESTful API 来进行交互。 例如，我们现在要编写一个管理外卖订单的系统，对一个订单进行查询、创建、更新和删除等操作，我们在编写程序的时候就要设计客户端浏览器与我们 Web 服务端交互的方式和路径。按照经验我们通常会设计成如下模式： 请求方法 URL 含义 GET &#x2F;order 查询订单信息 POST &#x2F;create_order 创建订单 POST &#x2F;update_order 更新订单信息 POST &#x2F;delete_order 删除订单 同样的需求我们按照 RESTful API 设计如下： 请求方法 URL 含义 GET &#x2F;order 查询订单信息 POST &#x2F;order 创建订单 PUT &#x2F;order 更新订单信息 DELETE &#x2F;order 删除订单 Gin 框架支持开发 RESTful API 的开发。 123456789101112 // 对订单进行增删改查的操作 // 可能的写法 r.GET(&quot;/order&quot;, func(c *gin.Context) &#123;&#125;) r.POST(&quot;/create_order&quot;, func(c *gin.Context) &#123;&#125;) r.POST(&quot;/update_order&quot;, func(c *gin.Context) &#123;&#125;) r.POST(&quot;/delete_order&quot;, func(c *gin.Context) &#123;&#125;) // RESRful API 风格 r.GET(&quot;/order&quot;, func(c *gin.Context) &#123;...&#125;) r.POST(&quot;/order&quot;, func(c *gin.Context) &#123;...&#125;) r.PUT(&quot;/order&quot;, func(c *gin.Context) &#123;...&#125;) r.DELETE(&quot;/order&quot;, func(c *gin.Context) &#123;...&#125;) 中间件Gin 框架允许开发者在处理请求的过程中，加入用户自己的钩子（Hook）函数。这个钩子函数就叫中间件，中间件适合处理一些公共的业务逻辑，比如登录认证、权限校验、数据分页、记录日志、耗时统计等。中间件本质上是一个 handler，可以作用在单路由、路由组和全局的 Engine。 定义中间件 Gin 中的中间件必须是一个 gin.HandlerFunc 类型，其实和我们的处理函数是同样的类型。 下面其实就是一个中间件，只不过没有什么实际的作用： 12345678func m1(c *gin.Context) &#123; fmt.Println(&quot;这是一个中间件&quot;) // 中间件也可以返回响应 c.JSON(200, gin.H&#123; &quot;msg&quot;: &quot;中间件&quot;, &#125;)&#125; 我们可以把它注册到我们的路由当中： 1234567891011121314func main() &#123; r := gin.Default()\t// 将 m1 作为一个中间件注册到该路由 r.GET(&quot;/&quot;, m1, func(c *gin.Context) &#123; fmt.Println(&quot;这是处理函数&quot;) c.JSON(200, gin.H&#123; &quot;msg&quot;: &quot;处理函数&quot;, &#125;) &#125;) r.Run()&#125; 实际上访问 127.0.0.1:8080&#x2F; 的时候会返次两个响应，但是我们基本不会这么写，一次请求对应多次响应是不准确也是不安全的，仅仅是用来做一个示例 根据打印和响应我们也可以发现执行顺序是中间件在处理函数之前 Abort() 和 Next() Abort() 会中止当前请求，不执行该语句后面的所有内容，即使后面可能处理函数都没有执行 注意和 return 不同，return 只结束该函数内的内容，不影响后续函数的执行 Next() 从当前 handler 的调用位置跳到下一个 handler 执行，执行完后续 handler（如果没有再次调用 next ），再返回上一个 next 调用位置继续往下执行 1234567891011121314151617181920212223242526272829func m1(c *gin.Context) &#123; fmt.Println(&quot;m1 in...&quot;) // 跳到下一个 handler c.Next() fmt.Println(&quot;m1 out...&quot;)&#125;func m2(c *gin.Context) &#123; fmt.Println(&quot;m2 in...&quot;) // 跳到下一个 handler c.Next() fmt.Println(&quot;m2 out...&quot;)&#125;func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, m1, m2, func(c *gin.Context) &#123; fmt.Println(&quot;/ in...&quot;) fmt.Println(&quot;/ out...&quot;) &#125;) r.Run()&#125; 这里写了两个中间件 m1 和 m2，遇到 Next 后会跳转到下一个 Handler 本质上就是一个函数嵌套调用的过程 所以运行后的输出结果为： 123456m1 in...m2 in.../ in.../ out...m2 out...m1 out... 如果将 m1 中的 c.Next() 换成 c.Abort() 12345678func m1(c *gin.Context) &#123; fmt.Println(&quot;m1 in...&quot;) // 终止当前请求，后续函数和代码都不会执行 c.Abort() fmt.Println(&quot;m1 out...&quot;)&#125; 运行后的输出结果为： 1m1 in... 运行到 Abort() 就结束了 Set() 和 Get() 用于中间件（handler）之间的通信，可以是在 handler 之内，也可以是之间 因为中间件实际上是不同的函数，在不同的函数之间我们不能直接传递数据，想要传递数据就需要用到 Gin 给我们封装好的 Context 中的 Set 和 Get 方法 Set：用于在请求上下文中设置数据。可以使用 c.Set(key, value) 方法将某个键和对应的值存储到请求上下文中 Get：用于从请求上下文中获取数据。可以使用 c.Get(key) 方法根据键获取在请求上下文中存储的值 先 Set 再 Get 123456789101112131415161718192021222324252627282930313233343536373839type UserInfo struct &#123; Name string Age int&#125;func m1(c *gin.Context) &#123; user := UserInfo&#123; Name: &quot;XiMo&quot;, Age: 3, &#125; // 将 user 以键值对的形式存储到 Context 中 c.Set(&quot;user&quot;, user)&#125;func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, m1, func(c *gin.Context) &#123; // 根据 key 返回 value（any 类型）和一个 bool 值 // bool 值用来判断是否有这个 key user, ok := c.Get(&quot;user&quot;) fmt.Println(gin.H&#123; &quot;userExist&quot;: ok, &#125;) // 断言，会返回断言类型的值和一个 bool 值 // bool 值用来判断是否断言成功 // 断言失败，返回的值为断言类型的零值 _user, _ok := user.(UserInfo) fmt.Println(gin.H&#123; &quot;type assertion&quot;: _ok, &#125;) fmt.Println(_user) &#125;) r.Run()&#125; 记录接口耗时的中间件我们可以写一个中间件用来记录接口耗时 123456789101112131415161718// StatCost 是一个统计请求耗时的中间件func StatCost(c *gin.Context) &#123; // 请求开始的时间 start := time.Now()\t// 请求前 // 调用该请求的剩余处理程序 c.Next()\t// 请求后 // 计算耗时 cost := time.Since(start) // 日志形式打印 log.Println(cost)&#125; 注册中间件在 gin 框架中，我们可以为每个路由添加任意数量的中间件。 为全局路由注册1234567891011121314151617func main() &#123; r := gin.Default()\t// 全局注册 StatCost 中间件 r.Use(StatCost) r.GET(&quot;/&quot;, func(c *gin.Context) &#123; // 停1秒 time.Sleep(time.Second) c.JSON(200, gin.H&#123; &quot;msg&quot;: &quot;Hello 精弘!&quot;, &#125;) &#125;) r.Run()&#125; 我们之前所讲的 gin.Default() 实际上就默认帮我们注册了两个全局中间件 Logger() 和 Recovery() 如果不想集成这两个中间件可以使用 gin.New() 方法 为某个路由单独注册123456789// 给 / 路由单独注册中间件（可注册多个）\tr.GET(&quot;/&quot;, StatCost, func(c *gin.Context) &#123; // 停1秒 time.Sleep(time.Second) c.JSON(200, gin.H&#123; &quot;msg&quot;: &quot;Hello 精弘!&quot;, &#125;)\t&#125;) 为路由组注册中间件为路由组注册中间件有以下两种写法。写法 1： 123456user := r.Group(&quot;/user&quot;, StatCost)&#123; user.POST(&quot;/register&quot;, func(c *gin.Context) &#123;...&#125;) user.POST(&quot;/login&quot;, func(c *gin.Context) &#123;...&#125;) user.POST(&quot;/exit&quot;, func(c *gin.Context) &#123;...&#125;)&#125; 写法 2： 1234567user := r.Group(&quot;/user&quot;)user.Use(StatCost)&#123; user.POST(&quot;/register&quot;, func(c *gin.Context) &#123;...&#125;) user.POST(&quot;/login&quot;, func(c *gin.Context) &#123;...&#125;) user.POST(&quot;/exit&quot;, func(c *gin.Context) &#123;...&#125;)&#125; 通过路由组注册中间件易于定义中间件的使用范围比如我只有 &#x2F;admin 相关的路由需要鉴权，判断是不是管理员，就可以通过路由组的方式去管理，而不需要单个一个个的注册或者全局注册（没有必要给所有路由都加上该中间件）","tags":["Go","Gin"],"categories":["Go Web"]},{"title":"ClickHouse——你没有见过的列存储","path":"/posts/clickhouse-column-storage/","content":"数据库基本概念数据库是结构化信息或数据的有序集合，一般以电子形式存储在计算机系统中。通常由数据库管理系统(DBMS)来控制。在现实中，数据、DBMS 及关联应用一起被称为数据库系统，通常简称为数据库 一个简单的例子 数据解析整理成有序集合 可以通过查询语言获取想要的信息 数据库的类型 数据库有很多种，至于各种数据库孰优孰劣，主要取决于企业希望如何使用数据 关系数据库：关系型数据库是把数据以表的形式进行储存，然后再各个表之间建立关系，通过这些表之间的关系来操作不同表之间的数据 非关系数据库 ： NoSQL 或非关系数据库，支持存储和操作非结构化及半结构化数据。相比于关系型数据库，NoSQL 没有固定的表结构，且数据之间不存在表与表之间的关系，数据之间可以是独立的。NoSQL 的关键是它们放弃了传统关系型数据库的强事务保证和关系模型，通过所谓最终一致性和非关系数据模型（例如键值对，图，文档）来提高 Web 应用所注重的高可用性和可扩展性 单机数据库：在一台计算机上完成数据的存储和查询的数据库系统 分布式数据库 ： 分布式数据库由位于不同站点的两个或多个文件组成。数据库可以存储在多台计算机上，位于同一个物理位置，或分散在不同的网络上 OLTP 数据库 ： OLTP（Online transactional processing）数据库是一种高速分析数据库，专为多个用户执行大量事务而设计 OLAP 数据库：OLAP (Online analytical processing) 数据库旨在同时分析多个数据维度，帮助团队更好地理解其数据中的复杂关系 OLAP 数据库 大量数据的读写，PB 级别的存储 多维分析，复杂的聚合函数 窗口函数，自定义 UDF (User Define Fucntion) 离线&#x2F;实时分析 SQL 一种编程语言，目前几乎所有的关系数据库都使用 SQL (Structured Query Language ) 编程语言来查询、操作和定义数据，进行数据访问控制 SQL 的结构 一个简单的 SQL 查询包含 SELECT 关键词。星号(“*“)也可以用来指定查询应当返回查询表所有字段，可选的关键词和子句 FROM子句指定了选择的数据表。FROM子句也可以包含JOIN 二层子句来为数据表的连接设置规则 WHERE子句后接一个比较谓词以限制返回的行。WHERE子句仅保留返回结果里使得比较谓词的值为 True 的行 GROUP BY子句用于将若干含有相同值的行合并。 GROUP BY通常与 SQL 聚合函数连用，或者用于清除数据重复的行。GROUP BY子句要用在WHERE子句之后 HAVING子句后接一个谓词来过滤从GROUP BY子句中获得的结果，由于其作用于GROUP BY子句之上，所以聚合函数也可以放到其谓词中 ORDER BY子句指明将哪个字段用作排序关键字，以及排序顺序(升序&#x2F;降序)，如果无此子句，那么返回结果的顺序不能保证有序 SQL 的用途 定义数据模型 读写数据库数据 SQL 的优点 标准化，ISO 和 ANSI 是长期建立使用的 SQL 数据库标准 高度非过程化，用 SQL 进行数据操作，用户只需提出“做什么”，而不必指明“怎么做”，因此用户无须了解存取路径，存取路径的选择以及 SQL 语句的操作过程由系统自动完成。这不但大大减轻了用户负担，而且有利于提高数据独立性 以同一种语法结构提供两种使用方式，用户可以在终端上直接输入 SQL 命令对数据库进行操作。作为嵌入式语言，SQL 语句能够嵌入到高级语言（如 C、C#、JAVA）程序中，供程序员设计程序时使用。而在两种不同的使用方式下，SQL 的语法结构基本上是一致的 语言简洁，易学易用：SQL 功能极强，但由于设计巧妙，语言十分简洁，完成数据定义、数据操纵、数据控制的核心功能只用了 9 个动词：CREATE、ALTER、DROP、SELECT、INSERT、UPDATE、DELETE、GRANT、REVOKE。且 SQL 语言语法简单，接近英语口语，因此容易学习，也容易使用 数据库的架构 SQL 的执行 Parser：词法分析，语法分析，生成 AST 树 (Abstract syntax tree) Analyzer：变量绑定、类型推导、语义检查、安全、权限检查、完整性检查等，为生成计划做准备 例如： 判断 a，b 是不是类型正确 a，b 是不是来自表 t group by 字段是否合法，是否存在聚合函数 Optimizer：为查询生成性能最优的执行计划，进行代价评估 Executor：将执行计划翻译成可执行的物理计划并驱动其执行 存储引擎 管理内存数据结构 索引 内存数据 缓存 Query cache Data cache Index cache 管理磁盘数据 磁盘数据的文件格式 磁盘数据的增删查改 读写算子 数据写入逻辑 数据读取逻辑 如何存储数据？ 是否可以并发处理 是否可以构建索引 行存、列存或者行列混合存储 如何读写数据？ 读多写少 读少写多 点查场景 分析型场景 列式存储 列式存储的优点 数据压缩 数据压缩可以使读的数据量更少，在 IO 密集型计算中获得大的性能优势 相同类型压缩效率更高 排序之后压缩效率更高 可以针对不同类型使用不同的压缩算法 几种常见的压缩算法 LZ4 (5,4) 代表向前 5 个 byte，匹配到的内容长度有 4，即”bcde”是一个重复 重复项越多或者越长，压缩率就会越高 Run-length encoding 压缩重复的数据 可以在压缩数据上直接计算 Delta encoding 将数据存储为连续数据之间的差异，而不是直接存储数据本身 特定算子也能直接在压缩数据上计算 数据选择 可以选择特定的列做计算而不是读所有列 对聚合计算友好 延迟物化 物化：将列数据转换为可以被计算或者输出的行数据或者内存数据结果的过程，物化后的数据通常可以用来做数据过滤，聚合计算，Join 延迟物化：尽可能推迟物化操作的发生 缓存友好 CPU &#x2F; 内存带宽友好 可以利用到执行计划和算子的优化，例如 filter 保留直接在压缩列做计算的机会 向量化 SIMD (single instruction multiple data)，对于现代多核 CPU，其都有能力用一条指令执行多条数据 如果这时候 CPU 也可以并行的计算我们写的代码，那么理论上我们的处理速度就会是之前代码的 100 倍，幸运的是 SIMD 指令就是完成这样的工作的，用 SIMD 指令完成这样代码设计和执行就叫做向量化 指令集 SIMD 程序使用的指令集有 SSE 和 AVX 系列，AVX 有 AVX-256 和 AVX-512，SSE 提供 128-bits 的寄存器，AVX-256 提供 256-bits，AVX-512 提供 512bits 的寄存器 数据格式要求 需要处理多个数据，因此数据需要是连续内存 需要明确数据类型 执行模型 数据需要按批读取 函数的调用需要明确数据类型 列存数据库适合设计出这样的执行模型，从而使用向量化技术 按列读取 每种列类型定义数据读写逻辑 函数按列类型处理 行存 VS 列存 ClickHouse 存储设计表定义和结构 集群架构 引擎架构 存储架构 文件组织 part 和 partition part 是物理文件夹的名字 partition 是逻辑结构 part 和 column 每个 column 都是一个文件 所有的 column 文件都在自己的 part 文件夹下 column 和 index 一个 part 有一个主键索引 每个 column 都有列索引 索引设计 Hash index 将输入的 key 通过一个 HashFunction 映射到一组 bucket 上 每个 bucket 都包含一个指向一条记录的地址 哈希索引在查找的时候只适用于等值比较 B-Tree 数据写入是有序的，支持增删查改 每个节点有多个孩子节点 每个节点都按照升序排列 key 值 每个 key 有两个指向左右孩子节点的引用 左孩子节点保存的 key 都小于当前 key 右孩子节点的保存的 key 都大于当前 key B+Tree 所有的数据都存储在叶子节点，非叶子节点只保存 key 值 叶子节点维护到相邻叶子节点的引用 可以通过 key 值做二分查找，也可以通过叶子节点做顺序访问 对于大数据量，B(B+)-Tree 深度太高 索引数据量太大，多个列如何平衡查询和存储——LSM-Tree OLAP 场景写入量非常大，如何优化写入 Log-structured merge-tree(LSM tree)是一种为大吞吐写入场景而设计的数据结构 着重优化顺序写入 主要数据结构 SSTables Memtable SSTables Key 按顺序存储到文件中，称为 segment 包含多个 segment 每个 segment 写入磁盘后都是不可更改的，新加的数据只能生成新的 segment Memtable 在内存中的数据保存在 memtable 中，大多数实现都是一颗 Binary search tree 当 memtable 存储的数据到达一定的阈值的时候，就会按顺序写入到磁盘 数据查询 需要从最新的 segment 开始遍历每个 key 也可以为每个 segment 建一个索引，例如 Compaction(合并) Compaction 指将多个 segments 合并成一个 segments 的过程 一般是有一个后台线程完成 不同的 segments 写入新的 segment 的时候也是需要排序，形成新的 segment 之后，旧的 segment 文件就会被删除 索引实现 主键索引 数据按照主键顺序依次做排序 首先按照 UserID 做排序 再按照 URL 排序 最后是 EventTime 数据被划分成 granule granule 是最小的数据读取单元 不同的 granulas 可以并行读取 每个 granule 都对应 primary.idx 里面的一行 默认每 8192 行记录主键的一行值，primary.idx 需要被全部加载到内存里面 里面保存的每一行数据被称为一个 index mark 每个列都有这样一个 mark 文件 mark 文件保存的是每个 granule 的物理地址 每一列都有一个自己的 mark 文件 mark 文件里面的每一行存储两个地址 第一个地址称为 block_offset，用于定位一个 granule 的压缩数据在物理文件中的位置，压缩数据会以一个 block 为单位解压到内存中 第二个地址称为 granule_offset，用于定位一个 granule 在解压之后的 block 中的位置 缺陷：数据按照 key 的顺序做排序，因此只有第一个 key 的过滤效果好，后面的 key 过滤效果依赖第一个 key 的基数大小 查询优化 secondary index：在 URL 列上构建二级索引 构建多个主键索引 再建一个表 数据需要同步两份 查询需要用户判断查哪张表 建一个物化视图 物化视图：可以通过 select 查询将一个表的数据写入一张隐式表 数据自动同步到隐式表 查询需要用户判断查哪张表 使用 Projection projection：类似于物化试图，但是不是将数据写入新的表，而是存储在原始表中，以一个列文件的形式存在 数据自动同步到隐式表 查询自动路由到最优的表 小结 主键包含的数据顺序写入 主键构造一个主键索引 每个列构建一个稀疏索引 通过 mark 的选择让主键索引可以定位到每一列的索引 可以通过多种手段优化非主键列的索引 数据合并 一个 part 内的数据是有序的 不同 part 之间的数据是无序的 数据合并是将多个 part 合并成一起的过程 part 的合并发生在一个分区内 数据的可见性 数据合并过程中，未被合并的数据对查询可见 数据合并完成后，新 part 可见，被合并的 part 被标记删除 数据查询 通过主键找到需要读的 mark 切分 marks，然后并发的调度 reader Reader 通过 mark block_offset 得到需要读的数据文件的偏移量 Reader 通过 mark granule_offset 得到解压之后数据的偏移量 构建列式 filter 做数据过滤 ClickHouse 应用场景 大宽表存储和查询 大宽表查询 可以建非常多的列 可以增加，删除，清空每一列的数据 查询的时候引擎可以快速选择需要的列 可以将列涉及到的过滤条件下推到存储层从而加速查询 动态表结构 map 中的每个 key 都是一列 map 中的每一列都可以单独的查询 使用方式同普通列，可以做任何计算 离线数据分析 数据导入 数据可以通过 spark 生成 clickhouse 格式的文件 导入到 hdfs 上由 hive2ch 导入工具完成数据导入 数据直接导入到各个物理节点 数据按列导入 保证查询可以及时访问已有数据 可以按需加载需要的列 实时数据分析 使用 memory table 减少 parts 数量 数据先缓存在内存中 到达一定阈值再写到磁盘 复杂类型查询 bitmap 索引 构建 查询 bitmap64 类型 lowcardinality 对于低基数列使用字典编码 减少数据存储和读写的 IO 使用 可以做运行时的压缩数据过滤 总结 ClickHouse 是标准的列存结构 存储设计是 LSM-Tree 架构 使用稀疏索引加速查询 每个列都有丰富的压缩算法和索引结构 基于列存设计的高效的数据处理逻辑","tags":["数据库","ClickHouse"],"categories":["字节青训营"]},{"title":"Redis——大厂程序员是怎么用的","path":"/posts/how-top-tech-programmers-use-redis/","content":"Redis 是什么 为什么需要 Redis 数据从单表，演进出了分库分表 Mysql 从单机演进出了集群 数据量增长 读写数据压力的不断增加 数据分冷热 热数据：经常被访问到的数据 将热数据存储到内存中 Redis 基本工作原理 数据从内存中读写 数据保存到硬盘上防止重启数据丢失 增量数据保存到 AOF 文件 全量数据 RDB 文件 单线程处理所有操作命令 Redis 应用案例 1、连续签到 掘金每日连续签到 用户每日有一次签到机会，如果断签，连续签到计数将归为 0 连续签到的定义：每天必须在 23:59:59 前签到 Key：cc_uid_1165894833417101 value：252 expireAt：后天的零点 String 数据结构 数据结构-sds 可以存储字符串、数字、二进制数据 通常和 expire 配合使用 场景：存储计数、Session 2、消息通知 用 list 作为消息队列 使用场景：消息通知 例如当文章更新时，将更新后的文章推送到 ES，用户就能搜索到最新的文章数据 List 数据结构 Quicklist Quicklist 由一个双向链表和 listpack 实现 Listpack 数据结构 3、计数 一个用户有多项计数需求，可通过 hash 结构存储 Hash 数据结构 dict rehash：rehash 操作是将 ht[O]中的数据全部迁移到 ht[1]中。数据量小的场景下直接将数据从 ht[O 拷贝到 ht[1]速度是较快的。数据量大的场景，例如存有上百万的 KV 时，迁移过程将会明显阻塞用户请求 渐进式 rehash：为避免出现这种情况，使用了 rehash 方案。基本原理就是，每次用户访问时都会迁移少量数据。将整个迁移过程，平摊到所有的访问用不请求过程中 排行榜 积分变化时，排名要实时变更 zset 数据结构 zskiplist 查找数字 7 的路径，head，3，3，7 结合 dict 时，可实现通过 key 操作跳表的功能 ZINCRBY myzset 2 “Alex” ZSCORE myzset “Alex” 5、限流 要求 1 秒内放行的请求为 N，超过 N 则禁止访问 Key：comment_freq_limit_1671356046 对这个 Key 调用 incr，超过限制 N 则禁止访问 1671356046 是当前时间戳 分布式锁 并发场景，要求一次只能有一个协程运行，执行完成后，其他等待中的协程才能执行 可以使用 redis 的 setnx 实现，利用了两个特性 Redis 是单线程执行命令 setnx 只有未设置过才能执行成功 Redis 使用注意事项大 Key、热 Key 大 Key 的定义 大 Key 的危害 读取成本高 容易导致慢查询（过期、删除） 主从复制异常，服务组塞无法正常响应请求 业务侧使用大 Key 请求 Redis 超时报错 消除大 Key 的方法 1、拆分 将大 Key 拆分为小 Key。例如一个 String 拆分成多个 String 2、压缩 将 valuel 压缩后写入 redis，读取时解压后再使用。压缩算法可以是 gzip、snappy、lz4 等。通常情况下，一个压缩算法压缩率高、则解压耗时就长。需要对实际数据进行测试后，选择一个合适的算法 如果存储的是 JSON 字符串，可以考虑使用 MessagePack 进行序列化 3、集合类结构 hash、list、set 拆分：可以用 hash 取余、位掩码的方式决定放在哪个 Key 中 区分冷热：如榜单列表场景使用 zset，只缓存前 10 页数据，后续数据走 db 热 Key 的定义 用户访问一个 Key 的 QPS 特别高，导致 Server 实例出现 CPU 负载突增或者不均的情况 热 key 没有明确的标准，QPS 超过 500 就有可能被识别为热 Key 解决热 Key 的方法 1、设置 Localcache 在访问 Redis 前，在业务服务侧设置 Localcache，降低访问 Redis 的 QPS。LocalCache 中缓存过期或未命中，则从 Redist 中将数据更新到 LocalCache。Java 的 Guava、Golang 的 Bigcache 就是这类 LocalCache 2、拆分 将 key : value 这一个热 Key 复制写入多份，例如 key1 : value,key2 : value，访问的时候访问多个 key，但 value 是同一个，以此将 qps 分散到不同实例上，降低负载。代价是，更新时需要更新多个 key，存在数据短暂不一致的风险 3、使用 Redis 代理的热 Key 承载能力 字节跳动的 Redis 访问代理就具备热 Key 承载能力。本质上是结合了“热 Key 发现”、“LocalCache”两个功能 慢查询场景 容易导致 redis 慢查询的操作 批量操作一次性传入过多的 key&#x2F;value，如 mset&#x2F;hmset&#x2F;sadd&#x2F;zadd 等 O(n)操作建议单批次不要超过 100，超过 100 之后性能下降明显 Zset 大部分命令都是 O(log(n))，当大小超过 5k 以上时，简单的 zadd&#x2F;zrem 也可能导致慢查询 操作的单个 vaue 过大，超过 10KB。也即，避免使用大 Key 对大 key 的 delete&#x2F;expire 操作也可能导致慢查询，Redis4.0 之前不支持异步删除 unlink，大 key 删除会阻塞 Redis 缓存穿透、缓存雪崩 缓存穿透：热点数据查询绕过缓存，直接查询数据库 缓存雪崩：大量缓存同时过期 缓存穿透的危害 查询一个一定不存在的数据 通常不会缓存不存在的数据，这类查询请求都会直接打到 db，如果有系统 bug 或人为攻击，那么容易导致 db 响应慢甚至宕机 缓存过期时 在高并发场景下，一个热 key 如果过期，会有大量请求同时击穿至 db，容易影响 db 性能和稳定 同一时间有大量 key 集中过期时，也会导致大量请求落到 db 上，导致查询变慢，甚至出现 db 无法响应新的查询 如何减少缓存穿透 缓存空值 如一个不存在的 userlD。这个 id 在缓存和数据库中都不存在。则可以缓存一个空值，下次再查缓存直接反空值 布隆过滤器 通过 bloom filter 算法来存储合法 Key，得益于该算法超高的压缩率，只需占用极小的空间就能存储大量 key 值 如何避免缓存雪崩 缓存空值 将缓存失效时间分散开，比如在原有的失效时间基础上增加一个随机值，例如不同 Key 过期时间可以设置为 10 分 1 秒过期，10 分 23 秒过期，10 分 8 秒过期。单位秒部分就是随机时间，这样过期时间就分散了 对于热点数据，过期时间尽量设置得长一些，冷门的数据可以相对设置过期时间短一些 使用缓存集群，避免单机宕机造成的缓存雪崩","tags":["数据库","Redis"],"categories":["字节青训营"]},{"title":"MySQL——深入理解RDBMS","path":"/posts/deep-understanding-of-rdbms/","content":"经典案例 从一场红包雨说起 RDBMS 事务 ACID 事务(Transaction)：是由一组 SQL 语句组成的一个程序执行单元（Unit），它需要满足 ACID 特性 ACID： 原子性(Atomicity)：事务是一个不可再分割的工作单元，事务中的操作要么都发生，要么都不发生 一致性(Consistency)：数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性 隔离性(Isolation)：多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果 持久性(Durability)：在事务完成以后，该事务所对数据库所做的更改便持久的保存在数据库之中，并不会被回滚 红包雨 与 ACID 红包雨 与 高并发 红包雨 与 高可靠 发展历史前 DBMS 时代 人工管理 在现代计算机发明出来以前，通过人工的方式进行数据记录和管理 文件系统 1950s，现代计算机的雏形基本出现。1956 年 IBM 发布了第一个磁盘驱动器–Model 305 RAMAC，从此数据存储进入硬盘时代。在这个阶段，数据管理直接通过文件系统来实现 DBMS 时代 1960s，传统的文件系统已经不能满足人们的需要，数据库管理系统（DBMS）应运而生 DBMS：按照某种数据模型来组织、存储和管理数据的仓库 所以通常按照数据模型的特点将传统数据库系统分成网状数据库、层次数据库和关系数据库三类 DBMS 数据模型 网状模型 网状数据库所基于的网状数据模型建立的数据之间的联系，能反映现实世界中信息的关联，是许多空间对象的自然表达形式 1964 年，世界上第一个数据库系统一集成数据存储（Integrated Data Storage，IDS）诞生于通用电气公司。1DS 是世界上第一个网状数据库，奠定了数据库发展的基础，在当时得到了广泛的应用。在 1970s 网状数据库系统十分流行，在数据库系统产品中占据主导地位 层次模型 1968 年，世界上第一个层次数据库一信息管理系统（Information Management System，IMS）诞生于于 IBM 公司，这也是世界上第一个大型商用的数据库系统。层次数据模型，即使用树形结构来描述实体及其之间关系的数据模型 关系模型 1970 年，IBM 的研究员 E.F.Codd 博士发表了一篇名为“A Relational Model of Data for large Shared Data Banks”的论文，提出了关系模型的概念，奠定了关系模型的理论基础。1979 年 Oracle 首次将关系型数据库商业化，后续 DB2，SAP Sysbase ASE，and Informix 等知名数据库产品也纷纷面世 优劣势 SQL 语言 1974 年 IBM 的 Ray Boycei 和 Don Chamberlin 将 Codd 关系数据库的 12 条准则的数学定义以简单的关键字语法表现出来，里程碑式地提出了 SQL(Structured Query Language)语言 语法风格接近自然语言 高度非过程化 面向集合的操作方式 语言简洁，易学易用 历史回顾 关键技术一条 SQL 的一生 SQL 引擎 Parser 解析器(Parser)一般分为词法分析(Lexical analysis)、语法分析(Syntax analysis))、语义分析(Semantic analyzer)等步骤 Optimizer 为什么需要一个优化器(Optimizer)？ 基于规则的优化(RBO Rule Base Optimizer) 条件化简 表连接优化 总是小表先进行连接 Scan 优化 唯一索引 普通索引 全表扫描 数据库索引：是数据库管理系统中辅助数据结构，以协助快速查询、更新数据库表中数据。目前数据库中最常用的索引是通过 B+树实现的 基于代价的优化(CBO Cost Base Optimizer) 一个查询有多种执行方案，CBO 会选择其中代价最低的方案去真正的执行 什么是代价？ Executor 火山模型 每个 Operator 调用 Next 操作，访问下层 Operator，获得下层 Operator 返回的一行数据，经过计算之后，将这行数据返回给上层 优点： 每个算子独立抽象实现，相互之间没有耦合，逻辑结构简单 缺点： 每计算一条数据有多次函数调用开销，导致 CPU 效率不高 向量化 每个 ○perator 每次操作计算的不再是一行数据，而是一批数据(Batch N 行数据)，计算完成后向上层算子返回一个 Batch 优点： 函数调用次数降低为 1&#x2F;N CPU cache 命中率更高 可以利用 CPU 提供的 SIMD(Single Instruction Multi Data)机制 编译执行 将所有的操作封装到一个函数里面，函数调用的代价也能大幅度降低 用户 SQL 干变万化怎么办？难道要穷举用户的所有 SQL,给每一个 SQL 都预先写好一个执行函数吗？ 存储引擎 InnoDB In-Memory： Buffer Pool Change Buffer Adaptive Hash Index Log Buffer On-Disk： System Tablespace(ibdata1) General Tablespaces(xxx.ibd) Undo Tablespaces(xxx.ibu) Temporary Tablespaces(xxx.ibt) Redo Log(ib_logfileN) Buffer Pool Page B+ Tree 页面内： 页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录。 从根到叶： 中间节点存储 点查： Select * from table wehre id &#x3D; 2000; 范围查询： Select * from table wehre id &gt; 2000; 事务引擎 Atomicity 与 Undo Log 如何将数据库回退到修改之前的状态？ Undo Log Undo Log 是逻辑日志，记录的是数据的增量变化。利用 Undo Log 可以进行事务回滚，从而保证事务的原子性。同时也实现了多版本并发控制(MVCC)，解决读写冲突和一致性读的问题 Isolation 与 锁 前情提要：羊老师从抖音抢了一个亿红包，又从头条抢了一个亿。抖音和头条都要往羊老师的账户转一个亿，如果两个操作同时进行，发生冲突怎么办？ Isolation 与 MVCC MVCC 的意义： 读写互补阻塞 降低死锁概率 实现一致性读 Undo Log 在 MVCC 的作用： 每个事务有一个单增的事务 ID 数据页的行记录中包含了 DB_ROW_ID，DB_TRX_ID，DB_ROLL_PTR DB_ROLL_PTR 将数据行的所有快照记录都通过链表的结构串联了起来 Durability 与 Redo Log 如何保证事务结束后，对数据的修改永久的保存？ 方案一：事务提交前页面写盘 问题：随机 IO、写放大 方案二：WAL(Write-ahead logging) redo log 是物理日志，记录的是页面的变化，它的作用是保证事务持久化。如果数据写入磁盘前发生故障，重启 MySQL 后会根据 redo log 重做 企业实践春节红包雨挑战 大流量-Sharding 问题背景 单节点写容易成为瓶颈 单机数据容量上限 解决方案 业务数据进行水平拆分 代理层进行分片路由 实施效果 数据库写入能力扩展 数据库容量线性扩展 流量突增 扩容 问题背景 活动流量上涨 集群性能不满足要求 解决方案 扩容 DB 物理节点数量 利用影子表进行压测 实施效果 数据库集群提供更高的吞吐 保证集群可以承担预期流量 代理连接池 问题背景 突增流量导致大量建联 大量建联导致负载变大，延时上升 解决方案 业务侧预热连接池 代理则预热连接池 代理侧则支持连接队列 实施效果 避免 DB 被突增流量打死 避免代理和 DB 被大量建联打死 稳定性&amp;可靠性 3AZ 高可用 HA 管理 问题背景 db 所在机器异常宕机 db 节点异常宕机 解决方案 ha 服务监管、切换宕机节点 代理支持配置热加载 代理自动屏蔽宕机读节点 实施效果 读节点宕机秒级恢复 写节点宕机 30s 内恢复服务","tags":["数据库","MySQL"],"categories":["字节青训营"]},{"title":"带你认识存储的本质——状态","path":"/posts/the-essence-of-storage/","content":"经典案例 数据的产生 数据的流动 数据的持久化 潜在的问题 数据库怎么保证数据不丢 数据库怎么处理多人同时修改的问题 为什么用数据库，除了数据库还能存到别的存储系统吗 数据库只能处理结构化数据吗 有哪些操作数据库的方式，要用什么编程语言 存储 &amp; 数据库简介存储系统 系统概览 什么是存储系统？ 一个提供了读写、控制类的接口，能够安全有效的把数据持久化的软件，就可以称为存储系统 系统特点 作为后端软件的底座，性能敏感 存储系统软件架构，容易受硬件影响 存储系统代码，既“简单”又“复杂” 存储器层级结构 数据怎么从应用到存储介质 [缓存] 很重要，贯穿整个存储体系 [拷贝] 很昂贵，应该尽量减少 硬件设备五花八门，需要有抽象统一的接入层 RAID 技术 单机存储系统怎么做到高性能&#x2F;高性价比&#x2F;高可靠性？ R(edundant) A(rray) of I(nexpensive) D(isks) RAID 出现的背景： 单块大容量磁盘的价格&gt;多块小容量磁盘 单块磁盘的写入性能&lt;多块磁盘的并发写入性能 单块磁盘的容错能力有限，不够安全 RAID 0 多块磁盘简单组合 数据条带化存储，提高磁盘宽带 没有额外的容错设计 RAID 1 一块磁盘对应一块额外镜像盘 真实空间利用率仅 50% 容错能力强 RAID 0+1 结合了 RAID 0 和 RAID 1 真实空间利用率仅 50% 容错能力强，写入宽带好 数据库 数据库和存储系统不一样 关系型数据库 非关系型数据库 概览 关系（Relation）是什么？ Edgar.F.Codd 于 1970 年提出 [关系模型] 关系 &#x3D; 集合 &#x3D; 任意元素组成的若干有序偶对反映了事物间的联系 关系代数 &#x3D; 对关系作运算的抽象查询语言 交、并、笛卡尔积…… SQL &#x3D; 一种 DSL &#x3D; 方便人类阅读的关系代数表达形式 关系型数据库特点 关系型数据库是存储系统，但是在存储之外，又发展出其他能力 结构化数据友好 支持事务（ACID） 支持复杂查询语言 非关系型数据库特点 非关系型数据体也是存储系统，但是一般不要求严格的结构化 半结构化数据友好 可能支持事务（ACID） 可能支持复杂查询语言 数据库 vs 经典存储 结构化数据管理 事务能力 凸显出数据库支持[事务]的优越性 事务具有： A(tomicity).事务内的操作要么全做，要么不做 C(onsistency).事务执行前后，数据状态是一致的 I(solation).可以隔离多个并发事务，避免影响 D(urability).事务一旦提交成功，数据保证持久性 复杂查询能力 写入数据之后，想做很复杂的查询怎么办？ Example：请查询出名字以 xiao 开头，且密码提示问题小于 10 个字的人，并按性别分组统计人数 数据库使用方式 Everything is D(omain) S(pecific) L(anguage) &#x3D;&#x3D;&gt; maybe SQL 以 SQl 为例，要操作数据时，支持以下操作： Insert Update Select Delete Where 子句 GroupBy OrderBy 要对数据库定义做修改时，支持以下操作： Create User Create database Create table Alter table …… 主流产品剖析单机存储 概览 单机存储 &#x3D; 单个计算机节点上的存储软件系统，一般不涉及网络交互 本地文件系统 key-value 存储 本地文件系统 Linux 经典哲学：一切皆文件 文件系统的管理单元：文件 文件系统接口：文件系统繁多，如 Ext2&#x2F;3&#x2F;4，sysfs，rootfs 等，但都遵循 VFS 的统一抽象接口 Linux 文件系统的两大数据结构：Index Node &amp; Directory Entry Index Node 记录文件元数据，如 id、大小、权限、磁盘位置等 inode 是一个文件的唯一标识，会被存储到磁盘上 inode 的总数在格式化文件系统时就固定了 Directory Entry 记录文件名、inode 指针，层级关系（parent）等 dentry 是内存结构，与 inode 的关系 N:1（hardlink 的实现） key-value 存储 世间一切皆key-value 常见使用方式：put(k,v)&amp;get(k) 常见数据结构：LSM-Tree，某种程度上牺牲读性能，追求写入性能 拳头产品：RocksDB 分布式存储 概览 分布式存储 &#x3D; 在单机存储基础上实现了分布式协议，涉及大量网络交互 分布式文件系统 分布式对象存储 HDFS HDFS：堪称大数据时代的基石 时代背景：专用的高级硬件很贵，同时数据存量很大，要求超高吞吐 HDFS 核心特点： 支持海量数据存储 高容错性 弱 POSIX 语义 使用普通 x86 服务器，性价比高 Ceph Ceph：开源分布式存储系统里的 [万金油] Ceph 的核心特点： 一套系统支持对象接口、块接口、文件接口，但是一切皆对象 数据写入采用主备复制模型 数据分布模型采用 CRUSH 算法 单机数据库 概览 单机数据库 &#x3D; 单个计算机节点上的数据库系统 事务在单机内执行，也可能通过网络交互实现分布式事务 关系型数据库 非关系型数据库 关系型数据库 商业产品 Oracle 称王，开源产品MySQL &amp; PostgreSQL称霸 关系型数据库的通用组件： Query Engine——负责解析 query，生成查询计划 Txn Manager——负责事务并发管理 Lock Manager——负责锁相关的策略 Storage Engine——负责组织内存&#x2F;磁盘数据结构 Replication——负责主备同步 关键内存数据结构：B-Tree、B+-Tree、LRU List 等 关键磁盘数据结构：WriteAheadLog（RedoLog）、Page 非关系型数据库 MongoDB、Redis、Elasticsearch三足鼎立 关系型数据库一般直接使用 SQL 交互，而非关系型数据库交互方式各不相同 非关系型数据库的数据结构千奇百怪，没有关系约束后，schema 相对灵活 不管是否关系型数据库，大家都在尝试支持SQL（子集）和“事务” Elasticsearch 使用案例 分布式数据库 从单机到分布式数据库 单机数据库遇到了哪些问题 &amp; 挑战，需要我们引入分布式架构来解决？ 容量 弹性 性价比 解决容量问题 解决弹性问题 解决性价比问题 More to Do 单写 vs 多写 从磁盘弹性到内存弹性 分布式事务优化 新技术演进 概览 SPDK AI &amp; Storage AI 领域相关技术，如 Machine Learning 在很多领域：如推荐、风控、视觉领域证明了有效性 高性能硬件 总结","tags":["数据库","存储"],"categories":["字节青训营"]},{"title":"RPC原理与实现","path":"/posts/rpc-principle-and-implementation/","content":"基本概念本地函数调用 将 a 和 b 的值压栈 通过函数指针找到 calculate 函数，进入函数取出栈中的值 2 和 3，将其赋予 x 和 y 计算 x * y，并将结果存在 z 将 z 的值压栈，然后从 calculate 返回 从栈中取出 z 返回值，并赋值给 result 远程函数调用（RPC-Remote Procedure Calls） RPC 需要解决的问题 函数映射 数据转换成字节流 网络传输 RPC 概念模型 1984 年 Neison 发表了论文《Implementing Remote Procedure Calls》，其中提出了 RPC 的过程由 5 个模型组成：User、User-Stub、RPC-Runtime、Server-Stub、Server 一次 RPC 的完整过程 IDL（Interface description language）文件 IDL 通过一种中立的方式来描述接口，使得在不同平台上运行的对象和用不同语言编写的程序可以相互通信 生成代码 通过编译器工具把 IDL 文件转换成语言对应的静态库 编解码 从内存中表示到字节序列的转换称为编码，反之为解码，也常叫做序列化和反序列化 通信协议 规范了数据在网络中的传输内容和格式，除必须的请求&#x2F;响应数据外，通常还会包含额外的元数据 网络传输 通常基于成熟的网络库走 TCP&#x2F;UDP 传输 RPC 的好处 单一职责，有利于分工协作和运维开发 可扩展性强，资源使用率更优 故障隔离，服务的整体可靠性更高 RPC 带来的问题 服务宕机，对方应该如何处理？ 在调用过程中发生网络异常如何保证消息的可达性？ 请求量暴增导致服务无法及时处理，有哪些应对措施？ 分层设计以 Apache Thrift 为例 编解码层 生成代码 数据格式 语言特定的格式 许多编程语言都内建了将内存对象编码为字节序列的支持，例如 Java 有 Java.io.Serializable 文本格式 JSON、XML、CSV 等文本格式，具有人类可读性 二进制编码 具备跨语言和高性能等优点，常见有 Thrift 的 BinaryProtocol，Protobuf 等 二进制编码 TLV 编码 Tag：标签，可以理解为类型 Lenght：长度 Value：值，Value 也可以是个 TLV 结构 选型 兼容性 支持自动增加新的字段，而不影响老的服务，这将提高系统的灵活性 通用性 支持跨平台、跨语言 性能 从空间和时间两个维度来考虑，也就是编码后数据大小和编码耗费时长 协议层 概念 特殊结束符：一个特殊字符作为每个协议单元结束的标识 变长协议：以定长加不定长的部分组成，其中定长的部分需要描述不定长的内容长度 协议构造 LENGTH：数据包大小，不包含自身 HEADER MAGIC：标识版本信息，协议解析时候快速校验 SEQUENCE NUMBER：表示数据包的 seqID，可用于多路复用，单连接内递增 HEADER SIZE：头部长度，从第 14 个字节开始计算一直到 PAYLOAD 前 PROTOCAL ID：编解码方式，有 Binary 和 Compact 两种 TRANSFORM ID：压缩方式，如 zlib 和 snappy INFO ID：传递一些定制的 meta 信息 PAYLOAD：消息体 协议解析 网络通信层 Sockets API 网络库 提供易用 API 封装底层 Socket API 连接管理和事件分发 功能 协议支持：tcp、udp 和 uds 等 优雅退出、异常处理等 性能 应用层 buffer 减少 copy 高性能定时器、对象池等 关键指标稳定性 保障策略 熔断：保护调用方，防止被调用的服务出现问题而影响到整个链路 限流：保护被调用方，防止大流量把服务压垮 超时控制：避免浪费资源在不可用节点上 请求成功率 负载均衡 重试 长尾请求 Backup Request 注册中间件 易用性 开箱即用 合理的默认参数选项，丰富的文档 周边工具 生成代码工具，脚手架工具 扩展性 Middleware Option 编解码层 协议层 网络传输层 代码生成工具插件扩展 观测性 Log、Metric、Tracing 内置观测性服务 高性能 场景 单机多机 单连接多连接 单&#x2F;多 client 单&#x2F;多 server 不同大小的请求包 不同请求类型：例如 pingpong、streaming 等 目标 高吞吐 低延迟 手段 连接池 多路复用 高性能编解码协议 高性能网络库 企业实践整体架构-Kitex Kitex Core 核心组件 Kitex Byted 与公司内部基础设施集成 Kitex Tool 代码生成工具 自研网络库 背景 原生库无法感知连接状态问题 在使用连接池时，池中存在失效链接，影响连接池的复用 原生库存在 goroutine 暴涨的风险 一个连接一个 goroutine 的模式，由于连接利用率低下，存在大量 goroutine 占用调度开销，影响性能 Netpoll 解决无法感知连接状态问题 引入 epoll 主动监听机制，感知连接状态 解决 goroutine 暴涨的风险 建议 goroutine 池，复用 goroutine 提升性能 引入 Nocopy Buffer，向上层提供 NoCopy 的调用接口，编解码层面零拷贝 扩展性设计 支持多协议，也支持灵活的自定义协议扩展 性能优化 网络库优化 调度优化 epoll_wait 在调度上的控制 gopool 重用 goroutine 降低同时运行协程数 LinkBuffer 读写并行无锁，支持 nocopy 地流式读写 高效扩缩容 Nocopy Buffer 池化，减少 GC Pool 引入内存池和对象池，减少 GC 开销 编解码优化 Codegen 预计算并预分配内存，减少内存操作次数，包括次数分配和拷贝 Inline 减少函数调用次数和减少不必要的反射操作等 自研了 Go 语言实现的 Thrift IDL 解析和代码生成器，支持完善的 Thrift IDL 语法和语义检查，并支持了插件机制 - Thriftgo JIT 使用 JIT 编译技术改善用户体验的同时带来更强的编解码性能，减轻用户维护生成代码的负担 基于 JIT 编译技术的高性能动态 Thrift 编解码器 - Frugal 合并部署 微服务过微，传输和序列化开销越来越大 将亲和性强的服务实例尽可能调度到同一个物理机，远程 RPC 调用优化为本地 IPC 调用 中心化的部署调度和流量控制 基于共享内存的通信协议 定制化的服务发现和连接池实现 定制化的服务启动和监听逻辑","tags":["RPC"],"categories":["字节青训营"]},{"title":"消息队列原理与实战","path":"/posts/message-queue-principle-and-practice/","content":"引入 案例一：系统崩溃 解决方案：解耦 案例二：服务能力有限 解决方案：削峰 案例三：链路耗时长尾 解决方案：异步 案例四：日志存储 服务器故障日志丢失 解决方案： 什么是消息队列？ 消息队列（MQ），指保存消息的一个容器，本质是个队列，但这个队列需要支持高吞吐、高并发、并且高可用 前世今生消息队列发展历程 业内消息队列对比 消息队列-Kafka使用场景 如何使用 Kafka 基本概念 Topic：逻辑队列，不同 Topic 可以建立不同的 Topic Cluster：物理集群，每个集群中可以建立多个不同的 Topic Producer：生产者，负责将业务消息发送到 Topic 中 Consumer：消费者，负责消费 Topic 中的消息 ConsumerGroup：消费者组，不同组 Consumer 消费进度互不干涉 Offset：消息在 partition 内的相对位置信息，可以理解为唯一 ID，在 partition 内部严格递增 Replica：每个分片有多个 Replica，Leader Replica 将会从 ISR 中选出 数据复制 Kafka 架构 一条消息的自述 从一条消息的视角，看看为什么 Kafka 能支撑这么高的吞吐？ 如果发送一条消息，等到其成功后再发一条会有什么问题？ Producer 批量发送 如果消息量很大，网络宽带不够用，如何解决？ 数据压缩 Broker 数据的存储 如何存储到磁盘？ 消息文件结构 数据路径：&#x2F;Topic&#x2F;Partition&#x2F;Segment&#x2F;(log | index |timeindex | …) 磁盘结构 移动磁头找到对应磁道，磁盘转动。找到对应扇区，最后写入，寻道成本比较高，因此顺序可以减少寻道所带来的时间成本 顺序写 采用顺序写的方式进行写入，以提高写入效率 如何找到消息 Consumer 通过发送 FetchRequest 请求消息数据，Broker 会将指定 Offset 处的消息，按照时间窗口和消息大小窗口发送给 Consumer，寻找数据这个细节是如何做到的呢？ 偏移量索引数据 目标：寻找 offset &#x3D; 28 二分找到小于目标 offset 的最大文件 时间戳索引文件 二分找到小于目标时间戳最大的索引位置，在通过寻找 offset 的方式找到最终数据 传统数据拷贝 零拷贝 Consumer 消息的接收端 如何解决 Partition 在 Consumer Group 中的分配问题？ Low Level 通过手动进行分配，哪一个 Consumer 消费哪一个 Partition 完全由业务来决定 这种方式的缺点是什么？ 如果 Consumer3 挂掉了，7，8 分片就停止消费了 如果新增了一台 Consumer4 ，需要重新停掉整个集群，重新修改配置再上线，保证 Consumer4 也可以消费数据 High Level Rebalance 一些可以帮 Kafka 提高吞吐或者稳定性的功能 Producer：批量发送、数据压缩 Broker：顺序写，消息索引，零拷贝 Consumer：Reblance 问题 数据复制问题 重启操作 替换、扩容、缩容 负载不均衡 问题总结 运维成本高 对于负载不均衡的场景，解决方案复杂 没有自己的缓存，完全依赖 Page cache Controller 和 Coordinator 和 Broker 在同一进程中，大量 IO 会造成其性能下降 消息队列-BMQBMQ 简介兼容 Kafka 协议，存算分离，云原生消息队列 BMQ 介绍 运维操作对比 HDFS 写文件流程 BMQ 文件结构 Broker Partition 状态机 保证对于任意分片在同一时刻只能在一个 Broker 上存活 写文件流程 写文件 Failover 如果 DataNode 节点挂了或者是其他原因导致我们写文件失败，应该如何处理？ Proxy 多机房部署 高级特性 泳道消息 BOE：Bytedance Offline Environment，是一套完全独立的线下机房环境 PPE：Product Preview Environment，即产品预览环境 多个人同时测试，需要等待上一个人测试完成 每多一个测试人员，都需要重新搭建一个相同配置的 Topic，造成人力和资源的浪费 对于 PPE 的消费者来说，资源没有生产环境多，所以无法承受生产环境的流量 解决主干泳道流量隔间问题以及泳道资源重复创建问题 Databus 直接使用原生 SDK 会有什么问题？ 客户端配置较为复杂 不支持动态配置 对于 latency 不是很敏感的业务，batch 效率不佳 简化消息队列客户端复杂配置 解耦业务与 Topic 缓解集群压力，提高吞吐 Mirror 是否可以通过多机房部署的方式，解决跨 Region 读写的问题？ 使用 Mirror 通过最终一致的方式，解决跨 Region 读写问题 Index 如果希望通过写入的 LogId、UserId 或者其他的业务字段进行消费的查询，应该怎么做？ 直接在 BMQ 中将数据结构化，配置索引 DDL，异步构建索引后，通过 Index Query 服务读出数据 ParquetApache Parquet 是 Hadoop 生态圈中一钟新型列式存储格式，它可以兼容 Hadoop 生态圈中大多数计算框架（Hadoop、Spark 等），被多种查询引擎支持（Hive、Impala、Drill 等） 直接在 BMQ 中将数据结构化，通过 Parquet Engine，可以使用不同的方式构建 Parquet 格式文件 小结 BMQ 的架构模型（解决 Kafka 存在的问题） BMQ 读写流程（Failover 机制，写入状态机） BMQ 高级特性（泳道、Databus、Mirror、Index、Parquet） 消息队列-RocketMQ使用场景例如，针对电商业务线，其业务涉及广泛，如注册、订单、库存、物流等；同时，也会涉及许多业务峰值时刻，如秒杀活动、周年庆、定期特惠等 基本概念 架构 存储模型 高级特性事务场景 事务消息 延迟发送 延时消息 处理失败 该如何处理失败的消息呢？ 消费重试和死信队列 小结 RocketMQ 的基本概念（Queue、Tag） RocketMQ 的底层原理（架构模型、存储模型） RocketMQ 的高级特性（事务消息、重试和死信队列、延迟队列）","tags":["消息队列"],"categories":["字节青训营"]},{"title":"分布式定时任务","path":"/posts/distributed-scheduled-tasks/","content":"前言春节集卡瓜分 20 亿作为后端开发同学，怎样设计最终开奖环节技术方案？ 业务流程 定时扫描抖音用户集卡状态 汇总计算用户的瓜分金额 定时开奖 技术体量 亿级用户规模 十亿级资金规模 百万级读写 QPS 方案引出 自动化 + 定时执行 + 海量数据 + 高效稳定 &#x3D; 分布式定时任务 发展历程发展历史Windows 批处理 Case 1：10 分钟后 Windows 电脑自动关机 Step1：桌面空白处右键单机-新建-文本文档 Step2：更改文件名和后缀为”自动关机.bat“ Step3：修改文件内容为”Shutdown -s -t 600“，代表 10 分钟后关机 Step4：双击运行该批处理文件，电脑将会在 10 分钟之后自动关机 Windows 任务计划程序 Case 2：每天 12:00 自动疫情打卡 Linux 命令-CronJob Case 3：每天 02:30 定时清理机器日志 Linux 系统命令，使用简单，稳定可靠 只能控制单台机器，且无法适用于其他操作系统 单机定时任务-Timer、Ticker Case 4：每隔 5 分钟定时刷新本地缓存数据 跨平台 仅单机可用 单机定时任务-ScheduledExecutorService case 5：每隔 5 分钟定时执行多个任务 拥有线程池功能 仅单机可用 任务调度-Quartz 单任务极致控制 没有负载均衡机制 分布式定时任务 平台化管理 分布式部署 支持海量数据 分布式定时任务 定义 定时任务是指系统为了自动完成特定任务，实时、延时、周期性完成任务调度的过程 分布式定时任务是把分散的、可靠性差的定时任务纳入统一的平台，并实现集群管理调度和分布式部署的一种定时任务的管理方式 按触发时机分类 定时任务：特定时间触发，比如今天 15:06 执行 延时任务：延时触发，比如 10s 后执行 周期任务：固定周期时间，或固定频率周期调度触发，比如每天 12 点或者每隔 5 秒执行 特点 自动化：全自动完成定时任务的调度和执行 平台化：基于平台化的思维管控一系列的分布式定时任务 分布式：在分布式系统环境下运行任务调度，突破单机定时任务的性能瓶颈 伸缩性：采用集群方式部署，可以随时按需扩容 高可用：单点故障不影响最终任务结果，可以做到故障转移 执行方式 单机任务：随机触发一台机器执行任务，适用于计算量小，并发度低的任务 广播任务：广播到所有机器上执行同一个任务，比如所有机器一起清理日志 Map 任务：一个任务可以分出多个子任务，每个子任务负责一部分的计算，适用于计算量大，单机无法满足要求的任务 MapReduce 任务：在 Map 任务的基础上，还可以对所有子任务的结果做汇总计算，适用于计算量大，并且需要对子任务结果做汇总的任务 执行方式 vs 春节集卡 发奖金额计算：MapReduce 任务 定时开奖：Map 任务 业内定时任务框架 知识面扩充 分布式定时任务 VS 单机定时任务 关系： 都可以实现自动化的定时、延时、周期任务调度 差异： 分布式定时任务可支撑更大的业务体量 分布式定时任务的性能、伸缩性、稳定性更高 分布式定时任务 VS 大数据处理引擎 关系： 都可以对海量数据做处理 性能、伸缩性、稳定性都很高 差异： 定时并不是大数据处理引擎要解决的核心问题 大数据引擎往往致力于将源数据处理成结果数据，分布式定时任务除了能做这个之外，还可以调用 HTTP 和 RPC 服务 实现原理核心架构 分布式定时任务核心要解决触发、调度、执行三个关键问题 触发器：Trigger，解析任务，生成触发事件 调度器：Scheduler，分配任务，管理任务生命周期 执行器：Executor，获取执行任务单元，执行任务逻辑 除此之外，还需要提供一个控制台（Admin），提供任务管理和干预的功能 数据流 功能架构 控制台基本概念 任务：Job，任务元数据 任务实例：JobInstance，任务运行的实例 任务结果：JobResult，任务实例运行的结果 任务历史：JobHistory，用户可以修改任务信息，任务实例对应的任务元数据可以不同，因而使用任务历史存储 任务元数据任务元数据（Job）是用户对任务属性定义，包括任务类型调度时机、执行行为等 任务实例任务实例（JobInstance）是一个确定的 Job 的一次运行实例 触发器核心职责 核心职责 给定一系列任务，解析他们的触发规则，在规定的时间点触发任务的调度 设计约束 需支持大量任务 需支持秒级的调度 周期任务需要多次执行 需保证秒级扫描的高性能，并避免资源浪费 方案 1定期扫描+延时消息（腾讯、字节方案） 方案 2 时间轮（Quartz 所用方案） 时间轮是一种高效利用线程资源进行批量化调度的一种调度模型，时间轮是一个存储环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表 目标：遍历任务列表，从中找出当前时间点需触发的任务列表 高可用 核心问题 不同业务之间，任务的调度相互影响怎么办 负责扫描和触发的机器挂了怎么办 解法思路 存储上，不同国别、业务做资源隔离 运行时，不同国别、业务分开执行 部署时，采用多机房集群化部署，避免单点故障，通过数据库锁或分布式锁保证任务只被触发一次 问题引出 单 Trigger 模式： 会有单点故障 机器故障时平台崩溃 Trigger 集群模式 可避免单点故障 需要避免同一任务被多次触发，导致业务紊乱 数据库行锁模式在触发调度之前，更新数据库中 JobInstance 的状态，成功枪锁才会触发调度 分布式锁模式在触发调度之前，尝试抢占分布式锁，可使用 Redis 锁或 Zookeeper 锁 调度器资源来源 业务系统提供机器资源 使用该方案的公司： 阿里、美团、字节等 优点： 任务执行逻辑与业务系统共用同一份资源，利用率更高 缺点： 更容易发生定时任务脚本影响在线服务的事故 不能由定时任务平台控制扩缩容 定时任务平台提供机器资源 使用该方案的公司： 字节等 优点： 任务执行逻辑与业务系统提供的在线服务隔离，避免相互影响 可以支持优雅的扩缩容 缺点： 消耗更多机器资源 需要额外为定时任务平台申请接口调用权限，而不能直接继承业务系统的权限 资源调度节点选择 随机节点执行：选择集群中一个可用的执行节点执行调度任务，使用场景：定时对账 广播执行：在集群中所有的执行节点发布调度任务并执行，使用场景：批量运维 分片执行：按照用户自定义分片逻辑进行拆分，分发到集群中不同节点并行执行，提升资源利用效率，使用场景：海量日志统计 任务分片通过任务分片来提高任务执行的效率和资源的利用率 高级特性任务编排使用有向无环图 DAG（Directed Acyclic Graph）进行可视化任务编排 故障转移确保部分执行单元任务失败时，任务最终成功 高可用调度器可以集群部署，做到完全的无状态，靠消息队列的重试机制保障任务一定会被调度 执行器 业务应用所有需要定时、延时、周期性执行任务的业务场景，都可以考虑使用分布式定时任务 其他解决方案 发货后超过 10 天未收货时系统自动确认收货 使用分布式定时任务的延时任务 使用消息队列的延时消息或者定时消息 春节集卡活动统计完成集卡的用户个数和总翻倍数 使用分布式定时任务的 MapReduce 任务 使用大数据离线处理引擎 Hive 离线做统计 使用大数据实时处理引擎 Fink 实时做累计 其他解决方案对比 课后作业","tags":["分布式"],"categories":["字节青训营"]},{"title":"黑灰产监控与防御","path":"/posts/black-and-gray-production-monitoring-and-defense/","content":"了解一些国内黑灰产的调研报告，推荐Freebuf 黑镜调查系列 国内黑产介绍 一些常见的黑产 黑色产业链规模 黑色产业链结构（部分） 黑产团伙的发展趋势 规模化 借助脚本、软件来实现攻击的批量化 上游各类资源丰富，大大降低攻击成本，同时攻击成功率也比较高 组织化 多数以工作室的形式运作 团伙内多人分工明确，合作紧密 某些黑产甚至成立了公司 平台化 今年来出现了很多平台级的爬虫、群控、钓鱼、木马、网络攻击、DDOS 攻击工具，攻击成本大大降低，且难以追查 各类平台将黑产手中零散的资源进行整合 常见的黑产技术分析 2018 年某银行业务逻辑漏洞（已修复） 人脸识别对抗 从照片到 3D 人脸模型 地理位置对抗 定位打卡 摇一摇附近的人 出租车抢单 某些线下使用的优惠 …… 安全防护体系的建设 事前 情报监控 暗网 贴吧 TG 破解论坛 SDLC 漏洞扫描 事中 渗透测试 威胁感知 用户行为异常 接口数据异常 恶意流量检测 风控&#x2F;安全策略 事后 威胁建模 攻击溯源","tags":["黑灰产"],"categories":["字节青训营"]},{"title":"手把手教你做系统设计","path":"/posts/system-design/","content":"系统设计方法论 为什么要做系统设计 个人 For 面试 个人能力提升 拓展技术视野 工作 业务驱动 系统重构 突破和创新 如何评估一个系统 可用性 安全性 扩展性 易用性 性能 耦合性 可维护性 伸缩性 系统设计的定义：为了达成某种目的，通过个体组成整体的过程 系统 关联的个体 规则运作 组成工作的整体 设计 设想和计划 目的 过程安排 如何做系统设计：4S 分析法 场景分析（Scenario） 什么系统，需要哪些功能，多大的并发量 存储设计（Storage） 数据如何组织，Sql 存储，NoSql 存储 服务设计（Service） 业务功能实现和逻辑整合 可扩展性（Scale） 解决设计缺陷，提高鲁棒性、扩展性 如何发现系统的瓶颈 火焰图分析 链路分析 性能测试 如何保证可用性和稳定性 链路梳理 核心链路 流量漏斗 强弱依赖 可观测性 链路追踪 核心监控 业务报警 全链路测试 压力测试 负载测试 容量测试 稳定性控制 系统限流 业务兜底 熔断降级 容灾演练 混沌工程 应急手册 容灾预案 电商秒杀业务介绍基本概念电商介绍 商品：具有交易价值和属性的信息载体 SPU：Standard Product Unit SKU：Stock Keeping Unit 秒杀业务的特点 瞬时流量高 读多写少 实时性要求高 秒杀的挑战 资源成本 反欺诈 高性能 防止超卖 流量管控 扩展性 鲁棒性 设计秒杀系统场景（Scenario） 功能： 秒杀活动发布 秒杀商品详情 秒杀下单 并发： 万人参与秒杀 QPS 1w+ TPS 1k+ 存储（Storage） 服务（Service） 子服务： 用户服务 风控服务 活动服务 订单服务 基础组件： ID 生成器 缓存组件 MQ 组件 限流组件 扩展（Scale） 流量隔离 CDN 缓存优化 流量管控 数据库扩展 MQ 扩展 Redis 扩展 服务水平扩展 服务垂直扩展 系统架构图 课程实践秒杀流程图 代码链接课程总结","tags":["系统设计"],"categories":["字节青训营"]},{"title":"微服务框架——不变的基建","path":"/posts/microservice-framework/","content":"微服务架构介绍系统架构演变历史 为什么系统架构需要演进？ 互联网的爆炸性发展 硬件设施的快速发展 需求复杂性的多样化 开发人员的急剧增加 计算机理论及技术的发展 单体架构——all in one process 优势： 性能最高 冗余小 劣势： debug 困难 模块相互影响 模块分工、开发流程 垂直应用架构——按照业务线垂直划分 优势： 业务独立开发维护 劣势： 不同业务存在冗余 每个业务还是单体 分布式架构——抽出与业务无关的公共模块 优势： 业务无关的独立服务 劣势： 服务模块 bug 可导致全站瘫痪 调用关系复杂 不同服务冗余 SOA 架构——面向服务 优势： 服务注册 劣势： 整个系统设计是中心化的 需要从上至下设计 重构困难 微服务架构——彻底的服务化 优势： 开发效率 业务独立设计 自上而下 故障隔离 劣势： 治理、运维难度 观测挑战 安全性 分布式系统 微服务架构概览 微服务架构核心要素 服务治理 服务注册 服务发现 负载均衡 扩缩容 流量治理 稳定性治理 可观测性 日志采集 日志分析 监控打点 监控大盘 异常报警 链路追踪 安全 身份验证 认证授权 访问令牌 审计 传输加密 黑产攻击 微服务架构原理及特征基本概念 服务（service） 一组具有相同逻辑的运行实体 实例（instance） 一个服务中，每个运行实体即为一个实例 实例与进程的关系 实例与进程之间没有必然对应关系，一个实例可以对应一个或多个进程（反之不常见） 集群（cluster） 通常指服务内部的逻辑划分，包含多个实例 常见的实例承载形式 进程、VM、k8s pod…… 有状态&#x2F;无状态服务 服务的实例是否存储了可持久化的数据（例如磁盘文件） 服务间通信 对于单体服务，不同模块通信只是简单的函数调用 对于微服务，服务间通信意味着网络传输 服务注册与发现 问题：在代码层面，如何指定调用一个目标服务的地址（ip:port）？ 直接指定 ip:port？ 没有任何动态能力 有多个实例下游实例怎么办？ 使用 DNS？ 本地 DNS 存在缓存，导致延迟 负载均衡问题 不支持服务探活检查 域名无法配置端口 解决思路：新增一个统一的服务注册中心，用于存储服务名到服务实例之间的映射关系 服务实例上线及下线过程 旧服务实例下线前，从服务注册中心删除该实例，下线流量 新服务实例上线后，在服务注册中心注册该实例，上线流量 流量特征 统一网关入口 内网通信多数采用 RPC（Thrift, gRPC） 网状调用链路 核心服务治理功能服务发布 服务发布（deployment） 让一个服务升级运行新的代码的过程 服务发布的难点 服务不可用 服务抖动 服务回滚 蓝绿部署 将服务分成两个部分，分别先后发布 简单、稳定 但需要两倍资源 灰度发布（金丝雀发布） 先发布少部分实例，接着逐步增加发布比例 不需要增加资源 回滚难度大，基础设施要求高 流量治理在微服务架构中，可以基于地区、集群、实例、请求等维度，对端到端流量的路由路径进行精确控制 负载均衡 负载均衡（Load Balance）负责分配请求在每个下游实例上的分布 常见的 LB 策略 Round Robin Random Ring Hash Least Request 稳定性治理 线上服务总是会出问题的，这与程序的正确性无关 网络攻击 流量突增 机房断电 光纤被挖 机器故障 网络故障 …… 微服务架构中典型的稳定性治理功能 限流 限制服务处理的最大 QPS，拒绝过多请求 熔断 中断请求路径，增加冷却时间从而让故障实例尝试恢复 过载保护 在负载高的实例中，主动拒绝一部分请求，防止实例被打挂 降级 服务处理能力不足时，拒绝低级别的请求，只响应线上高优请求 字节跳动服务治理实践重试的意义 本地函数调用——通常没有重试意义 可能有哪些异常？ 参数非法 OOM（Out Of Memory） NPE（Null Pointer Expection） 边界 case 系统崩溃 死循环 程序异常退出 远程函数调用 可能有哪些异常？ 网络抖动 下游负载高导致超时 下游机器宕机 本地机器负载高，调度超时 下游熔断、限流 …… 重试的意义 重试可以避免掉偶发的错误，提高 SLA（Service-Level Agreement） 降低错误率 假设单次请求的错误概率为 0.01，那么连续两次错误概率则为 0.0001 降低长尾延时 对于偶尔耗时较长的请求，重试请求有机会提前返回 容忍暂时性错误 某些时候系统会有暂时性异常（例如网络抖动），重试可以尽量规避 避开下游故障实例 一个服务中可能会有少量实例故障（例如机器故障），重试其他实例可以成功 重试的难点 幂等性 多次请求可能会造成数据不一致 重试风暴 随着调用链路的增加，重试次数呈指数级上升 超时设置 假设调用时间一共 1s，经过多少时间开始重试？ 重试策略 限制重试比例 设定一个重试比例阈值（例如 1%），重试次数占所有请求比例不超过该阈值 重试只有在大部分请求都成功，只有少量请求失败时才有必要 如果大部分请求都失败，重试只会加剧问题严重性 防止链路重试 链路层面的防重试风暴的核心是限制每层都发生重试，理想情况下只有最下一层发生重试 可以返回特殊的 status code，表示“请求失败，但别重试” Hedged Requests 对于可能超时（或延时高）的请求，重新向另一个下游实例发送一个相同的请求，并等待先到达的响应 重试效果验证实际验证经过上述重试策略后，在链路上发生的重试放大效应","tags":["架构","微服务"],"categories":["字节青训营"]},{"title":"分布式理论——现代架构基石","path":"/posts/distribution-theory/","content":"分布式概述什么是分布式 分布式系统是计算机程序的结合，这些程序利用跨多个独立计算节点的计算资源来实现共同的目标，可以分为分布式计算，分布式存储，分布式数据库等 优势： 去中心化 低成本 弹性 资源共享 可靠性高 挑战： 普遍的节点故障 不可靠的网络 异构的机器与硬件环境 安全 Why-How-What 使用者视角： Why： 数据爆炸，对存储和计算有大规模运营的诉求 成本低，构建在廉价服务器之上 How： 分布式框架 成熟的分布式系统 What： 理清规模，负载，一致性要求等 明确稳定性要求，制定技术方案 学习者视角： Why： 后端开发必备技能 帮助理解后台服务器之间协作的机理 How： 掌握分布式理论 了解一致性协议 What： 把要点深入展开，针对难点搜索互联网资料进行学习 把所学知识运用于实践 常见的分布式系统 分布式存储 Google File System（GFS）：google 分布式文件系统 Ceph：统一的分布式存储系统 Hadoop HDFS：基于 GFS 架构的开源分布式文件系统 Zookeeper：高可用的分布式数据管理与系统协调框架 分布式数据库 Google Spanner：google 可扩展的、全球分布式的数据库 TiDB：开源分布式关系型数据库 HBase：开源 Nosql 数据库 MongoDB：文档数据库 分布式计算 Hadoop：基于 MapReduce 分布式计算框架 Spark：在 Hadoop 基础上，使用内存来存储数据 YARN：分布式资源调度 系统模型故障模型 Byzantine failure：节点可以任意篡改发送给其他节点的数据，是最难处理的故障 Authentication detectable byzantine failure (ADB)：节点可以篡改数据，但不能伪造其他节点的数据 Performance failure：节点未在特定时间段内收到数据，即时间太早或太晚 Omission failure：节点收到数据的时间无限晚，即收不到数据 Crash failure：在 Omission failure 的基础上，增加了节点停止响应的假设，也即持续性地 Omission failure Fail-stop failure：在 Crash failure 的基础上增加了错误可检测的假设 拜占庭将军问题 引入： 两支军队的将军只能派信使穿越敌方领土互相通信，以此约定进攻时间。该问题希望求解如何在两名将军派出的任何信使都可能被俘虏的情况下，就进攻时间达成共识 结论： 两将军问题是被证实无解的电脑通信问题，两支军队理论上永远无法达成共识 方案： 一、同时发送 N 个信使，任何一个达到对方军队，都算成功 二、设置超时时间，发送后未在一定时间返回，则加派信使 共识与消息传递的不同：即使保证了消息传递成功，也不能保证达成共识 TCP 三次握手是在两个方向确认包的序列号，增加了超时重试，是两将军问题的一个工程解 三将军问题 拜占庭将军考虑更加普适的场景，例如 3 个将军 ABC 互相传递消息，消息可能丢失，也可能被篡改，当有一个将军是“叛徒”（即出现拜占庭故障）时，整个系统无法达成一致 如果没有”叛徒“，无论各自观察到怎样的敌情，总能达成一致的行动 由于“叛徒”C 的存在，将军 A 和将军 B 获得不同的信息。这样将军 A 获得 2 票进攻 1 票撤退的信息，将军 B 获得 1 票进攻 2 票撤退的信息，产生了不一致 四将军问题 考虑当 4 个将军，只有一个叛徒的场景，将军 D 作为消息分发中枢，约定如果没收到消息则执行撤退 步骤： 如果 D 为“叛徒”，ABC 无论收到任何消息，总能达成一致 D 为“忠将”，ABC 有 2 人将 D 的消息进行正确的传递，同样能保证最终决策符合大多数 进而能够证明，当有 3m+1 个将军，m 个“叛徒”时，可以进行 m 轮协商，最终达成一致 共识和一致性 客户端 A 读到 x&#x3D;0，当客户端 C 正在写入时，客户端 A 和客户端 B 可能读到 0 或者 1。但是当 C 写入完成后，A 和 B 最终能读到一致的数据，称这样的一致性为 Eventually consistent（最终一致性） 读请求和写请求并发时可能读到旧值 当客户端 A 读到更新的版本 x&#x3D;1 后，及时将消息同步给其他客户端，这样其他客户端立即能获取到 x&#x3D;1，称这样的一致性为 Linearizability（线程一致性） 一旦某个读取到新值，所有客户端都必须返回新值 如果要保证”线程“一致性，多个节点间势必需要进行协商，以寻求一致。这样增加了延迟，系统可用性便会受损 时间和事件顺序 1978 年 Leslie Lamport 发表《Time, Clocks, and the Ordering of Events in a Distributed System》 我们定义 ”happened before“ 关系，记为”-&gt;“。其满足如下三个条件： 如果 a 和 b 是在相同节点上的两个事件，a 在 b 之前发生，则定义 a-&gt;b 如果事件 a 表示某个节点发送某条消息，b 是另一个节点接受这条消息，则有 a-&gt;b 如果有 a-&gt;b 且 b-&gt;c ，则有 a-&gt;c 当且仅当 a -&#x2F;-&gt; b 且 b -&#x2F;-&gt; a 时，我们称两个事件为并发的（concurrent） Lamport 逻辑时钟 对于每一个节点 Pi 我们定义时钟 Ci 为一个函数，它为任意的事件 a 赋值编号为 Ci(a) 如果 a 和 b 是在相同节点 pi 上的两个事件，a 在 b 之前发生，则有 Ci(a)&lt;Ci(b) 如果事件 a 表示节点 pi 发送某条消息，b 表示节点 Pj 接受这条消息，则有 Ci(a)&lt;Cj(b) 在同一节点内的连续两个事件之间，至少要有一条 tick line 利用逻辑时钟，我们可以对整个系统中的事件进行全序排序 理论基础CAP 理论 CAP 理论往往运用于数据库领域，同样可以适用于分布式存储方向 CA：放弃分区容错性，加强一致性和可用性，其实就是传统的单机数据库的选择 AP：放弃一致性（这里说的是一致性是强一致性），追求分区容错性和可用性，例如一些注重用户体验的系统 CP：放弃可用性，追求一致性和分区容错性，例如与钱财安全相关的系统 在网络发生分区的情况下，我们必须在可用性和一致性之间做出选择。近似解决方法：把故障节点的负载转移给备用节点负责。下图演示了如何做故障转移： ACID 理论 事务是数据库系统中非常重要的概念，它是数据库管理系统执行过程中的一个逻辑单元，它能够保证一个事务中的所有操作要么全部执行，要么全都不执行 数据库事务拥有四个特性ACID：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability） 原子性（A）：原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚 一致性（C）：一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态 隔离性（I）：隔离性是当多个用户并发访问数据库时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离 持久性（D）：持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即使是在数据库系统遇到故障的情况下也不会丢失提交事务的操作 BASE 理论 Base 理论是对 CAP 中一致性和可用性权衡的结果，其来源于对大型互联网分布式实践的总结，是基于 CAP 定理逐步演化而来的，其核心思想是： Basically Available(基本可用)：假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言：响应时间上的损失，或功能上的损失 Soft state（软状态）：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延迟 Eventually consistent（最终一致性）：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问最终都能够获取到最新的值 分布式事务二阶段提交 二阶段提交（Two-phase Commit）：为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种演算法 三个假设： 引入协调者（Coordinator）和参与者（Participants），互相进行网络通信 所有节点都采用预写式日志，且日志被写入后即被保持在可靠的存储设备上 所有节点不会永久性损坏，即使损坏后仍然可以恢复 可能出现的情况： 1、Coordinator 不宕机，Participant 宕机。需要进行回滚操作 2、Coordinator 宕机，Participant 不宕机。可以引起新的协调者，待查询状态后，重复二阶段提交 3、Coordinator 宕机，Participant 宕机。无法确定状态，需要数据库管理员的介入，防止数据库进入一个不一致的状态 回滚：在 Prepare 阶段，如果某个事务参与者反馈失败消息，说明该节点的本地事务执行不成功，必须回滚 需注意的问题： 性能问题 两阶段提交需要多次节点间的网络通信，耗时过大，资源需要进行锁定，徒增资源等待时间 协调者单点故障问题 如果事务协调者节点宕机，需要另起新的协调者，否则参与者处于中间状态无法完成事务 网络分区带来的数据不一致 一部分参与者收到了 Commit 消息，另一部分参与者没收到 Commit 消息，会导致节点之间数据不一致 三阶段提交 三阶段提交 vs 两阶段提交 将两阶段提交中的 Prepare 阶段，拆成两部分：CanCommit 和 PreCommit 机制 解决了两个问题： 单点故障问题 阻塞问题 另外引入超时机制，在等待超时之后，会继续进行事务的提交 MVCC MVCC 是一种并发控制的方法，维持一个数据的多个版本使读写操作没有冲突。所以既不会阻塞写，也不阻塞读。MVCC 为每个修改保存一个版本，和事务的时间戳相关联，可以提高并发性能，解决脏读的问题 版本的选取： 物理时钟：提供 TrueTime API，有 Master 节点维持一个绝对时间，保证各个服务器之间时钟误差控制在 ϵ 内，通常 ϵ&lt;7ms 逻辑时钟：时间戳预言机（TSO），采用中心化授时的方式，所有协调者向中心化节点获取时钟，优点是算法简单，实现方便，但需要每个节点都与他进行交互，会产生一些网络通信的成本。TSo 的授时中就需要考虑低延迟、高性能以及更好的容错性 共识协议Quorum NWR 模型 Quorum NWR 三要素 N：在分布式存储系统中，有多少份备份数据 W：代表一次成功的更新操作要求至少有 w 份数据写入成功 R： 代表一次成功的读数据操作要求至少有 R 份数据成功读取 为了保证强一致性，需要保证 W+R&gt;N Quorum NWR 模型将 CAP 的选择交给用户，是一种简化版的一致性模型 引起的并发更新问题 如果允许数据被覆盖，则并发更新容易引起一致性问题 RAFT 协议 Raft 协议是一种分布式一致性算法（共识算法），即使出现部分节点故障，网络延时等情况，也不影响各节点，进而提高系统的整体可用性。Raft 是使用较为广泛的分布式协议。一定意义上讲，RAFT 也使用了 Quorum 机制 三种角色： Leader - 领导者：Leader 负责处理所有的客户端请求，并向 Follower 同步请求日志，当日志同步到大多数节点上后，通知 Follower 提交日志 Follower - 跟随者：不会发送任何请求，接受并持久化 Leader 同步的日志，在 Leader 告知日志可以提交后，提交日志。当 Leader 出现故障时，主动推荐自己为 Candidate Candidate - 备选者：Leader 选举过程中的临时角色，向其他节点发送请求投票信息，如果获得大多数选票，则晋升为 Leader 四种定义： Log（日志）：节点之间同步的信息，以只追加写的方式进行同步，解决了数据被覆盖的问题 Term（任期号）：单调递增，每个 Term 内最多只有一个 Leader Committed：日志被复制到多数派节点，即可认为已经被提交 Applied：日志被应用到本地状态机：执行了 log 中命令，修改了内存状态 状态转移： Leader 选举过程： 1、初始全部为 Follower 2、Current Term + 1 3、选举自己 4、向其它参与者发起 RequestVote 请求，retry 直到 收到多数派请求，成为 Leader，并发送心跳 收到其它 Leader 的请求，转为 Follower，更新自己的 Term 收到部分，但未达到多数派，选举超时，随机 timeout 开始下一轮 两个规则 在一个任期内每个参与者最多投一票（持久化） 要成为 Leader，必须拿到多数投票 Log Replication 过程： 新 Leader 产生，Leader 和 Follower 不同步，Leader 强制覆盖 Followers 的不同步的日志 1、Leader 收到写请求 w 2、将 w 写入本地 log 3、向其他 Follower 发起 AppendEntries RPC 4、等待多数派回复 更新本地状态机，返回给客户端 下一个心跳通知 Follower 上一个 Log 已经被 Commited 了 Follower 也根据命令应用本地状态机 5、Follower 有问题，Leader 一直 retry 问题：如果 Leader 有问题呢？ 切主： 当 Leader 出现问题时，就需要进行重新选举 1、Leader 发现失去 Follower 的响应，失去 Leader 身份 2、两个 Follower 之间一段时间未收到心跳，重新进行选举，选出新的 Leader，此时发生了切主 3、Leader 自杀重启，以 Follower 的身份加入进来 问题：老 Leader 未失去身份，新 Leader 已经选出，产生了”双主“如何解决？ Stale 读： 发生 Leader 切换，old leader 收到了读请求。如果直接响应，可能会有 Stale Read 解决方案：保证读的强一致 该操作在 lease timeout 内，默认自己是 Leader；不是则发起一次 heartbeat。等待 Commit Index 应用到状态机 Election timeout &gt; least timeout；新 Leader 上任，自从上次心跳之后一定超过了 Election timeout，旧 Leader 大概率能够发现自己的 Lease 过期 Paxos 协议 Paxos 算法与 RAFT 算法区别： Multi-Paxos 可以并发修改日志，而 Raft 写日志操作必须是连续的 Multi-Paxos 可以随机选主，不必最新最全的节点当选 Leader 优势：写入并发性能高，所有节点都能写 劣势：没有一个节点有完整的最新的数据，恢复流程复杂，需要同步历史记录 - - 分布式实践MapReduce Mapper：将输入分解为多个 Job 来并行处理，彼此间几乎没有依赖关系 Shuffler：将 maper 结果打乱，防止数据倾斜 Reducer：对 map 阶段的结果进行全局汇总 容错： Mapper 故障：由中心化节点重新发起调度，新起 Mapper 重跑 job Reducer 故障：重跑 Mapper，代价大 分布式 KV 架构： 将海量结构化数据根据 Key 分成不同的 Region，每个 Region 构建一个单机 KV 数据库，Region 之间形成 Raft Groups，做到强一致 容错： 当 Node 故障时，通过 Raft Learner 模式进行数据修复 弹性： 当出现局部 Key 热点或数据膨胀时，Region 可以进行 Split 操作，分成两个子 Region，反之收缩时进行 Merge 操作 思考题","tags":["分布式","架构"],"categories":["字节青训营"]},{"title":"架构初探——谁动了我的蛋糕","path":"/posts/architecture-preliminary-exploration/","content":"什么是架构定义 架构，又称软件架构 是有关软件整体结构与组件的抽象描述 用于指导软件系统各个方面的设计 实现一个软件有很多种方式，架构在方法选择上起着至关重要的指导作用 架构的重要性 地基没打好，大厦容易倒 地基坚实了，大厦才能盖得高 站在巨人肩膀上，才能看得远 问题 兰师傅蛋糕坊要开张了，亟须解决如下问题： 如何做蛋糕 独家秘方，还是亲自做比较好 如何卖蛋糕 刚开始客流量应该不大，边做边卖 单机 软件系统需要具备对外提供服务，单机，就是把所有功能都实现在一个进程里，并部署在一台机器上 优点： 简单 问题： C10K problem 运维需要停服 演进：如何卖更多的蛋糕？ 多雇几个蛋糕师傅 单机架构：分布式部署 垂直应用架构：按应用垂直切分的单体 优点： 水平扩容 运维不需要停服 问题： 职责太多，开发效率不高 爆炸半径大 演进：如何提高做蛋糕效率？ 分工协作 SOA、微服务|水平切分 SOA（Service-Oriented Architecture） 将应用的不同功能单元抽象为服务 定义服务之间的通信标准 微服务架构：SOA 的去中心化演进方向 问题： 数据一致性 装货台共交付了多少蛋糕？ 高可用 这么多师傅，如何合作？ 治理 烤箱坏了，怎么容灾？ 解耦 vs 过微 运维成本高了，值当么？ 小结 架构演进初衷：好比做蛋糕 需求量越来越大，终归要增加人手 越做越复杂，终归要分工合作 架构的演进思路：就像切蛋糕，蛋糕越来越大，一口吃不下终归要切分 竖着切（垂直切分） 横着切（水平切分） 企业级后端架构剖析背景 兰师傅蛋糕店经过 3 年的蓬勃发展，积累了良好的口碑和用户基础，接下来，需要扩大规模： 店面怎么盘： 买 租 师傅怎么招： 兰师傅全家出马 招培训班出身的 是否继续坚持纯手工制作？ 规模大了以后，工作重心应该是？ 精进蛋糕制作收益 蛋糕店重点方向梳理 &amp; 未来规划 云计算 云计算：是指通过软件自动化管理，提供计算资源的服务网站，是现代互联网大规模数据分析和存储的基石 基础： 虚拟化技术 - 整租 vs 合租 编排方案 -业主 vs 租凭平台 架构： IaaS（Infrastructure as a Service） 买房子 vs 房屋租聘平台 PaaS（platform as a Service） 清包 vs 全包 Saas（Software as a Service） 从零培训 vs 雇佣培训过的师傅 FaaS（Function as a Service） 纯手工制作 vs 蛋糕机批量生产 云原生云原生技术为组织（公司）在公有云、自由云、混合云等新型的动态环境中，构建和运行可弹性扩展的应用提供了可能 弹性资源 弹性计算资源类型： 服务资源调度 微服务：和面、雕花 大服务：烤箱 计算资源调度 在线：热销榜单 离线：热销榜单更新 消息队列 在线：削峰、解耦 离线：大数据分析 弹性存储资源类型： 经典 对象：宣传视频 大数据：用户消费记录 关系型数据库 收银记录 元数据 服务发现：蛋糕店通讯录 NoSQL KV：来个 xx 蛋糕 总结：将存储资源当成服务一样 DevOps DevOps 是云原生时代软件交付的利器，贯穿证个软件开发周期 结合自动化流程，提高软件开发、交付效率 微服务架构 通信标准： HTTP（RESTful API） RPC（Thrift，gRPC） 微服务中间件 RPC vs HTTP： 性能 服务治理 服务可解释性 云原生场景下，微服务大可不必在业务逻辑中实现符合通信标准的交互逻辑，而是交给框架来做 服务网格 服务网格（Service Mesh）： 微服务之间通讯的中间层 高性能网格代理 业务代码与治理解耦 相比较于 RPC&#x2F;HTTP 框架： 异构系统治理统一化 与业务进程解耦，生命周期易管理 云原生蛋糕店 企业级蛋糕店架构： 售卖 蛋糕制作（肉松、慕斯） 会员激励 满意度分析 研发新品 企业级后端架构的挑战问题 挑战： 物理资源是有限的 机器 宽带 资源利用率受制于部署服务 用户层面 网络通信开销较大 网络抖动导致运维成本提高 异构环境下，不同实例资源水位不同 离在线资源并池 核心收益： 降低物理资源成本 提供更多的弹性资源，增加收入 解决思路：离在线资源并池 在线业务的特点 IO 密集型为主 潮汐性、实时性 离线业务的特点 计算密集型占多数 非实时性 问题：同一个机器怎么做离在线隔离？ 自动扩缩容 核心收益： 降低业务成本 解决思路： 自动扩缩容 利用在线业务潮汐性自动扩缩容 问题：扩缩容依据什么指标？ 微服务亲和性部署 核心收益 降低业务成本 提高服务可用性 解决思路：微服务亲和性部署 将满足亲和性条件的容器调度到一台宿主机 微服务中间件与服务网格通过共享内存通信 服务网格控制面实施灵活、动态的流量调度 流量治理 核心收益： 提高微服务调用容错性 容灾 进一步提高开发效率，DevPos 发挥到极致 解决思路：基于微服务中间件 &amp; 服务网格的流量治理 熔断、重试 单元化 复杂环境（功能、预览）的流量调度 CPU 水位负载均衡 核心收益： 打平异构环境算力差异 为自动扩缩容提供正向收入 解决思路：CPU 水位负载均衡 IaaS 提供服务探针 服务网格 动态负载均衡 后端架构实战问题背景 兰师傅蛋糕店也碰到了类似的问题： 不同师傅干活的效率差距较大 有些师傅希望能者多劳多挣 在这个背景下，继续像之前一样为每个师傅分配完全相同的工作，会引起他们的不满 回到 CPU 水位负载均衡，应该如何设计？ 需要哪些输入？ 设计师需要考虑哪些关键点？ 问题提炼 输入： 服务网格数据面 支持带权重的负载均衡策略 注册中心存储了所有容器的权重信息 宿主机能提供 容器的资源使用情况 物理资源信息（如 CPU 型号） 关键点： 紧急回滚能力 大规模 极端情况 自适应静态权重 方案： 采集宿主机物理资源信息 调整容器注册的权重 优势： 复杂度低 完全分布式，可用性高 微服务中间件无适配成本 缺点： 无紧急回滚能力 缺乏运行时自适应能力 自适应动态权重 Alpha 方案： 容器动态权重的自适应调整 服务网格的服务发现 &amp; 流量调度能力 演进方向： 解决无法紧急回滚的问题 运行时权重自适应 缺点： 过度流量倾斜可能会有异常情况 自适应动态权重 Beta 方案： 服务网格上报 RPC 指标 演进方向： 极端场景的处理成为可能 缺点： 时序数据库压力较大 动态权重决策中心职责越来越多，迭代-&gt;变更-&gt;风险 自适应动态权重 Release 演进方向： 微服务化 引入消息队列削峰、解耦 离在线链路切分 梳理强弱依赖 尾声 没有最好的架构，只有最合适的架构 如何做架构设计 需求先行：弄清楚要解决什么问题 业界调研：业界都有哪些解决方案可供参考 技术选型：内部&#x2F;社区都有哪些基础组件 异常情况：考虑清楚 xxx 不行了怎么办","tags":["架构"],"categories":["字节青训营"]},{"title":"规则引擎设计与实现","path":"/posts/rule-engine-design-and-implementation/","content":"认识规则引擎规则引擎的定义规则引擎是一种嵌入在应用服务中的组件，实现了将业务决策从应用程序代码中分离出来，并使用预定义的语义模块编写业务决策。接受数据输入，解释业务规则，并根据业务规则做出业务决策 解决开发人员重复编码的问题 业务决策与服务本身解耦，提高服务的可维护性 缩短开发路径，提高效率 组成部分 应用场景 编译原理基本概念 词法分析 Lexical Analysis 词法分析就是把源代码字符串转换为词法单元（Token）的这个过程 如何识别 Token？——有限自动机（Finite-State Automation) 有限自动机就是一个状态机，它的状态数量是有限的。该状态机在任何一个状态，基于输入的字符，都能做一个确定的状态转换 语法分析 Syntax Analysis 语法分析就是在词法分析的基础上，识别表达式的语法结构的过程 抽象语法树 表达式的语法结构可以用树来表示，其每个节点（子树）是一个语法单元，这个单元的构成规则就叫“语法”。每个节点还可以有下级节点 抽象语法树 Abstract Syntax Tree 上下文无关语法 Context-Free Grammar 语法句子无需考虑上下文，就可以判断正确性。可以使用巴科斯范式（BNF）来表达 产生式：一个表达式可以由另外已知类型的表达式或者符号推导产生 内置符号：字面量（string、bool、number）标识符、运算符 一个基础表达式可以由 常量（string、bool、number）或标识符（identifier） 一个乘法表达式可以由 基础表达式 或者 乘法表达式 * 基础表达式组成 . . . . . . 递归下降算法 Recursive Descent Parsing 递归下降算法就是自顶向下构造语法树 不断的对 Token 进行语法展开（下降），展开过程中可能会遇到递归的情况 演示 类型检查 类型综合 根据子表达式的类型构造出父表达式的类型。例如，表达式 A+B 的类型是根据 A 和 B 的类型定义的 编译时检查 &amp; 运行时检查 类型检查可以发生在表达式的编译阶段，即在构造语法树的阶段；也可以发生在执行时的阶段 编译时：需要提前声明参数的类型，在构建语法树的过程中进行类的检查 执行时：可以根据执行时的参数输入的值的类型，在执行过程中进行类型检查 设计一个规则引擎设计目标 设计一个规则引擎，支持特定的语法、运算符、数据类型和优先级。并且基于以上预定义语法的规则表达式的编译和执行 词法（合法 Token） 参数：由字母数字下划线组成 eg：_ab2、user_name 布尔值：true、false 字符串：”abcd”、’abcd’、`abcd` 十进制 int：1234 十进制 float：123.5 预定义运算符：+ - 运算符 一元运算符：+ - 二元运算符：+ - * &#x2F; % &gt; &lt; &gt;&#x3D; &lt;&#x3D; &#x3D;&#x3D; !&#x3D; 逻辑操作符：&amp;&amp; || ! 括号：（ ） 数据类型 字符串 布尔值 十进制 int 十进制 float 优先级 词法分析 参数：由字母数字下划线组成 eg：_ab2、user_name 布尔值：true、false 字符串：”abcd”、’abcd’、`abcd` 十进制 int：1234 十进制 float：123.5 预定义运算符：+ - 设计词法分析的状态机 语法分析 优先级的表达 语法树结构 一元运算符：左子树为空，右子树为右操作数 二元运算符：左子树为左操作数，右子树为右操作数 括号：左子树为空，右子树为内部表达式的 AST 语法树执行与类型检查 语法树执行 预先定义好每种操作符的执行逻辑 对抽象语法树进行后续遍历执行，即： 先执行左子树，得到左节点的值 再执行右子树，得到右节点的值 最后根据根节点的操作符执行得到根节点的值 类型检查 检查时机：执行时检查 检查方法：在一个节点的左右子节点执行完成后，分别校验左右子节点的类型是否符合对应操作符的类型检查预设规则 ‘&gt;’符号要求左右子节点的值都存在且为 int 或 float ‘!’符号要求左节点为空且右节点的值为 bool 实现规则引擎","tags":["规则引擎"],"categories":["字节青训营"]},{"title":"Go框架三件套详解（Web/RPC/ORM）","path":"/posts/go-framework-three-piece-set/","content":"三件套介绍01.GormGorm 是一个已经迭代了 10 年+的功能强大的 ORM 框架，在字节内部被广泛使用并且拥有非常丰富的开源扩展。 02.KitexKitex 是字节内部的 Golang 微服务 RPC 框架，具有高性能、强可扩展的主要特点，支持多协议并且拥有丰富的开源扩展。 03.HertzHertz 是字节内部的 HTTP 框架，参考了其他开源框架的优势，结合字节跳动内部的需求，具有高易用性、高性能、高扩展性特点。 三件套的使用GormGorm 的基本使用 Gorm 的约定（默认） Gorm 使用名为 ID 的字段作为主键 使用结构体的蛇形复数作为表名 字段名的蛇形作为列名 使用 CreatedAt、UpdatedAt 字段作为创建、更新时间 Gorm 支持的数据库 Gorm 目前支持 MySQL、SQLServer、PostgreSQL、SQLite 什么是 DSN https://github.com/go-sql-driver/mysql#dsn-data-source-name Gorm 通过驱动来连接数据库，如果需要连接其它类型的数据库，可以复用&#x2F;自行开发驱动 Gorm 创建数据 如何使用 Upsert使用 clause.OnConflict 处理数据冲突 如何使用默认值通过使用 default 标签为字段定义默认值 Gorm 查询数据 First 的使用踩坑 使用 First 时，需要注意查询不到数据会返回 ErrRecordNotFound 使用 Find 查询多条数据，查询不到数据不会返回错误 使用结构体作为查询条件 当使用结构体作为条件查询时，Gorm 只会查询非零值字段。这意味着如果你的字段值为 0、**””、false** 或其他零值，该字段不会被用于构建查询条件，使用 Map 来构建查询条件 Gorm 更新数据 使用 Struct 更新时，只会更新非零值，如果需要更新零值可以使用 Map 更新或使用 Select 选择字段 Gorm 删除数据物理删除 软删除 Gorm 提供了 gorm.DeletedAt 用于帮助用户实现软删除 拥有软删除能力的 Model 调用 Delete 时，记录不会被从数据库中真正删除。但 Gorm 会将 DeletedAt 置为当前时间，并且你不能再通过正常的查询方法找到该纪录 使用 Unscoped 可以查询到被软删除的数据 Gorm 事务Gorm 提供了 Begin、Commit、Rollback 方法用于事务 Gorm 提供了 Tansaction 方法用于自动提交事务，避免用户漏写 Commit、RollBack Gorm Hook Gorm 提供了 CURD 的 Hook 能力 Hook 是在创建、查询、更新、删除等操作之前、之后自动调用的函数 如果任何 Hook 返回错误，Gorm 将停止后续的操作并回滚事务 Gorm 性能提高 对于写操作（创建、更新、删除），为了确保数据的完整性，Gorm 会将它们封装在事务内运行。但这会降低性能，你可以使用 SkipDefaultTransaction 关闭默认事务 使用 PrepareStmt 缓存预编译语句可以提高后续调用的速度，本机测试提高大约**35%**左右 Gorm 生态Gorm 拥有非常丰富的扩展生态，以下列举一部分常用扩展 Gorm 代码生成工具 https://github.com/go-gorm/gen Gorm 分片库方案 https://github.com/go-gorm/sharding Gorm 手动索引 https://github.com/go-gorm/hints Gorm 乐观锁 https://github.com/go-gorm/optimisticlock Gorm 读写分离 https://github.com/go-gorm/dbresolver Gorm Open Telemetry 扩展 https://github.com/go-gorm/opentelemetry Kitex安装 Kitex 代码生成工具 Kitex 目前对 Windows 的支持不完善，如果本地开发环境是 Windows 建议使用虚拟机或 WSL2 安装代码生成工具 go install github.com/cloudwego/kitex/tool/cmd/kitex@latest go install github.com/cloudwego/thriftgo@latest 定义 IDL 使用 IDL 定义服务与接口 如果我们要进行 RPC，就需要知道对方的接口是什么，需要传什么参数，同时也需要知道返回值是什么样的。这时候，就需要通过 IDL 来约定双方的协议，就像在写代码的时候需要调用某个函数，我们需要知道函数签名一样 Kitex 生成代码使用 kitex -module example -service example echo.thrift 命令生成代码 build.sh：构建脚本 kitex_gen：IDL 内容相关的生成代码，主要是基础的 Server&#x2F;Client 代码 main.go：程序入口 handler.go：用户在该文件里实现 IDL service 定义的方法 Kitex 基本使用服务默认监听 8888 端口 Kitex Client 发起请求创建 Client 发起请求 kitex 服务注册与发现目前 Kitex 的服务注册与发现已经对接了主流的服务注册与发现中心，如 ETCD，Nacos 等 Kitex 生态Kitex 拥有非常丰富的扩展生态，以下列举一部分常用扩展 XDS 扩展 https://github.com/kitex-contrib/xds opentelemetry 扩展 https://github.com/kitex-contrib/obs-opentelemetry ETCD 服务注册与发现扩展 https://github.com/kitex-contrib/registry-etcd Nacos 服务注册与发现扩展 https://github.com/kitex-contrib/registry-nacos Zookeeper 服务注册与发现扩展 https://github.com/kitex-contrib/registry-zookeeper polaris 扩展 https://github.com/kitex-contrib/polaris 丰富的示例代码与业务 Demo https://github.com/cloudwego/kitex-examples/ HertzHertz 基本使用使用 Hertz 实现，服务监听 8080 端口并注册了一个 GET 方法的路由函数 Hertz 路由Hertz 提供了 GET、POST、PUT、DELETE、ANY 等方法用于注册路由 Hertz 提供了路由组（Group）的能力，用于支持路由分组的功能 Hertz 提供了参数路由和通配路由，路由的优先级为：静态路由&gt;命名路由&gt;通配路由 Hertz 参数绑定Hertz 提供了 Bind、Validate、BindAndValidate 函数用于进行参数绑定和校验 Hertz 中间件Hertz 的中间件主要分为客户端中间件与服务端中间件，如下展示一个服务端中间件 如何终止中间件调用链的执行 c.Abort c.AbortWithMsg c.AbortWithStats Hertz ClientHertz 提供了 HTTP Client 用于帮助用户发送 HTTP 请求 Hertz 代码生成工具Hertz 提供了代码生成工具 Hz，通过定义 IDL（inteface description language）文件即可生成对应的基础服务代码 目录结构 生成文件 Hertz 性能 网络库 Netpoll Json 编解码 Sonic 使用 sync.Pool 复用对象协议层数据解析优化 Hertz 生态Hertz 拥有非常丰富的扩展生态，以下列举一部分常用扩展 HTTP2 扩展 https://github.com/hertz-contrib/http2 opentelemetry 扩展 https://github.com/hertz-contrib/obs-opentelemetry 国际化扩展 https://github.com/hertz-contrib/i18n 反向代理扩展 https://github.com/hertz-contrib/reverseproxy JWT 鉴权扩展 https://github.com/hertz-contrib/jwt Websocket 扩展 https://github.com/hertz-contrib/websocket 丰富的示例代码与业务 Demo https://github.com/cloudwego/hertz-examples/ 实战案例笔记服务项目地址 优化版：https://github.com/cloudwego/biz-demo/tree/main/easy_note 普通版：https://github.com/cloudwego/kitex-examples/tree/main/bizdemo/easy_note 项目介绍笔记项目是一个使用 Hertz、Kitex、Gorm 搭建出来的具备一定业务逻辑的后端 API 项目 服务名称 服务介绍 传输协议 主要技术栈 demoapi API 服务 HTTP Gorm&#x2F;Kitex&#x2F;Hertz demouser 用户数据管理 Protobuf Gorm&#x2F;Kitex demonote 笔记数据管理 Thrift Gorm&#x2F;Kitex 项目功能介绍 项目调用关系 IDL 介绍 项目技术栈介绍 Hertz 关键代码 Kitex Client 关键代码 Kitex Server 关键代码 Gorm 关键代码","tags":["Go"],"categories":["字节青训营"]},{"title":"Go语言内存管理详解","path":"/posts/go-memory-management/","content":"引言 什么是性能优化？ 提升软件系统处理能力，减少不必要的消耗，充分发掘计算机算力 为什么要做性能优化？ 用户体验：带来用户体验的提升 —— 让刷抖音更丝滑，让双十一购物不再卡顿 资源高效利用：降低成本，提高效率 —— 很小的优化乘以海量机器会是显著的性能提升和成本节约 性能优化 业务层优化 针对特定场景，具体问题，具体分析 容易获得较大性能收益 语言运行时优化 解决更通用的性能问题 考虑更多场景 Tradeoffs 数据驱动 自动化性能分析工具 —— pprof 依靠数据而非猜测 首先优化最大瓶颈 软件质量 保证接口稳定的前提下改进实现 测试用例：覆盖尽可能多的场景，方便回归 文档：做了什么，没做什么，能达到怎样的效果 隔离：通过选项控制是否开启优化 可观测：必要的日志输出 自动内存管理 动态内存 程序在运行时根据需求动态分配的内存：malloc() 自动内存管理（垃圾回收）：由程序语言的运行时系统回收动态内存 避免手动内存管理，专注于实现业务逻辑 保证内存使用的正确性和安全性：double-free problem，use-after-free problem 三个任务 为新对象分配空间 找到存活对象 回收死亡对象的内存空间 相关概念 Mutator：业务线程，分配新对象，修改对象指向关系 Collector：GC 线程，找到存活对象，回收死亡对象的内存空间 Serial GC：只有一个 collector Parallel GC：支持多个 collectors 同时回收的 GC 算法 Concurrent GC：mutator(s) 和 collector(s) 可以同时执行 Collectors 必须感知对象指向关系的改变 评价 GC 算法 安全性(Safety)：不能回收存活的对象 基本要求 吞吐率(Throughput)：1-GC 时间&#x2F;程序执行总时间 花在 GC 上的时间 暂停时间(Pause time)：stop the world（STW）业务是否感知 内存开销(Space overhead) GC 元数据开销 追踪垃圾回收(Tracing garbage collection) 引用计数(Reference counting) 追踪垃圾回收 对象被回收的条件：指针指向关系不可达的对象 标记根对象 静态变量、全局变量、常量、线程栈等 标记：找到可达对象 求指针指向关系的传递闭包：从根对象出发，找到所有可达对象 清理：所有不可达对象 将存活对象复制到另外的内存空间（Copying GC） 将死亡对象的内存标记为”可分配“（Mark-sweep GC） 使用 free list 管理空闲内存 移动并整理存活对象（Mark-compact GC） 原地整理对象 根据对象的生命周期，使用不同的标记和清理策略 分代 GC(Generational GC) 分代假说(Generational hypothesis)：most objects die young Intuition：很多对象在分配出来后很快就不再使用了 每个对象都有年龄：经历过 GC 的次数 目的：对年轻和年老的对象，制定不同的 GC 策略，降低整体内存管理的开销 不同年龄的对象处于 heap 的不同区域 年轻代(Young generation) 常规的对象分配 由于存活对象很少，可以采用 copying collection GC 吞吐率很高 老年代(Old generation) 对象趋向于一直活着，反复复制开销较大 可以采用 mark-sweep collection 引用计数 每个对象都有一个与之关联的引用数目 对象存活的条件：当且仅当引用数大于零 优点 内存管理的操作被平摊到程序执行过程中 内存管理不需要了解 runtime 的实现细节：C++智能指针(smart pointer) 缺点 维护引用计数的开销较大：通过原子操作保证引用计数操作的原子性和可见性 无法回收环形数据结构——weak reference 内存开销：每个对象都引入的额外内存空间存储引用数目 回收内存时依然可能引发暂停 Go 内存管理及优化内存分配分块 目标：为对象在 heap 上分配内存 提前将内存分块 调用系统调用 mmap() 向 OS 申请一大块内存，例如 4 MB 先将内存划分成大块，例如 8 KB，称作 mspan 再将大块继续划分成特定大小的小块，用于对象分配 noscan mspan：分配不包含指针的对象 —— GC 不需要扫描 scan mspan：分配包含指针的对象 —— GC 需要扫描 对象分配：根据对象的大小，选择最合适的块返回 缓存 TCMalloc：thread caching 每个 p 包含一个 mcache 用于快速分配，用于为绑定于 p 上的 g 分配对象 mcache 管理一组 mspan 当 mcache 中的 mspan 分配完毕，向 mcentral 申请带有未分配块的 mspan 当 mspan 中没有分配的对象，mspan 会被缓存在 mcentral 中，而不是立刻释放归还给 OS Go 内存管理优化 对象分配是非常高频的操作：每秒分配 GB 级别的内存 小对象占比较高 Go 内存分配比较耗时 分配路径长：g -&gt; m -&gt; p -&gt; mcache -&gt; mspan -&gt; memory block -&gt; return pointer pprof：对象分配的函数是最频繁调用的函数之一 字节优化方案：Balanced GC 每个 g 都绑定一大块内存（1KB），称作 goroutine allocation buffer（GAB） GAB 用于 noscan 类型的小对象分配：&lt;128 B 使用三个指针维护 GAB：base，end，top Bump pointer（指针碰撞）风格对象分配 无需和其他分配请求互斥 分配动作简单高效 GAB 对于 Go 内存管理来说是一个大对象 本质：将多个小对象的分配合并成一次大对象的分配 问题：GAB 的对象分配方式会导致内存被延迟释放 方案：移动 GAB 中存活的对象 当 GAB 总大小超过一定阈值时，将 GAB 中存活的对象复制到另外分配的 GAB 中 原先的 GAB 可以释放，避免内存泄漏 本质：用 copying GC 的算法管理小对象 编译器和静态分析编译器的结构 重要的系统软件 识别符合语法和非法的程序 生成正确且高效的代码 分析部分（前端 front end） 词法分析，生成词素（lexeme） 语法分析，生成语法树 语义分析，收集类型信息，进行语义检查 中间代码生成，生成 intermediate representation（IR） 综合部分（后端 back end） 代码优化，机器无关优化，生成优化后的 IR 代码生成，生成目标代码 静态分析 静态分析：不执行程序代码，推导程序的行为，分析程序的性质 控制流(Control flow)：程序执行的流程 数据流(Data flow)：数据在控制流上的传递 通过分析控制流和数据流，我们可以知道更多关于程序的性质（properties） 根据这些性质优化代码 过程内分析和过程间分析 过程内分析（Intra-procedural analysis） 仅在函数内部进行分析 过程间分析（Inter-procedural analysis） 考虑参数调用时参数传递和返回值的数据流和控制流 为什么过程间分析是个问题？ 需要通过数据流分析得知 i 的具体类型，才能知道 i.foo() 调用的是哪个 foo() 根据 i 的类型，产生了新的控制流，A.foo()，分析继续 过程间分析需要同时分析控制流和数据流——联合求解，比较复杂 Go 编译器优化 为什么做编译器优化 用户无感知，重新编译即可获得性能收益 通用性优化 现状 采取的优化少 编译时间较短，没有进行较复杂的代码分析和优化 编译优化的思路 场景：面向后端长期执行任务 Tradeoff：用编译时间换取更高效的机器码 Beast mode 函数内联 逃逸分析 默认栈大小调整 边界检查消除 循环展开 . . . . . . 函数内联（Inlining） 内联：将被调用函数的函数体（callee）的副本替换到调用位置（caller）上，同时重写代码以反映参数的绑定 优点 消除函数调用开销，例如传递参数，保存寄存器等 将过程间分析转化为过程内分析，帮助其他优化，例如逃逸分析 缺点 函数体变大，instruction cache（icache）不友好 编译生成的 Go 镜像变大 函数内联在大多数情况下是正向优化 内联策略 调用和被调用函数的规模 . . . . . . Beast Mode Go 函数内联受到的局限较多 语言特性，例如 interface，defer 等，限制了函数内联 内联策略非常保守 Beast Mode：调整函数内联的策略，使更多函数被内联 降低了函数内联的开销 增加了其他优化的机会：逃逸分析 开销 Go 镜像增加 ~10% 编译时间增加 逃逸分析 逃逸分析：分析代码中指针的动态作用域：指针在何处可以被访问 大致思路 从对象分配处出发，沿着控制流，观察对象的数据流 若发现指针 p 在当前作用域 s： 作为参数传递给其他函数 传递给全局变量 传递给其他的 goroutine 传递给已逃逸的指针指向的对象 则指针 p 指向的对象逃逸出 s，反之则没有逃逸出 s Beast mode：函数内联拓展了函数边界，更多对象不逃逸 优化：未逃逸的对象可以在栈上分配 对象在栈上分配和回收很快：移动 sp 减少在 heap 上的分配，降低 GC 负担","tags":["Go"],"categories":["字节青训营"]},{"title":"Go高质量编程与性能优化","path":"/posts/go-high-quality-programming-and-performance-optimization/","content":"高质量编程简介什么是高质量——编写的代码能够达到正确可靠、简单清晰的目标可称之为高质量代码 各种边界条件是否考虑完备 异常情况处理，稳定性保证 易读易维护 编程原则：实际应用场景千变万化，各种语言的特性和语法各不相同，但是高质量编程遵循的原则是相通的 简单性 消除“多余的复杂性”，以简单清晰的逻辑编写代码 不理解的代码无法修复改进 可读性 代码是写给别人看的，而不是机器 编写可维护代码的第一步是确保代码可读 生产力 团队整体工作效率非常重要 编码规范 如何编写高质量的 Go 代码 代码格式 注释 命名规范 控制流程 错误和异常处理 代码格式 推荐使用 gofmt 自动格式化代码 gofmt Go 语言官方提供的工具，能自动格式化 Go 语言代码为官方统一风格 常见 IDE 都支持方便的配置 goimports 也是 Go 语言官方提供的工具 实际等于 gofmt 加上依赖包管理 自动增删依赖的包引用、将依赖包按字母序排序并分类 注释 注释应该做的 注释应该解释代码作用 适合注释公共符号 注释应该解释代码如何做的 适合注释实现过程 注释应该解释代码实现的原因 适合解释代码的外部因素 提供额外上下文 注释应该解释代码什么情况会出错 适合解释代码的限制条件 公共符号始终要注释 包中声明的每个公共的符号：变量、常量、函数以及结构都需要添加注释 任何既不明显也不简短的公共必须予以注释 无论长度或复杂程度如何，对库中的任何函数都必须进行注释 尽管 LimitedReader.Read 本身没有注释，但他紧跟 LimitedReader 结构的声明，明确它的作用 有一个例外，不需要注释实现接口的方法，具体不要像下面这样做 小结 代码是最好的注释 注释应该提供代码未表达出的上下文信息 命名规范 variable 简洁胜于冗长 缩略词全大写，但当其位于变量开头且不需要导出时，使用全小写 例如使用 ServeHTTP 而不是 ServeHttp 使用 XMLHTTPRequest 或者 xmlHTTPRequest 变量距离其被使用的地方越远，则需要携带越多的上下文信息 全局变量在其名字中需要更多的上下文信息，使得在不同地方可以轻易辨认出其含义 i 和 index 的作用域范围仅限于 for 循环内部时 index 的额外冗长几乎没有增加对于程序的理解 将 deadline 替换成 t 降低了变量名的信息量 t 常指任意时间 deadline 指截止时间，有特定的含义 function 函数名不携带包名的上下文信息，因为包名和函数名总是成对出现的 函数名尽量简短 当名为 foo 的包某个函数返回类型 Foo 时，可以省略类型信息而不导致歧义 例如在 http 包中创建服务的函数 命名func Serve(I net.Listener, handler Handler) error而不是func ServeHTTP(I net.Listener, handler Handler) error 在其它包中调用时只需写 http.Serve 而不是 http.ServeHTTP 当名为 foo 的包某个函数返回类型 T 时（T 并不是 Foo），可以在函数名中加入类型信息 package 只由小写字母组成。不包含大写字母和下划线等字符 简短并包含一定的上下文信息 例如 schema、task 等 不要与标准库同名 例如不要使用 sync 或者 strings 以下规则尽量满足，以标准包名为例 不使用常用变量名作为包名 例如使用 bufio 而不是 buf 是用单数而不是复数 例如使用 encoding 而不是 encodings 谨慎地使用缩写 例如使用 fmt 在不破环上下文的情况下比 format 更加简短 小结 核心目标是降低阅读理解代码的成本 重点考虑上下文信息，设计简洁清晰的名称 控制流程 避免嵌套，保持正常流程清晰 如果两个分支中都包含 return 语句，则可以去除冗余的 else 尽量保持正常代码路径为最小缩进 优先处理错误情况&#x2F;特殊情况，尽早返回或继续循环来减少嵌套 最常见的正常流程的路径被嵌套在两个 if 条件内 成功的返回条件是 return nil ，必须仔细匹配大括号来发现 函数最后一行返回一个错误，需要追溯到匹配的左括号，才能了解何时会触发错误 如果后续正常流程需要增加一步操作，调用新的函数，则又会增加一层嵌套 调整后 小结 线性原理，处理逻辑尽量走直线，避免复杂的嵌套分支 正常流程代码沿着屏幕向下移动 提升代码可维护性和可读性 故障问题大多出现在复杂的条件语句和循环语句中 错误和异常处理 简单错误处理 简单的错误指的是仅出现一次的错误，且在其他地方不需要捕获该错误 优先使用 error.New 来创建匿名变量来直接表示简单错误 如果有格式化的需求，使用 fmt.Errorf 错误的 Wrap 和 Unwrap 错误的 Wrap 实际上是提供了一个 error 嵌套另一个 error 的能力，从而生成一个 error 的跟踪链 在 fmt.Errorf 中使用：%v 关键字来将一个错误关联至错误链中 错误判定 判定一个错误是否为特定错误，使用 error.Is 不同于使用==，使用该方法可以判定错误链上的所有错误是否含有特定的错误 在错误链上获取特定种类的错误，使用 errors.As panic 不建议在业务代码中使用 panic 调用函数不包含 recover 会造成整个程序崩溃 若问题可以被屏蔽或解决，建议使用 error 代替 panic 当程序启动阶段发生不可逆转的错误时，可以在 init 或 main 函数中使用 panic recover recover 只能在被 defer 的函数中使用 嵌套无法生效 只在当前 goroutine 生效 defer 的语句是后进后出 如果需要更多的上下文信息，可以 recover 后在 log 中记录当前的调用栈 小结 error 尽可能提供简明的上下文信息，方便定位问题 panic 用于真正异常的情况 recover 生效范围，在当前 goroutine 的被 defer 的函数中生效 性能优化建议Benchmark 如何使用 性能表现需要实际数据衡量 Go 语言提供了支持基准性能测试的 benchmark 工具 go test -bench=. -benchmem 结果说明 Slice 预分配内存 尽可能在使用 make() 初始化切片时提供容量信息，特别是在追加切片时 原理 切片本质是一个数组片段的描述 包括了数组的指针 片段的长度 片段的容量(不改变内存分配情况下的最大长度) 切片操作并不复制切片指向的元素 创建一个新的切片会复用原来切片的底层数组 另一个陷阱：大内存未释放 在已有切片的基础上创建切片，不会创建新的底层数组 因为原来的底层数组没有发生变化，内存会一直占用，直到没有变量引用该数组 场景 原切片较大，代码在原切片基础上新建小切片 原底层数组在内存中有引用，得不到释放 可使用 copy 替代 re-slice Map 预分配内存 分析 不断向 map 中添加元素的操作会触发 map 的扩容 提前分配好空间可以减少内存拷贝和 Rehash 的消耗 根据实际需求提前预估好需要的空间 字符串处理（使用 strings.Builder) 常见的字符串拼接方式 strings.Builder bytes.Buffer strings.Builder 最快，bytes.Buffer 较快，+ 最慢 分析 字符串在 Go 语言中是不可变类型，占用内存大小是固定的 使用 + 每次都会重新分配内存 当使用 + 拼接 2 个字符串时，生成一个新的字符串，那么就需要开辟一段新的空间，新空间的大小是原来两个字符串的大小之和 strings.Builder 和 bytes.Buffer 底层都是 []byte 数组 内存扩容策略，不需要每次拼接重新分配内存 bytes.Buffer 转化为字符串时重新申请了一块空间，存放生成的字符串变量 strings.Builder 直接将底层的 []byte 转换成了字符串类型返回 预分配内存 结果 空结构体节省内存 空结构体 struct{} 示例不占据任何内存空间 可作为各种场景下的占位符使用 节省资源 空结构体本身具备很强的语义，即这里不需要任何值，仅作为占位符 实现 Set，可以考虑用 map 来代替 对于这个场景，只需要用到 map 的键，而不需要值 即使是将 map 的值设置为 bool 类型，也会多占据 1 个字节空间 atomic 包 原理 锁的实现是通过操作系统来实现，属于系统调用，atomic 操作是通过硬件实现的，效率比锁高很多 sync.Mutex 应该用来保护一段逻辑，不仅仅用于保护一个变量 对于非数值系列，可以使用 atomic.Value，atomic.Value 能承载一个 interface{} 小结 避免常见的性能陷阱可以保证大部分程序的性能 普通应用代码，不要一味地追求程序的性能 越高级的性能优化手段越容易出现问题 在满足正确可靠、简洁清晰等质量要求的前提下提高程序性能 性能调优实战简介 性能调优原则 要依靠数据不是猜测 要定位最大瓶颈而不是细枝末节 不要过早优化 不要过度优化 性能分析工具 pprof 希望知道应用在什么地方耗费了多少 CPU、Memory pprof 是用于可视化和分析性能分析数据的工具 功能简介 排查实战搭建 pprof 实践项目 Github（来自 Wolfogre） https://github.com/wolfogre/go-pprof-practice 项目提前埋入了一些炸弹代码，产生可观测的性能问题 浏览器查看指标 localhost:6060&#x2F;debug&#x2F;pprof&#x2F; 排查 CPU 命令行分析 （可读性较差） go tool pprof &quot;[http://localhost:6060/debug/pprof/profile?seconds=10](https://link.juejin.cn/?target=http%3A%2F%2Flocalhost%3A6060%2Fdebug%2Fpprof%2Fprofile%3Fseconds%3D10)&quot; 命令：topN 查看占用资源最多的函数 flat 当前函数本身的执行耗时 flat% flat 占 CPU 总时间的比例 sum% 上面每一行的 flat% 总和 cum 指当前函数本身加上其调用函数的总耗时 cum% cum 占 CPU 总时间的比例 Flat &#x3D;&#x3D; Cum，说明函数中没有调用其他函数 Flat &#x3D;&#x3D; 0，说明函数中只有其他函数的调用 命令：list 根据指定的正则表达式查找代码行 命令：web 调用关系可视化 go tool pprof -http=:8080 &quot;[http://localhost:6060/debug/pprof/cpu](http://localhost:6060/debug/pprof/cpu)&quot; 排查 Heap-堆内存 go tool pprof -http=:8080 &quot;[http://localhost:6060/debug/pprof/heap](https://link.juejin.cn/?target=http%3A%2F%2Flocalhost%3A6060%2Fdebug%2Fpprof%2Fheap)&quot; VIEW：切换视图类型 Top 视图 –&gt; Source 视图 SAMPLE alloc_objects：程序累计申请的对象数 alloc_space：程序累计申请的内存大小 inuse_objects：程序当前持有的对象数 inuse_space：程序当前占用的内存大小 排查 goroutine-协程goroutine 泄露也会导致内存泄漏 go tool pprof -http=:8080 &quot;[http://localhost:6060/debug/pprof/goroutine](https://link.juejin.cn/?target=http%3A%2F%2Flocalhost%3A6060%2Fdebug%2Fpprof%2Fgoroutine)&quot; VIEW 切换到 flamegraph 视图（常用） 由上到下表示调用顺序 每一块代表一个函数，越长代表占用 CPU 的时间更长 火焰图是动态的，支持点击块进行分析 支持搜索，在 Source 视图下搜索 排查 mutex-锁 go tool pprof -http=:8080 &quot;[http://localhost:6060/debug/pprof/mutex](https://link.juejin.cn/?target=http%3A%2F%2Flocalhost%3A6060%2Fdebug%2Fpprof%2Fmutex)&quot; 排查 block-阻塞 go tool pprof -http=:8080 &quot;[http://localhost:6060/debug/pprof/block](https://link.juejin.cn/?target=http%3A%2F%2Flocalhost%3A6060%2Fdebug%2Fpprof%2Fblock)&quot; 采样过程和原理CPU 采样对象：函数调用和它们占用的时间 采样率：100 次&#x2F;秒，固定值 采样时间：从手动启动到手动结束 开始采样 –&gt; 设定信号处理函数 –&gt; 开启定时器 停止采样 –&gt; 取消信号处理函数 –&gt; 关闭定时器 操作系统 每 10ms 向进程发送一次 SIGPROF 信号 进程 每次接收到 SIGPROF 会记录调用堆栈 写缓冲 每 100ms 读取已经记录的调用栈并写入输出流 Heap-堆内存 采样程序通过内存分配器在堆上分配和释放的内存，记录分配&#x2F;释放的大小和数量 采样率：每分配 512KB 记录一次，可在运行开头修改，1 为每次分配均记录 采样时间：从程序运行开始到采样时 采样指标：alloc_space，alloc_objects，inuse_space，inuse_objects 计算方式：inuse &#x3D; alloc - free Goroutine-协程 &amp; ThreadCreate-线程创建 Goroutine 记录所有用户发起且在运行中的 goroutine （即入口非 runtime 开头的）runtime.main 的调用栈信息 Stop The World –&gt; 遍历 allg 切片 –&gt; 输出创建 g 的堆栈 –&gt; Start The World ThreadCreate 记录程序创建的所有系统线程的信息 Stop The World –&gt; 遍历 allm 链表 –&gt; 输出创建 m 的堆栈 –&gt; Start The World Block-阻塞 &amp; Mutex-锁 阻塞操作 采样阻塞操作的次数和耗时 采样率：阻塞耗时超过阈值的才会被记录，1 为每次阻塞均记录 阻塞操作 – (上报调用栈和消耗时间) –&gt; Profiler –&gt; 时间未到阈值则丢弃 I–(采样)–&gt; 遍历阻塞记录 –&gt; 统计阻塞次数和耗时 锁竞争 采样争抢锁的次数和耗时 采样率：只记录固定比例的锁操作，1 为每次加锁均记录 锁竞争操作 – (上报调用栈和消耗时间) –&gt; Profiler –&gt; 比例未命中则丢弃 I–(采样)–&gt; 遍历锁记录 –&gt; 统计锁竞争次数和耗时 性能调优案例简介 业务服务优化 基础库优化 Go 语言优化 业务服务优化基本概念 服务：能单独部署，承载一定功能的程序 依赖：Service A 的功能实现依赖 Service B 的响应结果，称为 Service A 依赖 Service B 调用链路：能支持一个接口请求的相关服务集合及其相互之间的依赖关系 基础库：公共的工具包、中间件 流程 建立服务性能评估手段 分析性能数据，定位性能瓶颈 重点优化项改造 优化效果验证 建立服务性能评估手段 服务性能评估方式 单独 benchmark 无法满足复杂逻辑分析 不同负载下性能表现差异 请求流量构造 不同请求参数覆盖逻辑不同 线上真实流量情况 压测范围 单机器压测 集群压测 性能数据采集 单机性能数据 集群性能数据 分析性能数据，定位性能瓶颈 使用库不规范 高并发场景优化不足 重点优化项改造 正确性是基础 响应数据 diff 线上请求数据录制回放 新旧逻辑接口数据 diff 优化效果验证 重复压测验证 上线评估优化效果 关注服务监控 逐步放量 收集性能数据 进一步优化，服务整体链路分析 规范上游服务调用接口，明确场景需求 分析链路，通过业务流程优化提升服务性能 基础库优化AB 实验 SDK 的优化 分析基础库核心逻辑和性能瓶颈 设计完善改造方案 数据按需获取 数据序列化协议优化 内部压测验证 推广业务服务落地验证 Go 语言优化编译器&amp;运行时优化 优化内存分配策略 优化代码编译流程，生成更高效的程序 内部压测验证 推广业务服务落地验证 优点 接入简单，只需要调整编译配置 通用性强","tags":["Go"],"categories":["字节青训营"]},{"title":"Go语言进阶——工程进阶","path":"/posts/go-language-advanced/","content":"并发编程从并发编程的视角了解 Go 高性能的本质 并发 VS 并行 并发：多线程程序在一个核的 CPU 上运行 并行：多线程程序在多个核的 CPU 上运行 Go 可以充分发挥多核优势，高效运行（高并发） 协程 Goroutine 协程：用户态，轻量级线程，栈 KB 级别 线程：内核态，线程跑多个协程，栈 MB 级别 快速打印 hello goroutine : 4 12345678910111213141516171819func hello(i int) &#123;\tprintln(&quot;hello goroutine : &quot; + fmt.Sprint(i))&#125;func HelloGoRoutine() &#123;\tfor i := 0; i &lt; 5; i++ &#123; go func(j int) &#123; //为一个函数创建协程 hello(j) &#125;(i)\t&#125;\ttime.Sleep(time.Second) //保证子协程在执行完前主协程不退出&#125;//通过并行打印输出// hello goroutine : 4// hello goroutine : 1// hello goroutine : 0// hello goroutine : 2// hello goroutine : 3 CSP（Communicating Sequential Processes） 提倡通过通信共享内存而不是通过共享内存而实现通信 通道 Channal make(chan 元素类型,[缓冲大小]) 无缓冲通道 make(chan int) 有缓冲通道 make(chan int,2) 前者直接传输，也称为同构通道；后者类似快递柜，如果满了需要取走才能继续放，生产消费模型 1234567891011121314151617181920212223242526272829303132333435363738func CalSquare() &#123;\tsrc := make(chan int)\tdest := make(chan int, 3)\t//该子协程发送0~9数字\tgo func() &#123; defer close(src) for i := 0; i &lt; 10; i++ &#123; src &lt;- i &#125;\t&#125;()\t//该子协程计算输入数字的平方\tgo func() &#123; defer close(dest) for i := range src &#123; dest &lt;- i * i &#125;\t&#125;()\t//主协程输出最后的平方数\tfor i := range dest &#123; //复杂操作 println(i)\t&#125;&#125;//输出// 0// 1// 4// 9// 16// 25// 36// 49// 64// 81 Sync并发安全-锁 Lock pkg.go.dev&#x2F;sync对变量进行 2000 次+1 操作，5 个协程并发执行 12345678910111213141516171819202122232425262728293031323334353637var (\tx int64\tlock sync.Mutex)func addWithLock() &#123;\tfor i := 0; i &lt; 2000; i++ &#123; lock.Lock() x += 1 lock.Unlock()\t&#125;&#125;func addWithoutLock() &#123;\tfor i := 0; i &lt; 2000; i++ &#123; x += 1\t&#125;&#125;func Add() &#123;\tx = 0\tfor i := 0; i &lt; 5; i++ &#123; go addWithoutLock()\t&#125;\ttime.Sleep(time.Second)\tprintln(&quot;WithoutLock:&quot;, x)\tx = 0\tfor i := 0; i &lt; 5; i++ &#123; go addWithLock()\t&#125;\ttime.Sleep(time.Second)\tprintln(&quot;WithLock:&quot;, x)&#125;//输出（没有锁是不稳定的）// WithoutLock: 9245// WithLock: 10000 线程同步 WaitGroup pkg.go.dev&#x2F;sync 使用time.Sleep()等待子协程全部结束不够优雅 计数器：开启协程+1；执行结束-1；主协程阻塞知道计数器为 0 使用 WaitGroup 将 Goroutine 例子中的time.Sleep()替换优化 123456789101112131415func hello(i int) &#123;\tprintln(&quot;hello goroutine : &quot; + fmt.Sprint(i))&#125;func ManyGoWait() &#123;\tvar wg sync.WaitGroup\twg.Add(5) //开启5个协程\tfor i := 0; i &lt; 5; i++ &#123; go func(j int) &#123; defer wg.Done() //计数器-1 hello(j) &#125;(i)\t&#125;\twg.Wait() //阻塞&#125; 依赖管理了解 Go 语言依赖管理的演进路线 背景 工程项目不可能基于标准库 0~1 编码搭建 管理依赖库 Go 依赖管理演进 GOPATH - -&gt; Go Vender –&gt; Go Module 不同环境（项目）依赖的版本不同 控制依赖库的版本 GOPATH 环境变量$GOPATH 项目代码直接依赖 src 下的源码 go get 下载最新版本的包到 src 目录下 弊端 场景：A 和 B 依赖于某一 package 的不同版本 问题：无法实现 package 的多版本控制 Go Vender 通过每个项目引入一份依赖的副本，解决了多个项目需要同一个 package 依赖冲突的问题 项目目录下增加 vender 文件，所有依赖包副本形式放在$ProjectRoot&#x2F;vender 依赖寻址方式：vender &#x3D;&gt; GOPATH 弊端 无法控制依赖的版本 更新项目又可能出现依赖冲突，导致编译出错 Go Moudle go.dev&#x2F;blog&#x2F;using-go-modules 通过 go.mod 文件管理依赖包版本 通过 go get&#x2F;go mod 指令工具管理依赖包 终极目标：定义版本规则和管理项目依赖关系 依赖管理三要素 配置文件，描述依赖 go.mod 中心仓库管理依赖库 Proxy 本地工具 go get&#x2F;mod 依赖配置-go.mod 依赖标识：[Module Path][Version/Pseudo-version 依赖配置-version 语义化版本 $&#123;MAJOR&#125;.$&#123;MINOR&#125;.$&#123;PATCH&#125; V1.3.0 V2.3.0 基于 commit 伪版本 vX.0.0-yyyymmddhhmmss-abcdefg1234 v0.0.0-20220401081311-c38fb59326b7 v1.0.0-20201130134442-10cb98267c6c 依赖配置-indirect A -&gt; B -&gt; C A -&gt; B 直接依赖 A -&gt; C 间接依赖 依赖配置-incompatible 主版本 2+模块会在模块路径增加&#x2F;vN 后缀 对于没有 go.mod 文件并且主版本 2+的依赖，会+incompatible 依赖配置-依赖图 如果 X 项目依赖了 A、B 两个项目，且 A、B 分别依赖了 C 项目的 v1.3、v1.4 两个版本，最终编译时所使用的 C 项目的版本为如下哪个选项？（单选） A.v1.3 B.v1.4 C.A 用到 C 时用 v1.3 编译，B 用到 C 时用 v1.4 编译 答案：B 选择最低兼容版本（如果 C 项目有 v1.5 版本但未依赖，依旧选择 v1.4，即使都兼容） 依赖分发-回源 依赖分发：依赖从其他地方获取 问题 无法保证构建稳定性 增加&#x2F;修改&#x2F;删除软件版本 无法保证依赖可用性 删除软件 增加第三方压力 代码托管平台负载问题 依赖分发-Proxy Proxy：一个服务站点，缓存源站中的软件内容，不会改变版本，直接从 Proxy 拉取依赖 依赖分发-变量 GOPROXY GOPROXY&#x3D;”https://proxy1.cn,https://proxy2.cn,direct“ 服务站点 URL 列表，“direct”表示源站 Proxy1 -&gt; Proxy2 -&gt; Direct 如果前面 Proxy 都没有依赖会回源到第三方代码平台上去 工具-go get go get example.org&#x2F;pkg @update 默认 @none 删除依赖 @v1.1.2 tag 版本，语义版本 @23dfdd5 特定的 commit @master 分支的最新 commit 工具-go mod go mod init 初始化，创建 go.mod 文件 download 下载模块到本地缓存 tidy 增加需要的依赖，删除不需要的依赖 测试 回归测试 –&gt; 集成测试 –&gt; 单元测试 覆盖率逐层变大，成本却逐层降低 单元测试 pkg.go.dev&#x2F;testing从单元测试实践出发，提高质量意识 规则 所有测试文件以 _test.go 结尾 func TestXxx(*testing.T) 初始化逻辑放到 TestMain 中 例子print.go 12345package testfunc HelloTom() string &#123;\treturn &quot;Tom&quot;&#125; print_test.go 12345678910111213package testimport (\t&quot;testing&quot;)func TestHelloTom(t *testing.T) &#123;\toutput := HelloTom()\texpectOutput := &quot;Tom&quot;\tif output != expectOutput &#123; t.Errorf(&quot;Expected %s do not match actual %s&quot;, expectOutput, output)\t&#125;&#125; 运行go test [flags][packages] assertprint.go 12345package testfunc HelloTom() string &#123;\treturn &quot;Tom&quot;&#125; print_test.go 12345678910111213package testimport (\t&quot;testing&quot;\t&quot;github.com/stretchr/testify/assert&quot; //assert测试包)func TestHelloTom(t *testing.T) &#123;\toutput := HelloTom()\texpectOutput := &quot;Tom&quot;\tassert.Equal(t, expectOutput, output)&#125; 覆盖率 获取覆盖率需要在结尾加 --cover go test judgment_test.go judgment.go --cover judgment.go 12345678package testfunc JudgePassLine(score int16) bool &#123;\tif score &gt;= 60 &#123; return true\t&#125;\treturn false&#125; 不全judgment_test.go 1234567891011121314package testimport (\t&quot;testing&quot;\t&quot;github.com/go-playground/assert/v2&quot;)// 测试truefunc TestJudgePassLineTrue(t *testing.T) &#123;\tisPass := JudgePassLine(70)\tassert.Equal(t, true, isPass)&#125; 测试函数没有测试到return false，因此只有 2&#x2F;3 覆盖率 全judgment_test.go 12345678910111213141516171819package testimport (\t&quot;testing&quot;\t&quot;github.com/go-playground/assert/v2&quot;)// 测试turefunc TestJudgePassLineTrue(t *testing.T) &#123;\tisPass := JudgePassLine(70)\tassert.Equal(t, true, isPass)&#125;// 测试falsefunc TestJudgePassLineFail(t *testing.T) &#123;\tisPass := JudgePassLine(50)\tassert.Equal(t, false, isPass)&#125; tips 一般覆盖率：50%~60%，较高覆盖率 80%+ 测试分支相互独立、全面覆盖 测试单元粒度足够小，函数单一职责 依赖 外部依赖 &#x3D;&gt; 稳定&amp;幂等 文件处理 依赖于测试文件，如果测试文件被篡改，就不可运行了 mock.go 1234567891011121314151617181920212223242526package testimport (\t&quot;bufio&quot;\t&quot;os&quot;\t&quot;strings&quot;)func ReadFirstLine() string &#123;\topen, err := os.Open(&quot;log&quot;)\tdefer open.Close()\tif err != nil &#123; return &quot;&quot;\t&#125;\tscanner := bufio.NewScanner(open)\tfor scanner.Scan() &#123; return scanner.Text()\t&#125;\treturn &quot;&quot;&#125;func ProcessFirstLine() string &#123;\tline := ReadFirstLine()\tdestline := strings.ReplaceAll(line, &quot;ll&quot;, &quot;00&quot;)\treturn destline&#125; mock_test.go 123456789101112package testimport (\t&quot;testing&quot;\t&quot;github.com/go-playground/assert/v2&quot;)func TestProcessFirstLine(t *testing.T) &#123;\tfirstLine := ProcessFirstLine()\tassert.Equal(t, &quot;line00&quot;, firstLine)&#125; Mock github.com&#x2F;bouk&#x2F;monkey 快速 Mock 函数 为一个函数打桩 为一个方法打桩 12345678910111213141516// Patch replace a function with another// 用打桩函数替换原函数func Patch(target, replacement interface&#123;&#125;) *PatchGuard &#123;\tt := reflect.ValueOf(target)\tr := reflect.ValueOf(replacement)\tpatchValue(t, r)\treturn &amp;PatchGuard&#123;t, r&#125;&#125;// Unpatch removes any monkey patches on target// returns whether target was patched in the first place// 卸载桩func Unpatch(target interface&#123;&#125;) bool &#123;\treturn unpatchValue(reflect.ValueOf(target))&#125; 对 ReadFirstLine（文件处理代码）打桩测试，不再依赖本地文件 mock_test.go 123456789101112131415161718package testimport (\t&quot;testing&quot;\t&quot;bou.ke/monkey&quot;\t&quot;github.com/go-playground/assert/v2&quot;)// Mock打桩func TestProcessFirstLineWithMock(t *testing.T) &#123;\tmonkey.Patch(ReadFirstLine, func() string &#123; return &quot;line110&quot;\t&#125;)\tdefer monkey.Unpatch(ReadFirstLine)\tline := ProcessFirstLine()\tassert.Equal(t, &quot;line000&quot;, line)&#125; 基准测试 pkg.go.dev&#x2F;testing#hdr-Benchmarks 优化代码，需要对当前代码分析 内置的测试框架提供了基准测试的能力 例子随机选择执行服务器 12345678910111213141516171819package benchmarkimport (\t&quot;math/rand&quot;\t&quot;github.com/bytedance/gopkg/lang/fastrand&quot;)var ServerIndex [10]intfunc InitServerIndex() &#123;\tfor i := 0; i &lt; 10; i++ &#123; ServerIndex[i] = i + 100\t&#125;&#125;func Select() int &#123;\treturn ServerIndex[rand.Intn(10)]&#125; 运行1234567891011121314151617func BenchmarkSelect(b *testing.B) &#123;\tInitServerIndex()\tb.ResetTimer()\tfor i := 0; i &lt; b.N; i++ &#123; Select()\t&#125;&#125;func BenchmarkSelectParallel(b *testing.B) &#123;\tInitServerIndex()\tb.ResetTimer()\tb.RunParallel(func(pb *testing.PB) &#123; for pb.Next() &#123; Select() &#125;\t&#125;)&#125; 并行做基准测试性能会有劣化，rand 函数为了保证全局的随机性和并发安全有一把全局锁，在一定程度上降低了并发的性能 优化123func FastSelect() int &#123;\treturn ServerIndex[fastrand.Intn(10)]&#125; 项目实战通过项目需求、需求拆解、逻辑设计、代码实现感受真实的项目开发 需求背景（需求模型来源）青训营话题页forum.juejin.cn&#x2F;youthcamp&#x2F;p… 需求描述 社区话题页面 展示话题（标题，文字描述）和回帖列表 暂不考虑前端页面实现，仅仅实现一个本地 web 服务 话题和回帖数据用文件存储 需求用例 浏览消费用户 ER 图-Entity Relationship Diagram 话题 帖子 分层结构 数据层：数据 Model，外部数据的增删改查 逻辑层：业务 Entity，处理核心业务逻辑输出 视图层：视图 View，处理和外部的交互逻辑 组件工具 Gin 高性能 go web 框架 https://github.com/gin-gonic/gin#installation Go Mod go mod init go get gopkg.in/gin-gonic/gin.v1@v1.3.0 Repository 实现查询 QueryTopicById QueryPostsByParentId index 1234var (\ttopicIndexMap map[int64]*Topic\tpostIndexMap map[int64][]*Post) 初始化话题数据索引（帖子略） 123456789101112131415161718func initTopicIndexMap(filePath string) error &#123;\topen, err := os.Open(filePath + &quot;topic&quot;) //打开文件\tif err != nil &#123; return err\t&#125;\tscanner := bufio.NewScanner(open)\ttopicTmpMap := make(map[int64]*Topic)\tfor scanner.Scan() &#123; //遍历存储 text := scanner.Text() var topic Topic if err := json.Unmarshal([]byte(text), &amp;topic); err != nil &#123; return err &#125; topicTmpMap[topic.Id] = &amp;topic\t&#125;\ttopicIndexMap = topicTmpMap\treturn nil&#125; 查询 话题 索引：话题 ID 数据：话题 帖子 索引：话题 ID 数据：帖子列表 话题查询（帖子略） 123456789101112131415161718192021222324type Topic struct &#123;\tId int64 `json:&quot;id&quot;`\tTitle string `json:&quot;title&quot;`\tContent string `json:&quot;content&quot;`\tCreateTime int64 `json:&quot;create_time&quot;`&#125;type TopicDao struct &#123;&#125;var (\ttopicDao *TopicDao\ttopicOnce sync.Once //适合高并发场景下只执行一次的场景，可以减少存储的浪费)func NewTopicDaoInstance() *TopicDao &#123;\ttopicOnce.Do( func() &#123; topicDao = &amp;TopicDao&#123;&#125; &#125;)\treturn topicDao&#125;func (*TopicDao) QueryTopicById(id int64) *Topic &#123;\treturn topicIndexMap[id]&#125; Service实体1234type PageInfo struct &#123;\tTopic *repository.Topic\tPostList []*repository.Post&#125; 流程 参数校验 –&gt; 准备数据 –&gt; 组装实体 代码流程编排123456789101112func (f *QueryPageInfoFlow) Do() (*PageInfo, error) &#123;\tif err := f.checkParam(); err != nil &#123; return nil, err\t&#125;\tif err := f.prepareInfo(); err != nil &#123; return nil, err\t&#125;\tif err := f.packPageInfo(); err != nil &#123; return nil, err\t&#125;\treturn f.pageInfo, nil&#125; 可用性并行处理 123456789101112131415161718func (f *QueryPageInfoFlow) prepareInfo() error &#123;\t//获取topic信息\tvar wg sync.WaitGroup\twg.Add(2)\tgo func() &#123; defer wg.Done() topic := repository.NewTopicDaoInstance().QueryTopicById(f.topicId) f.topic = topic\t&#125;()\t//获取post列表\tgo func() &#123; defer wg.Done() posts := repository.NewPostDaoInstance().QueryPostsByParentId(f.topicId) f.posts = posts\t&#125;()\twg.Wait()\treturn nil&#125; Controller 构建 View 对象 业务错误码 123456789101112131415161718192021222324252627type PageData struct &#123;\tCode int64 `json:&quot;code&quot;`\tMsg string `json:&quot;msg&quot;`\tData interface&#123;&#125; `json:&quot;data&quot;`&#125;func QueryPageInfo(topicIdStr string) *PageData &#123;\ttopicId, err := strconv.ParseInt(topicIdStr, 10, 64)\tif err != nil &#123; return &amp;PageData&#123; Code: -1, Msg: err.Error(), &#125;\t&#125;\tpageInfo, err := service.QueryPageInfo(topicId)\tif err != nil &#123; return &amp;PageData&#123; Code: -1, Msg: err.Error(), &#125;\t&#125;\treturn &amp;PageData&#123; Code: 0, Msg: &quot;success&quot;, Data: pageInfo,\t&#125;&#125; Router 初始化数据索引 初始化引擎配置 构建路由 启动服务 123456789101112131415func main() &#123;\tif err := Init(&quot;./data/&quot;); err != nil &#123; os.Exit(-1)\t&#125;\tr := gin.Default()\tr.GET(&quot;/community/page/get/:id&quot;, func(c *gin.Context) &#123; topicId := c.Param(&quot;id&quot;) data := cotroller.QueryPageInfo(topicId) c.JSON(200, data)\t&#125;)\terr := r.Run()\tif err != nil &#123; return\t&#125;&#125; 运行 运行测试：go run server.go 课后实践 支持发布帖子 支持 Id 生成需要保证不重复、唯一性 Append 文件，更新索引，注意 Map 的并发安全问题","tags":["Go"],"categories":["字节青训营"]},{"title":"Go语言基础——基础语法","path":"/posts/go-language-basics/","content":"什么是 Go 语言 高性能、高并发 语法简单、学习曲线平缓 丰富的标准库 完整的工具链 静态链接 快速编译 跨平台 垃圾回收 123456789// 实现一个简单的http服务器package mainimport &quot;net/http&quot;func main() &#123;\thttp.Handle(&quot;/&quot;, http.FileServer(http.Dir(&quot;.&quot;)))\thttp.ListenAndServe(&quot;:8080&quot;, nil)&#125; 开发环境 安装 Golang Golang 官网：https://go.dev/ Golang 中国镜像：https://studygolang.com/dl 配置代理：https://goproxy.cn/ 配置集成开发环境 VSCode——安装 Go 插件 GoLand 基于云的开发环境 https://gitpod.io/#github.com/wangkechun/go-by-example 短链接：https://hi-hi.cn/gitpod 基础语法Hello World123456789package mainimport (\t&quot;fmt&quot;)func main() &#123;\tfmt.Println(&quot;hello world&quot;)&#125; 变量12345678910111213141516171819202122232425package mainimport (\t&quot;fmt&quot;\t&quot;math&quot;)func main() &#123;\t//两种声明方式\tvar a = &quot;initial&quot; //声明变量会自动推导变量类型\tvar b, c int = 1, 2 //也可以显式写出变量类型\tvar d = true\tvar e float64\tf := float32(e) //即var f = float32(e)\tg := a + &quot;foo&quot; //字符串可直接通过 + 拼接\tfmt.Println(a, b, c, d, e, f) //initial 1 2 true 0 0\tfmt.Println(g) //initialapple\tfmt.Println(&quot;abc&quot; &gt; &quot;a&quot;) //true 可以直接对字符串进行比较\t//声明常量只需将var改成const,常量没有固定类型，会根据上下文自动判断\tconst s string = &quot;constant&quot;\tconst h = 500000000\tconst i = 3e20 / h\tfmt.Println(s, h, i, math.Sin(h), math.Sin(i))&#125; if else1234567891011121314151617181920212223package mainimport &quot;fmt&quot;func main() &#123;\tif 7%2 == 0 &#123; //花括号不能另起一行 fmt.Println(&quot;7 is even&quot;)\t&#125; else &#123; //else也不能另起一行 fmt.Println(&quot;7 is odd&quot;)\t&#125;\tif 8%4 == 0 &#123; fmt.Println(&quot;8 is divisible by 4&quot;)\t&#125;\tif num := 9; num &lt; 0 &#123; //if里可以多个语句，但只以最后一句作为判断，一般不这么写 fmt.Println(num, &quot;is negative&quot;)\t&#125; else if num &lt; 10 &#123; fmt.Println(num, &quot;has 1 digit&quot;)\t&#125; else &#123; fmt.Println(num, &quot;has multiple digits&quot;)\t&#125;&#125; 循环12345678910111213141516171819202122232425package mainimport &quot;fmt&quot;func main() &#123;\ti := 1\tfor &#123; //相当于无限循环，遇到break退出 fmt.Println(&quot;loop&quot;) break\t&#125;\tfor j := 7; j &lt; 9; j++ &#123; fmt.Println(j)\t&#125;\tfor n := 0; n &lt; 5; n++ &#123; if n%2 == 0 &#123; continue &#125; fmt.Println(n)\t&#125;\tfor i &lt;= 3 &#123; //相当于while (i &lt;= 3) fmt.Println(i) i = i + 1\t&#125;&#125; switch1234567891011121314151617181920212223242526272829303132package mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\ta := 2\tswitch a &#123; //可以使用任意变量类型\tcase 1: fmt.Println(&quot;one&quot;) //默认不需要加break，不会跑到其他分支\tcase 2: fmt.Println(&quot;two&quot;) fallthrough //想要穿透下一层需要加（只能穿透一层）\tcase 3: fmt.Println(&quot;three&quot;)\tcase 4, 5: //多种情况中间加&quot;,&quot; fmt.Println(&quot;four or five&quot;)\tdefault: fmt.Println(&quot;other&quot;)\t&#125;\t//可以利用switch在case里写条件分支，相比更多if-else嵌套更加清晰易懂\tt := time.Now() //获取当前时间\tswitch &#123;\tcase t.Hour() &lt; 12: fmt.Println(&quot;It&#x27;s before noon&quot;)\tdefault: fmt.Println(&quot;It&#x27;s after noon&quot;)\t&#125;&#125; 数组12345678910111213141516171819202122package mainimport &quot;fmt&quot;func main() &#123;\t//数组长度固定，因此更多用的是切片slice\tvar a [5]int\ta[4] = 100\tfmt.Println(&quot;get:&quot;, a[2])\tfmt.Println(&quot;len:&quot;, len(a))\tb := [5]int&#123;1, 2, 3, 4, 5&#125;\tfmt.Println(b) // [1,2,3,4,5] Go会给array、slice、map等输出做渲染\tvar twoD [2][3]int\tfor i := 0; i &lt; 2; i++ &#123; for j := 0; j &lt; 3; j++ &#123; twoD[i][j] = i + j &#125;\t&#125;\tfmt.Println(&quot;2d:&quot;, twoD) // 2d: [[0 1 2] [1 2 3]]&#125; 切片12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;func main() &#123;\ts := make([]string, 3)\ts[0] = &quot;a&quot;\ts[1] = &quot;b&quot;\ts[2] = &quot;c&quot;\tfmt.Println(&quot;get:&quot;, s[2]) // c\tfmt.Println(&quot;len:&quot;, len(s)) // 3\ts = append(s, &quot;d&quot;)\ts = append(s, &quot;e&quot;, &quot;f&quot;)\tfmt.Println(s) // [a b c d e f]\tc := make([]string, len(s))\tcopy(c, s) //拷贝数据\tfmt.Println(c) // [a b c d e f]\tfmt.Println(s[2:5]) // [c d e] 左闭右开\tfmt.Println(s[:5]) // [a b c d e] 从第一个开始\tfmt.Println(s[2:]) // [c d e f] 到最后一个结束\tfmt.Println(s[:]) // [a b c d e f] 全部打印出来\tgood := []string&#123;&quot;g&quot;, &quot;o&quot;, &quot;o&quot;, &quot;d&quot;&#125;\tfmt.Println(good) // [g o o d]&#125; map1234567891011121314151617181920212223package mainimport &quot;fmt&quot;func main() &#123;\t//相当于映射,但存储是无序存储，声明时的默认值是nil\tm := make(map[string]int)\tm[&quot;one&quot;] = 1\tm[&quot;two&quot;] = 2\tfmt.Println(m) // map[one:1 two:2]\tfmt.Println(len(m)) // 2\tfmt.Println(m[&quot;one&quot;]) // 1\tfmt.Println(m[&quot;unknow&quot;]) // 0\tr, ok := m[&quot;unknow&quot;] //会有2个返回值，前一个是int（对应类型），后一个是bool\tfmt.Println(r, ok) // 0 false\tdelete(m, &quot;one&quot;) //删除\tm2 := map[string]int&#123;&quot;one&quot;: 1, &quot;two&quot;: 2&#125;\tvar m3 = map[string]int&#123;&quot;one&quot;: 1, &quot;two&quot;: 2&#125;\tfmt.Println(m2, m3)&#125; range123456789101112131415161718192021222324package mainimport &quot;fmt&quot;func main() &#123;\t//range允许你遍历某个slice或map,并通过两个参数（index和value），分别获得其中的index以及其值\tnums := []int&#123;2, 3, 4&#125;\tsum := 0\tfor i, num := range nums &#123; sum += num if num == 2 &#123; fmt.Println(&quot;index:&quot;, i, &quot;num:&quot;, num) // index: 0 num: 2 &#125;\t&#125;\tfmt.Println(sum) // 9\tm := map[string]string&#123;&quot;a&quot;: &quot;A&quot;, &quot;b&quot;: &quot;B&quot;&#125;\tfor k, v := range m &#123; fmt.Println(k, v) // b B; a A (或a A; b B) map是无序存储\t&#125;\tfor k := range m &#123; //第二个返回值默认丢弃，返回index（也可写成k,_:=range m） fmt.Println(&quot;key&quot;, k) // key a; key b (或key b,key a)\t&#125;&#125; 函数123456789101112131415161718192021222324package mainimport &quot;fmt&quot;func add(a int, b int) int &#123;\treturn a + b&#125;func add2(a, b int) int &#123; //若数据类型相同，前一个可以省略\treturn a + b&#125;func exists(m map[string]string, k string) (v string, ok bool) &#123;\tv, ok = m[k]\treturn v, ok&#125;func main() &#123;\tres := add(1, 2)\tfmt.Println(res) // 3\tv, ok := exists(map[string]string&#123;&quot;a&quot;: &quot;A&quot;&#125;, &quot;a&quot;)\tfmt.Println(v, ok) // A True&#125; 指针12345678910111213141516171819package mainimport &quot;fmt&quot;func add2(n int) &#123;\tn += 2&#125;func add2ptr(n *int) &#123;\t*n += 2&#125;func main() &#123;\tn := 5\tadd2(n)\tfmt.Println(n) // 5\tadd2ptr(&amp;n)\tfmt.Println(n) // 7&#125; 结构体123456789101112131415161718192021222324252627282930package mainimport &quot;fmt&quot;type user struct &#123;\tname string\tpassword string&#125;func main() &#123;\ta := user&#123;name: &quot;wang&quot;, password: &quot;1024&quot;&#125;\tb := user&#123;&quot;wang&quot;, &quot;1024&quot;&#125; //省略前面写需要一一对应\tc := user&#123;name: &quot;wang&quot;&#125; //前面不省略可以不一一对应，未赋值默认为空值\tc.password = &quot;1024&quot;\tvar d user\td.name = &quot;wang&quot;\td.password = &quot;1024&quot;\tfmt.Println(a, b, c, d) // &#123;wang 1024&#125; &#123;wang 1024&#125; &#123;wang 1024&#125; &#123;wang 1024&#125;\tfmt.Println(checkPassword(a, &quot;haha&quot;)) // false\tfmt.Println(checkPassword2(&amp;a, &quot;haha&quot;)) // false&#125;func checkPassword(u user, password string) bool &#123;\treturn u.password == password&#125;func checkPassword2(u *user, password string) bool &#123;\treturn u.password == password //Go中指针写法与不是指针的一样&#125; 结构体方法12345678910111213141516171819202122package mainimport &quot;fmt&quot;type user struct &#123;\tname string\tpassword string&#125;func (u user) checkPassword(password string) bool &#123; //函数前面的括号表示只能被该类型调用，称为方法\treturn u.password == password&#125;func (u *user) resetPassword(password string) &#123;\tu.password = password&#125;func main() &#123;\ta := user&#123;name: &quot;wang&quot;, password: &quot;1024&quot;&#125;\ta.resetPassword(&quot;2048&quot;)\tfmt.Println(a.checkPassword(&quot;2048&quot;)) // true&#125; 错误处理123456789101112131415161718192021222324252627282930313233343536package mainimport (\t&quot;errors&quot;\t&quot;fmt&quot;)type user struct &#123;\tname string\tpassword string&#125;func findUser(users []user, name string) (v *user, err error) &#123;\tfor _, u := range users &#123; if u.name == name &#123; return &amp;u, nil &#125;\t&#125;\treturn nil, errors.New(&quot;not found&quot;)&#125;func main() &#123;\tu, err := findUser([]user&#123;&#123;&quot;wang&quot;, &quot;1024&quot;&#125;&#125;, &quot;wang&quot;)\tif err != nil &#123; fmt.Println(err) return\t&#125;\tfmt.Println(u.name) // wang\tif u, err := findUser([]user&#123;&#123;&quot;wang&quot;, &quot;1024&quot;&#125;&#125;, &quot;li&quot;); err != nil &#123; fmt.Println(err) // not found return\t&#125; else &#123; fmt.Println(u.name)\t&#125;&#125; 字符串操作123456789101112131415161718192021222324252627package mainimport (\t&quot;fmt&quot;\t&quot;strings&quot;)func main() &#123;\ta := &quot;hello&quot;\tfmt.Println(strings.Contains(a, &quot;ll&quot;)) // true 是否包含\tfmt.Println(strings.Count(a, &quot;l&quot;)) // 2 计数\tfmt.Println(strings.HasPrefix(a, &quot;he&quot;)) // true 是否存在前缀\tfmt.Println(strings.HasSuffix(a, &quot;llo&quot;)) // true 是否存在后缀\tfmt.Println(strings.Index(a, &quot;ll&quot;)) // 2 字符串开头位的索引（前一个l）\tfmt.Println(strings.Join([]string&#123;&quot;he&quot;, &quot;llo&quot;&#125;, &quot;-&quot;)) // he-llo 切片之间加东西连接返回字符串\tfmt.Println(strings.Split(&quot;a-b-c&quot;, &quot;-&quot;)) // [a b c] 与join相反，字符串去东西返回切片\tfmt.Println(strings.Repeat(a, 2)) // hellohello 重复\tfmt.Println(strings.Replace(a, &quot;l&quot;, &quot;L&quot;, 1)) // heLlo 替换1个\tfmt.Println(strings.Replace(a, &quot;l&quot;, &quot;L&quot;, 2)) //heLLo 替换2个\tfmt.Println(strings.Replace(a, &quot;l&quot;, &quot;L&quot;, 3)) //heLLo 超出相当于全部替换,不会报错\tfmt.Println(strings.Replace(a, &quot;l&quot;, &quot;L&quot;, -1)) //heLLo -1表示全部替换\tfmt.Println(strings.ToLower(a)) // hello 全小写\tfmt.Println(strings.ToUpper(a)) // HELLO 全大写\tfmt.Println(len(a)) // 5 长度\tb := &quot;你好&quot;\tfmt.Println(len(b)) // 6 UTF-8一个中文字符对应三个字符&#125; 字符串格式化1234567891011121314151617181920212223242526package mainimport &quot;fmt&quot;type point struct &#123;\tx, y int&#125;func main() &#123;\ts := &quot;hello&quot;\tn := 123\tp := point&#123;1, 2&#125;\tfmt.Println(s, n) // hello 123\tfmt.Println(p) // &#123;1 2&#125;\tfmt.Printf(&quot;s=%v &quot;, s) // s=hello\tfmt.Printf(&quot;n=%v &quot;, n) // n=123\tfmt.Printf(&quot;p=%v &quot;, p) // p=&#123;1 2&#125;\tfmt.Printf(&quot;p=%+v &quot;, p) // p=&#123;x:1 y:2&#125; 返回详细结果\tfmt.Printf(&quot;p=%#v &quot;, p) // p=main.point&#123;x:1, y:2&#125; 返回更详细结果\tf := 3.141592653\tfmt.Println(f) // 3.141592653\tfmt.Printf(&quot;%.2f &quot;, f) // 3.14 2位小数\tfmt.Printf(&quot;%.2v &quot;, f) // 3.1 2位有效数字&#125; JSON 处理1234567891011121314151617181920212223242526272829303132333435package mainimport (\t&quot;encoding/json&quot;\t&quot;fmt&quot;)type userInfo struct &#123;\tName string\tAge int `json:&quot;age&quot;` //映射，将不同规范下的变量名绑定起来\tHobby []string&#125;func main() &#123;\ta := userInfo&#123;Name: &quot;wang&quot;, Age: 18, Hobby: []string&#123;&quot;Golang&quot;, &quot;TypeScript&quot;&#125;&#125;\tbuf, err := json.Marshal(a) //序列化\tif err != nil &#123; panic(err)\t&#125;\tfmt.Println(buf) // [123 34 78 97...] 十六进制编码\tfmt.Println(string(buf)) // &#123;&quot;Name&quot;:&quot;wang&quot;,&quot;age&quot;:18,&quot;Hobby&quot;:[&quot;Golang&quot;,&quot;TypeScript&quot;]&#125;\tbuf, err = json.MarshalIndent(a, &quot;&quot;, &quot;\\t&quot;) //第二位表示前缀，第三位表示缩进\tif err != nil &#123; panic(err)\t&#125;\tfmt.Println(string(buf))\tvar b userInfo\terr = json.Unmarshal(buf, &amp;b) //反序列化\tif err != nil &#123; panic(err)\t&#125;\tfmt.Printf(&quot;%#v &quot;, b) // main.userInfo&#123;Name:&quot;wang&quot;, Age:18, Hobby:[]string&#123;&quot;Golang&quot;, &quot;TypeScript&quot;&#125;&#125;&#125; 时间处理1234567891011121314151617181920212223242526package mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tnow := time.Now()\tfmt.Println(now) // 2022-03-27 18:04:59.433297 +0800 CST m=+0.000087933\tt := time.Date(2022, 3, 27, 1, 25, 36, 0, time.UTC)\tt2 := time.Date(2022, 3, 27, 2, 30, 36, 0, time.UTC)\tfmt.Println(t) // 2022-03-27 01:25:36 +0000 UTC\tfmt.Println(t.Year(), t.Month(), t.Day(), t.Hour(), t.Minute()) // 2022 March 27 1 25\tfmt.Println(t.Format(&quot;2006-01-02 15:04:05&quot;)) // 2022-03-27 01:25:36 固定的格式化时间，将时间转为字符串输出\tdiff := t2.Sub(t) //时间差\tfmt.Println(diff) // 1h5m0s\tfmt.Println(diff.Minutes(), diff.Seconds()) // 65 3900\tt3, err := time.Parse(&quot;2006-01-02 15:04:05&quot;, &quot;2022-03-27 01:25:36&quot;) //将字符串转为时间输出\tif err != nil &#123; panic(err)\t&#125;\tfmt.Println(t3 == t) // true\tfmt.Println(now.Unix()) //从1970.1.1 00：00：00到现在以秒为单位的时间戳\tfmt.Println(now.UnixNano()) //更精细到纳秒&#125; 数字解析1234567891011121314151617181920212223package mainimport (\t&quot;fmt&quot;\t&quot;strconv&quot;)func main() &#123;\tf, _ := strconv.ParseFloat(&quot;1.234&quot;, 64) //string-&gt;float64\tfmt.Println(f) // 1.234\tn, _ := strconv.ParseInt(&quot;111&quot;, 10, 64) //string-&gt;10进制longlong\tfmt.Println(n) // 111\tn, _ = strconv.ParseInt(&quot;0x1000&quot;, 0, 64) //中间0表示默认，按字符串内格式转化，如0x1000表示16进制，01000表示8进制，1000表示十进制\tfmt.Println(n) // 4096\tn2, _ := strconv.Atoi(&quot;123&quot;) //一种简写，等价于ParseInt(&quot;123&quot;,10,0),默认转为十进制，最后一位0表示默认，按转化的数据大小为32或64\tfmt.Println(n2) // 123\tn2, err := strconv.Atoi(&quot;AAA&quot;) //输入不合法会返回错误\tfmt.Println(n2, err) // 0 strconv.Atoi: parsing &quot;AAA&quot;: invalid syntax&#125; 进程信息1234567891011121314151617181920package mainimport (\t&quot;fmt&quot;\t&quot;os&quot;\t&quot;os/exec&quot;)func main() &#123;\t// go run example/20-env/main.go a b c d\tfmt.Println(os.Args) // [/var/folders/8p/n34xxfnx38dg8bv_x8l62t_m0000gn/T/go-build3406981276/b001/exe/main a b c d]\tfmt.Println(os.Getenv(&quot;PATH&quot;)) // /usr/local/go/bin...\tfmt.Println(os.Setenv(&quot;AA&quot;, &quot;BB&quot;))\tbuf, err := exec.Command(&quot;grep&quot;, &quot;127.0.0.1&quot;, &quot;/etc/hosts&quot;).CombinedOutput()\tif err != nil &#123; panic(err)\t&#125;\tfmt.Println(string(buf)) // 127.0.0.1 localhost&#125;","tags":["Go"],"categories":["字节青训营"]},{"path":"/friends/index.html","content":"友链关于浮云一别后，流水十年间。 老登 派大星🐷j10cFinley 中登 青鸟🐷竹林里有冰TiancymulberrorT-ON-Y 小登 离谱望舒QianqianZykZeroHzzzzSodium-salt"},{"path":"/about/index.html","content":"友链关于About&nbsp;Me hello，这里是我 软件工程专业MBTI: ISFJ-T熟悉一些Web开发喜欢看番/看漫画/看小说/在工作时间不工作人生追求：“不求大富大贵，但求安饱无忧。不望平凡余生，但愿尽己余力。”"}]